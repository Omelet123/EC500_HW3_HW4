{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Problem Set 3\n",
    "\n",
    "\n",
    "By Xide Xia  with help of Brian Kulis, Kate Saenko, Ali Siahkamari, and Kun He."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This assignment will introduce you to:\n",
    "1. Building and training a convolutional network\n",
    "2. Saving snapshots of your trained model\n",
    "3. Reloading weights from a saved model\n",
    "4. Fine-tuning a pre-trained network\n",
    "5. Visualizations using Tensorboard\n",
    "\n",
    "This code has been tested and should for Python 3.5 and 2.7 with tensorflow. You can update to recent tensorflow version just by doing `pip install tensorflow`,  or `pip install tensorflow-gpu` if you want to use GPU.\n",
    "\n",
    "**Note:** This notebook contains problem descriptions and demo/starter code. However, you're welcome to implement and submit .py files directly, if that's easier for you. Starter .py files are provided in the same `pset4/` directory.\n",
    "\n",
    "**Warning:** The gpu queue on SCC may be long when the deadline comes. Please start your homework early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Tutorials\n",
    "\n",
    "You will find these TensorFlow tutorials on CNNs useful:\n",
    " - [Deep MNIST for experts](https://www.tensorflow.org/get_started/mnist/pros)\n",
    " - [Convolutional Neural Networks](https://www.tensorflow.org/tutorials/deep_cnn)\n",
    " \n",
    "Note that there are many ways to implement the same thing in TensorFlow, for example, both tf.nn and tf.layers provide convolutional layers but with slightly different interfaces. You will need to read the documentation of the functions provided below to understand how they work.\n",
    "\n",
    "Also, you can run your experiments on SCC if you want to use GPU. You will find the SCC tutorial helpful: - [SCC tutorials](http://rcs.bu.edu/classes/DeepLearning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Building and Training a ConvNet on SVHN\n",
    "(25 points)\n",
    "\n",
    "First we provide demo code that trains a convolutional network on the [SVHN Dataset](http://ufldl.stanford.edu/housenumbers/).. \n",
    "\n",
    "You will need to download   __Format 2__ from the link above.\n",
    "- Create a directory named `svhn_mat/` in the working directory. Or, you can create it anywhere you want, but change the path in `svhn_dataset_generator` to match it.\n",
    "- Download `train_32x32.mat` and `test_32x32.mat` to this directory.\n",
    "- `extra_32x32.mat` is NOT needed.\n",
    "- You may find the `wget` command useful for downloading on linux. \n",
    "\n",
    "\n",
    "\n",
    "The following defines a generator for the SVHN Dataset, yielding the next batch every time next is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "\n",
    "from six.moves import range\n",
    "\n",
    "import read_data\n",
    "\n",
    "@read_data.restartable\n",
    "def svhn_dataset_generator(dataset_name, batch_size):\n",
    "    assert dataset_name in ['train', 'test']\n",
    "    assert batch_size > 0 or batch_size == -1  # -1 for entire dataset\n",
    "    \n",
    "    path = './svhn_mat/' # path to the SVHN dataset you will download in Q1.1\n",
    "    file_name = '%s_32x32.mat' % dataset_name\n",
    "    file_dict = scipy.io.loadmat(os.path.join(path, file_name))\n",
    "    X_all = file_dict['X'].transpose((3, 0, 1, 2))\n",
    "    y_all = file_dict['y']\n",
    "    data_len = X_all.shape[0]\n",
    "    batch_size = batch_size if batch_size > 0 else data_len\n",
    "    \n",
    "    X_all_padded = np.concatenate([X_all, X_all[:batch_size]], axis=0)\n",
    "    y_all_padded = np.concatenate([y_all, y_all[:batch_size]], axis=0)\n",
    "    y_all_padded[y_all_padded == 10] = 0\n",
    "    \n",
    "    for slice_i in range(int(math.ceil(data_len / batch_size))):\n",
    "        idx = slice_i * batch_size\n",
    "        X_batch = X_all_padded[idx:idx + batch_size]\n",
    "        y_batch = np.ravel(y_all_padded[idx:idx + batch_size])\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# The following defines a simple CovNet Model.\n",
    "def SVHN_net_v0(x_):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            name='conv1')\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            name ='conv2')\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def apply_classification_loss(model_function):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        with tf.device(\"/gpu:0\"):  # use gpu:0 if on GPU\n",
    "            x_ = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "            y_ = tf.placeholder(tf.int32, [None])\n",
    "            y_logits = model_function(x_)\n",
    "            \n",
    "            y_dict = dict(labels=y_, logits=y_logits)\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict)\n",
    "            cross_entropy_loss = tf.reduce_mean(losses)\n",
    "            trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "            train_op = trainer.minimize(cross_entropy_loss)\n",
    "            \n",
    "            y_pred = tf.argmax(tf.nn.softmax(y_logits), axis=1)\n",
    "            correct_prediction = tf.equal(tf.cast(y_pred, tf.int32), y_)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    model_dict = {'graph': g, 'inputs': [x_, y_], 'train_op': train_op,\n",
    "                  'accuracy': accuracy, 'loss': cross_entropy_loss}\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Training SVHN Net\n",
    "(2 points)\n",
    "\n",
    "Now we train the SVHN_net_v0 net on Format 2 of the SVHN Dataset.  \n",
    "\n",
    "**Note:** training will take a while, so you might want to use GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_dict, dataset_generators, epoch_n, print_every):\n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch_i in range(epoch_n):\n",
    "            for iter_i, data_batch in enumerate(dataset_generators['train']):\n",
    "                train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
    "                sess.run(model_dict['train_op'], feed_dict=train_feed_dict)\n",
    "                \n",
    "                if iter_i % print_every == 0:\n",
    "                    collect_arr = []\n",
    "                    for test_batch in dataset_generators['test']:\n",
    "                        test_feed_dict = dict(zip(model_dict['inputs'], test_batch))\n",
    "                        to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
    "                        collect_arr.append(sess.run(to_compute, test_feed_dict))\n",
    "                    averages = np.mean(collect_arr, axis=0)\n",
    "                    fmt = (epoch_i, iter_i, ) + tuple(averages)\n",
    "                    print('epoch {:d} iter {:d}, loss: {:.3f}, '\n",
    "                          'accuracy: {:.3f}'.format(*fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 57.970, accuracy: 0.079\n",
      "epoch 0 iter 20, loss: 2.282, accuracy: 0.186\n",
      "epoch 0 iter 40, loss: 2.243, accuracy: 0.196\n",
      "epoch 0 iter 60, loss: 2.241, accuracy: 0.196\n",
      "epoch 0 iter 80, loss: 2.238, accuracy: 0.196\n",
      "epoch 0 iter 100, loss: 2.235, accuracy: 0.196\n",
      "epoch 0 iter 120, loss: 2.234, accuracy: 0.196\n",
      "epoch 0 iter 140, loss: 2.235, accuracy: 0.196\n",
      "epoch 0 iter 160, loss: 2.233, accuracy: 0.196\n",
      "epoch 0 iter 180, loss: 2.229, accuracy: 0.195\n",
      "epoch 0 iter 200, loss: 2.216, accuracy: 0.209\n",
      "epoch 0 iter 220, loss: 2.208, accuracy: 0.200\n",
      "epoch 0 iter 240, loss: 2.192, accuracy: 0.219\n",
      "epoch 0 iter 260, loss: 2.172, accuracy: 0.221\n",
      "epoch 0 iter 280, loss: 2.150, accuracy: 0.222\n",
      "epoch 1 iter 0, loss: 2.138, accuracy: 0.237\n",
      "epoch 1 iter 20, loss: 2.113, accuracy: 0.248\n",
      "epoch 1 iter 40, loss: 2.036, accuracy: 0.301\n",
      "epoch 1 iter 60, loss: 1.704, accuracy: 0.436\n",
      "epoch 1 iter 80, loss: 1.540, accuracy: 0.513\n",
      "epoch 1 iter 100, loss: 1.458, accuracy: 0.531\n",
      "epoch 1 iter 120, loss: 1.424, accuracy: 0.543\n",
      "epoch 1 iter 140, loss: 1.358, accuracy: 0.571\n",
      "epoch 1 iter 160, loss: 1.285, accuracy: 0.598\n",
      "epoch 1 iter 180, loss: 1.233, accuracy: 0.616\n",
      "epoch 1 iter 200, loss: 1.232, accuracy: 0.622\n",
      "epoch 1 iter 220, loss: 1.193, accuracy: 0.638\n",
      "epoch 1 iter 240, loss: 1.150, accuracy: 0.653\n",
      "epoch 1 iter 260, loss: 1.131, accuracy: 0.656\n",
      "epoch 1 iter 280, loss: 1.090, accuracy: 0.675\n",
      "epoch 2 iter 0, loss: 1.075, accuracy: 0.675\n",
      "epoch 2 iter 20, loss: 1.060, accuracy: 0.685\n",
      "epoch 2 iter 40, loss: 1.050, accuracy: 0.687\n",
      "epoch 2 iter 60, loss: 1.052, accuracy: 0.687\n",
      "epoch 2 iter 80, loss: 1.009, accuracy: 0.698\n",
      "epoch 2 iter 100, loss: 1.028, accuracy: 0.689\n",
      "epoch 2 iter 120, loss: 0.968, accuracy: 0.712\n",
      "epoch 2 iter 140, loss: 0.964, accuracy: 0.715\n",
      "epoch 2 iter 160, loss: 0.961, accuracy: 0.713\n",
      "epoch 2 iter 180, loss: 0.925, accuracy: 0.727\n",
      "epoch 2 iter 200, loss: 0.958, accuracy: 0.718\n",
      "epoch 2 iter 220, loss: 0.938, accuracy: 0.725\n",
      "epoch 2 iter 240, loss: 0.941, accuracy: 0.723\n",
      "epoch 2 iter 260, loss: 0.890, accuracy: 0.741\n",
      "epoch 2 iter 280, loss: 0.907, accuracy: 0.737\n",
      "epoch 3 iter 0, loss: 0.892, accuracy: 0.738\n",
      "epoch 3 iter 20, loss: 0.891, accuracy: 0.741\n",
      "epoch 3 iter 40, loss: 0.883, accuracy: 0.746\n",
      "epoch 3 iter 60, loss: 0.920, accuracy: 0.732\n",
      "epoch 3 iter 80, loss: 0.827, accuracy: 0.761\n",
      "epoch 3 iter 100, loss: 0.834, accuracy: 0.756\n",
      "epoch 3 iter 120, loss: 0.844, accuracy: 0.753\n",
      "epoch 3 iter 140, loss: 0.832, accuracy: 0.761\n",
      "epoch 3 iter 160, loss: 0.828, accuracy: 0.761\n",
      "epoch 3 iter 180, loss: 0.810, accuracy: 0.767\n",
      "epoch 3 iter 200, loss: 0.852, accuracy: 0.752\n",
      "epoch 3 iter 220, loss: 0.801, accuracy: 0.771\n",
      "epoch 3 iter 240, loss: 0.805, accuracy: 0.765\n",
      "epoch 3 iter 260, loss: 0.779, accuracy: 0.777\n",
      "epoch 3 iter 280, loss: 0.789, accuracy: 0.778\n",
      "epoch 4 iter 0, loss: 0.813, accuracy: 0.768\n",
      "epoch 4 iter 20, loss: 0.779, accuracy: 0.778\n",
      "epoch 4 iter 40, loss: 0.781, accuracy: 0.778\n",
      "epoch 4 iter 60, loss: 0.820, accuracy: 0.766\n",
      "epoch 4 iter 80, loss: 0.766, accuracy: 0.783\n",
      "epoch 4 iter 100, loss: 0.768, accuracy: 0.780\n",
      "epoch 4 iter 120, loss: 0.781, accuracy: 0.776\n",
      "epoch 4 iter 140, loss: 0.758, accuracy: 0.785\n",
      "epoch 4 iter 160, loss: 0.747, accuracy: 0.787\n",
      "epoch 4 iter 180, loss: 0.737, accuracy: 0.792\n",
      "epoch 4 iter 200, loss: 0.743, accuracy: 0.791\n",
      "epoch 4 iter 220, loss: 0.755, accuracy: 0.791\n",
      "epoch 4 iter 240, loss: 0.743, accuracy: 0.791\n",
      "epoch 4 iter 260, loss: 0.737, accuracy: 0.794\n",
      "epoch 4 iter 280, loss: 0.755, accuracy: 0.794\n",
      "epoch 5 iter 0, loss: 0.790, accuracy: 0.784\n",
      "epoch 5 iter 20, loss: 0.743, accuracy: 0.793\n",
      "epoch 5 iter 40, loss: 0.737, accuracy: 0.792\n",
      "epoch 5 iter 60, loss: 0.753, accuracy: 0.792\n",
      "epoch 5 iter 80, loss: 0.732, accuracy: 0.797\n",
      "epoch 5 iter 100, loss: 0.730, accuracy: 0.794\n",
      "epoch 5 iter 120, loss: 0.733, accuracy: 0.799\n",
      "epoch 5 iter 140, loss: 0.720, accuracy: 0.802\n",
      "epoch 5 iter 160, loss: 0.741, accuracy: 0.791\n",
      "epoch 5 iter 180, loss: 0.712, accuracy: 0.803\n",
      "epoch 5 iter 200, loss: 0.750, accuracy: 0.800\n",
      "epoch 5 iter 220, loss: 0.766, accuracy: 0.791\n",
      "epoch 5 iter 240, loss: 0.721, accuracy: 0.800\n",
      "epoch 5 iter 260, loss: 0.724, accuracy: 0.800\n",
      "epoch 5 iter 280, loss: 0.757, accuracy: 0.796\n",
      "epoch 6 iter 0, loss: 0.770, accuracy: 0.796\n",
      "epoch 6 iter 20, loss: 0.716, accuracy: 0.807\n",
      "epoch 6 iter 40, loss: 0.735, accuracy: 0.799\n",
      "epoch 6 iter 60, loss: 0.731, accuracy: 0.806\n",
      "epoch 6 iter 80, loss: 0.722, accuracy: 0.805\n",
      "epoch 6 iter 100, loss: 0.712, accuracy: 0.804\n",
      "epoch 6 iter 120, loss: 0.723, accuracy: 0.808\n",
      "epoch 6 iter 140, loss: 0.726, accuracy: 0.805\n",
      "epoch 6 iter 160, loss: 0.743, accuracy: 0.797\n",
      "epoch 6 iter 180, loss: 0.731, accuracy: 0.805\n",
      "epoch 6 iter 200, loss: 0.775, accuracy: 0.800\n",
      "epoch 6 iter 220, loss: 0.763, accuracy: 0.800\n",
      "epoch 6 iter 240, loss: 0.719, accuracy: 0.806\n",
      "epoch 6 iter 260, loss: 0.716, accuracy: 0.805\n",
      "epoch 6 iter 280, loss: 0.730, accuracy: 0.809\n",
      "epoch 7 iter 0, loss: 0.761, accuracy: 0.804\n",
      "epoch 7 iter 20, loss: 0.710, accuracy: 0.812\n",
      "epoch 7 iter 40, loss: 0.742, accuracy: 0.802\n",
      "epoch 7 iter 60, loss: 0.748, accuracy: 0.805\n",
      "epoch 7 iter 80, loss: 0.710, accuracy: 0.814\n",
      "epoch 7 iter 100, loss: 0.713, accuracy: 0.810\n",
      "epoch 7 iter 120, loss: 0.718, accuracy: 0.812\n",
      "epoch 7 iter 140, loss: 0.781, accuracy: 0.804\n",
      "epoch 7 iter 160, loss: 0.765, accuracy: 0.799\n",
      "epoch 7 iter 180, loss: 0.745, accuracy: 0.811\n",
      "epoch 7 iter 200, loss: 0.853, accuracy: 0.791\n",
      "epoch 7 iter 220, loss: 0.758, accuracy: 0.799\n",
      "epoch 7 iter 240, loss: 0.741, accuracy: 0.808\n",
      "epoch 7 iter 260, loss: 0.740, accuracy: 0.808\n",
      "epoch 7 iter 280, loss: 0.754, accuracy: 0.807\n",
      "epoch 8 iter 0, loss: 0.755, accuracy: 0.809\n",
      "epoch 8 iter 20, loss: 0.736, accuracy: 0.814\n",
      "epoch 8 iter 40, loss: 0.784, accuracy: 0.798\n",
      "epoch 8 iter 60, loss: 0.752, accuracy: 0.807\n",
      "epoch 8 iter 80, loss: 0.739, accuracy: 0.815\n",
      "epoch 8 iter 100, loss: 0.736, accuracy: 0.815\n",
      "epoch 8 iter 120, loss: 0.747, accuracy: 0.814\n",
      "epoch 8 iter 140, loss: 0.842, accuracy: 0.801\n",
      "epoch 8 iter 160, loss: 0.778, accuracy: 0.802\n",
      "epoch 8 iter 180, loss: 0.762, accuracy: 0.815\n",
      "epoch 8 iter 200, loss: 0.795, accuracy: 0.807\n",
      "epoch 8 iter 220, loss: 0.772, accuracy: 0.805\n",
      "epoch 8 iter 240, loss: 0.749, accuracy: 0.812\n",
      "epoch 8 iter 260, loss: 0.738, accuracy: 0.814\n",
      "epoch 8 iter 280, loss: 0.754, accuracy: 0.814\n",
      "epoch 9 iter 0, loss: 0.784, accuracy: 0.807\n",
      "epoch 9 iter 20, loss: 0.765, accuracy: 0.816\n",
      "epoch 9 iter 40, loss: 0.814, accuracy: 0.800\n",
      "epoch 9 iter 60, loss: 0.793, accuracy: 0.807\n",
      "epoch 9 iter 80, loss: 0.759, accuracy: 0.814\n",
      "epoch 9 iter 100, loss: 0.790, accuracy: 0.808\n",
      "epoch 9 iter 120, loss: 0.791, accuracy: 0.808\n",
      "epoch 9 iter 140, loss: 0.872, accuracy: 0.793\n",
      "epoch 9 iter 160, loss: 0.809, accuracy: 0.805\n",
      "epoch 9 iter 180, loss: 0.897, accuracy: 0.790\n",
      "epoch 9 iter 200, loss: 0.921, accuracy: 0.803\n",
      "epoch 9 iter 220, loss: 0.793, accuracy: 0.807\n",
      "epoch 9 iter 240, loss: 0.799, accuracy: 0.803\n",
      "epoch 9 iter 260, loss: 0.745, accuracy: 0.811\n",
      "epoch 9 iter 280, loss: 0.838, accuracy: 0.803\n",
      "epoch 10 iter 0, loss: 0.834, accuracy: 0.799\n",
      "epoch 10 iter 20, loss: 0.814, accuracy: 0.814\n",
      "epoch 10 iter 40, loss: 0.826, accuracy: 0.802\n",
      "epoch 10 iter 60, loss: 0.853, accuracy: 0.799\n",
      "epoch 10 iter 80, loss: 0.786, accuracy: 0.813\n",
      "epoch 10 iter 100, loss: 0.839, accuracy: 0.807\n",
      "epoch 10 iter 120, loss: 0.843, accuracy: 0.801\n",
      "epoch 10 iter 140, loss: 0.826, accuracy: 0.805\n",
      "epoch 10 iter 160, loss: 0.847, accuracy: 0.803\n",
      "epoch 10 iter 180, loss: 0.852, accuracy: 0.803\n",
      "epoch 10 iter 200, loss: 0.895, accuracy: 0.801\n",
      "epoch 10 iter 220, loss: 0.816, accuracy: 0.809\n",
      "epoch 10 iter 240, loss: 0.793, accuracy: 0.813\n",
      "epoch 10 iter 260, loss: 0.753, accuracy: 0.814\n",
      "epoch 10 iter 280, loss: 0.797, accuracy: 0.819\n",
      "epoch 11 iter 0, loss: 0.825, accuracy: 0.811\n",
      "epoch 11 iter 20, loss: 0.893, accuracy: 0.806\n",
      "epoch 11 iter 40, loss: 0.844, accuracy: 0.801\n",
      "epoch 11 iter 60, loss: 0.809, accuracy: 0.814\n",
      "epoch 11 iter 80, loss: 0.814, accuracy: 0.810\n",
      "epoch 11 iter 100, loss: 0.840, accuracy: 0.804\n",
      "epoch 11 iter 120, loss: 0.883, accuracy: 0.796\n",
      "epoch 11 iter 140, loss: 0.843, accuracy: 0.805\n",
      "epoch 11 iter 160, loss: 0.890, accuracy: 0.812\n",
      "epoch 11 iter 180, loss: 0.859, accuracy: 0.816\n",
      "epoch 11 iter 200, loss: 0.902, accuracy: 0.803\n",
      "epoch 11 iter 220, loss: 0.837, accuracy: 0.804\n",
      "epoch 11 iter 240, loss: 0.820, accuracy: 0.810\n",
      "epoch 11 iter 260, loss: 0.780, accuracy: 0.818\n",
      "epoch 11 iter 280, loss: 0.814, accuracy: 0.814\n",
      "epoch 12 iter 0, loss: 0.870, accuracy: 0.814\n",
      "epoch 12 iter 20, loss: 0.932, accuracy: 0.799\n",
      "epoch 12 iter 40, loss: 0.951, accuracy: 0.793\n",
      "epoch 12 iter 60, loss: 0.865, accuracy: 0.811\n",
      "epoch 12 iter 80, loss: 0.850, accuracy: 0.812\n",
      "epoch 12 iter 100, loss: 0.843, accuracy: 0.806\n",
      "epoch 12 iter 120, loss: 0.894, accuracy: 0.805\n",
      "epoch 12 iter 140, loss: 0.832, accuracy: 0.811\n",
      "epoch 12 iter 160, loss: 0.961, accuracy: 0.806\n",
      "epoch 12 iter 180, loss: 0.918, accuracy: 0.818\n",
      "epoch 12 iter 200, loss: 0.967, accuracy: 0.797\n",
      "epoch 12 iter 220, loss: 0.852, accuracy: 0.807\n",
      "epoch 12 iter 240, loss: 0.841, accuracy: 0.806\n",
      "epoch 12 iter 260, loss: 0.811, accuracy: 0.815\n",
      "epoch 12 iter 280, loss: 0.885, accuracy: 0.808\n",
      "epoch 13 iter 0, loss: 0.849, accuracy: 0.818\n",
      "epoch 13 iter 20, loss: 0.906, accuracy: 0.811\n",
      "epoch 13 iter 40, loss: 0.915, accuracy: 0.815\n",
      "epoch 13 iter 60, loss: 1.033, accuracy: 0.788\n",
      "epoch 13 iter 80, loss: 0.902, accuracy: 0.804\n",
      "epoch 13 iter 100, loss: 0.963, accuracy: 0.796\n",
      "epoch 13 iter 120, loss: 0.935, accuracy: 0.798\n",
      "epoch 13 iter 140, loss: 0.813, accuracy: 0.816\n",
      "epoch 13 iter 160, loss: 1.030, accuracy: 0.807\n",
      "epoch 13 iter 180, loss: 0.903, accuracy: 0.815\n",
      "epoch 13 iter 200, loss: 0.998, accuracy: 0.793\n",
      "epoch 13 iter 220, loss: 0.934, accuracy: 0.803\n",
      "epoch 13 iter 240, loss: 0.869, accuracy: 0.810\n",
      "epoch 13 iter 260, loss: 0.820, accuracy: 0.814\n",
      "epoch 13 iter 280, loss: 0.863, accuracy: 0.809\n",
      "epoch 14 iter 0, loss: 0.979, accuracy: 0.808\n",
      "epoch 14 iter 20, loss: 0.971, accuracy: 0.804\n",
      "epoch 14 iter 40, loss: 0.976, accuracy: 0.808\n",
      "epoch 14 iter 60, loss: 0.975, accuracy: 0.802\n",
      "epoch 14 iter 80, loss: 0.923, accuracy: 0.804\n",
      "epoch 14 iter 100, loss: 0.994, accuracy: 0.807\n",
      "epoch 14 iter 120, loss: 0.935, accuracy: 0.813\n",
      "epoch 14 iter 140, loss: 0.911, accuracy: 0.808\n",
      "epoch 14 iter 160, loss: 1.161, accuracy: 0.792\n",
      "epoch 14 iter 180, loss: 0.959, accuracy: 0.819\n",
      "epoch 14 iter 200, loss: 0.994, accuracy: 0.814\n",
      "epoch 14 iter 220, loss: 0.926, accuracy: 0.812\n",
      "epoch 14 iter 240, loss: 0.894, accuracy: 0.812\n",
      "epoch 14 iter 260, loss: 0.853, accuracy: 0.819\n",
      "epoch 14 iter 280, loss: 0.895, accuracy: 0.812\n",
      "epoch 15 iter 0, loss: 0.859, accuracy: 0.820\n",
      "epoch 15 iter 20, loss: 0.940, accuracy: 0.825\n",
      "epoch 15 iter 40, loss: 1.088, accuracy: 0.806\n",
      "epoch 15 iter 60, loss: 1.010, accuracy: 0.800\n",
      "epoch 15 iter 80, loss: 0.974, accuracy: 0.805\n",
      "epoch 15 iter 100, loss: 1.013, accuracy: 0.811\n",
      "epoch 15 iter 120, loss: 1.015, accuracy: 0.801\n",
      "epoch 15 iter 140, loss: 1.025, accuracy: 0.808\n",
      "epoch 15 iter 160, loss: 1.160, accuracy: 0.802\n",
      "epoch 15 iter 180, loss: 1.083, accuracy: 0.806\n",
      "epoch 15 iter 200, loss: 1.090, accuracy: 0.811\n",
      "epoch 15 iter 220, loss: 1.029, accuracy: 0.799\n",
      "epoch 15 iter 240, loss: 0.967, accuracy: 0.816\n",
      "epoch 15 iter 260, loss: 0.931, accuracy: 0.817\n",
      "epoch 15 iter 280, loss: 0.950, accuracy: 0.816\n",
      "epoch 16 iter 0, loss: 0.898, accuracy: 0.816\n",
      "epoch 16 iter 20, loss: 0.960, accuracy: 0.821\n",
      "epoch 16 iter 40, loss: 1.097, accuracy: 0.812\n",
      "epoch 16 iter 60, loss: 1.151, accuracy: 0.789\n",
      "epoch 16 iter 80, loss: 0.986, accuracy: 0.811\n",
      "epoch 16 iter 100, loss: 0.964, accuracy: 0.817\n",
      "epoch 16 iter 120, loss: 1.034, accuracy: 0.800\n",
      "epoch 16 iter 140, loss: 1.111, accuracy: 0.800\n",
      "epoch 16 iter 160, loss: 1.061, accuracy: 0.806\n",
      "epoch 16 iter 180, loss: 1.079, accuracy: 0.810\n",
      "epoch 16 iter 200, loss: 1.176, accuracy: 0.811\n",
      "epoch 16 iter 220, loss: 1.018, accuracy: 0.813\n",
      "epoch 16 iter 240, loss: 0.991, accuracy: 0.809\n",
      "epoch 16 iter 260, loss: 0.948, accuracy: 0.814\n",
      "epoch 16 iter 280, loss: 1.005, accuracy: 0.820\n",
      "epoch 17 iter 0, loss: 0.927, accuracy: 0.814\n",
      "epoch 17 iter 20, loss: 1.006, accuracy: 0.819\n",
      "epoch 17 iter 40, loss: 1.110, accuracy: 0.814\n",
      "epoch 17 iter 60, loss: 1.146, accuracy: 0.801\n",
      "epoch 17 iter 80, loss: 1.089, accuracy: 0.809\n",
      "epoch 17 iter 100, loss: 1.052, accuracy: 0.809\n",
      "epoch 17 iter 120, loss: 1.208, accuracy: 0.772\n",
      "epoch 17 iter 140, loss: 1.120, accuracy: 0.810\n",
      "epoch 17 iter 160, loss: 1.065, accuracy: 0.812\n",
      "epoch 17 iter 180, loss: 1.095, accuracy: 0.819\n",
      "epoch 17 iter 200, loss: 1.218, accuracy: 0.796\n",
      "epoch 17 iter 220, loss: 1.092, accuracy: 0.810\n",
      "epoch 17 iter 240, loss: 0.958, accuracy: 0.809\n",
      "epoch 17 iter 260, loss: 0.994, accuracy: 0.813\n",
      "epoch 17 iter 280, loss: 1.078, accuracy: 0.820\n",
      "epoch 18 iter 0, loss: 0.956, accuracy: 0.820\n",
      "epoch 18 iter 20, loss: 1.083, accuracy: 0.818\n",
      "epoch 18 iter 40, loss: 1.218, accuracy: 0.801\n",
      "epoch 18 iter 60, loss: 1.224, accuracy: 0.802\n",
      "epoch 18 iter 80, loss: 1.143, accuracy: 0.807\n",
      "epoch 18 iter 100, loss: 1.133, accuracy: 0.804\n",
      "epoch 18 iter 120, loss: 1.145, accuracy: 0.793\n",
      "epoch 18 iter 140, loss: 1.100, accuracy: 0.816\n",
      "epoch 18 iter 160, loss: 1.011, accuracy: 0.815\n",
      "epoch 18 iter 180, loss: 1.031, accuracy: 0.820\n",
      "epoch 18 iter 200, loss: 1.239, accuracy: 0.798\n",
      "epoch 18 iter 220, loss: 1.113, accuracy: 0.804\n",
      "epoch 18 iter 240, loss: 1.075, accuracy: 0.799\n",
      "epoch 18 iter 260, loss: 1.055, accuracy: 0.806\n",
      "epoch 18 iter 280, loss: 1.132, accuracy: 0.816\n",
      "epoch 19 iter 0, loss: 1.029, accuracy: 0.818\n",
      "epoch 19 iter 20, loss: 1.148, accuracy: 0.814\n",
      "epoch 19 iter 40, loss: 1.316, accuracy: 0.786\n",
      "epoch 19 iter 60, loss: 1.226, accuracy: 0.809\n",
      "epoch 19 iter 80, loss: 1.048, accuracy: 0.815\n",
      "epoch 19 iter 100, loss: 1.163, accuracy: 0.803\n",
      "epoch 19 iter 120, loss: 1.098, accuracy: 0.806\n",
      "epoch 19 iter 140, loss: 1.071, accuracy: 0.812\n",
      "epoch 19 iter 160, loss: 1.105, accuracy: 0.821\n",
      "epoch 19 iter 180, loss: 1.122, accuracy: 0.820\n",
      "epoch 19 iter 200, loss: 1.128, accuracy: 0.821\n",
      "epoch 19 iter 220, loss: 1.120, accuracy: 0.810\n",
      "epoch 19 iter 240, loss: 1.085, accuracy: 0.806\n",
      "epoch 19 iter 260, loss: 1.140, accuracy: 0.813\n",
      "epoch 19 iter 280, loss: 1.147, accuracy: 0.818\n",
      "epoch 20 iter 0, loss: 1.057, accuracy: 0.822\n",
      "epoch 20 iter 20, loss: 1.136, accuracy: 0.818\n",
      "epoch 20 iter 40, loss: 1.365, accuracy: 0.783\n",
      "epoch 20 iter 60, loss: 1.298, accuracy: 0.804\n",
      "epoch 20 iter 80, loss: 1.139, accuracy: 0.813\n",
      "epoch 20 iter 100, loss: 1.331, accuracy: 0.788\n",
      "epoch 20 iter 120, loss: 1.205, accuracy: 0.802\n",
      "epoch 20 iter 140, loss: 1.159, accuracy: 0.814\n",
      "epoch 20 iter 160, loss: 1.187, accuracy: 0.816\n",
      "epoch 20 iter 180, loss: 1.178, accuracy: 0.820\n",
      "epoch 20 iter 200, loss: 1.358, accuracy: 0.809\n",
      "epoch 20 iter 220, loss: 1.218, accuracy: 0.807\n",
      "epoch 20 iter 240, loss: 1.169, accuracy: 0.804\n",
      "epoch 20 iter 260, loss: 1.176, accuracy: 0.814\n",
      "epoch 20 iter 280, loss: 1.271, accuracy: 0.812\n",
      "epoch 21 iter 0, loss: 1.151, accuracy: 0.813\n",
      "epoch 21 iter 20, loss: 1.211, accuracy: 0.823\n",
      "epoch 21 iter 40, loss: 1.366, accuracy: 0.803\n",
      "epoch 21 iter 60, loss: 1.350, accuracy: 0.806\n",
      "epoch 21 iter 80, loss: 1.219, accuracy: 0.816\n",
      "epoch 21 iter 100, loss: 1.359, accuracy: 0.809\n",
      "epoch 21 iter 120, loss: 1.292, accuracy: 0.807\n",
      "epoch 21 iter 140, loss: 1.202, accuracy: 0.816\n",
      "epoch 21 iter 160, loss: 1.208, accuracy: 0.817\n",
      "epoch 21 iter 180, loss: 1.335, accuracy: 0.817\n",
      "epoch 21 iter 200, loss: 1.297, accuracy: 0.820\n",
      "epoch 21 iter 220, loss: 1.452, accuracy: 0.803\n",
      "epoch 21 iter 240, loss: 1.260, accuracy: 0.809\n",
      "epoch 21 iter 260, loss: 1.261, accuracy: 0.810\n",
      "epoch 21 iter 280, loss: 1.233, accuracy: 0.818\n",
      "epoch 22 iter 0, loss: 1.236, accuracy: 0.809\n",
      "epoch 22 iter 20, loss: 1.269, accuracy: 0.820\n",
      "epoch 22 iter 40, loss: 1.324, accuracy: 0.808\n",
      "epoch 22 iter 60, loss: 1.400, accuracy: 0.805\n",
      "epoch 22 iter 80, loss: 1.264, accuracy: 0.808\n",
      "epoch 22 iter 100, loss: 1.412, accuracy: 0.810\n",
      "epoch 22 iter 120, loss: 1.387, accuracy: 0.802\n",
      "epoch 22 iter 140, loss: 1.220, accuracy: 0.817\n",
      "epoch 22 iter 160, loss: 1.266, accuracy: 0.821\n",
      "epoch 22 iter 180, loss: 1.368, accuracy: 0.816\n",
      "epoch 22 iter 200, loss: 1.372, accuracy: 0.823\n",
      "epoch 22 iter 220, loss: 1.503, accuracy: 0.800\n",
      "epoch 22 iter 240, loss: 1.340, accuracy: 0.803\n",
      "epoch 22 iter 260, loss: 1.311, accuracy: 0.811\n",
      "epoch 22 iter 280, loss: 1.313, accuracy: 0.814\n",
      "epoch 23 iter 0, loss: 1.233, accuracy: 0.819\n",
      "epoch 23 iter 20, loss: 1.296, accuracy: 0.816\n",
      "epoch 23 iter 40, loss: 1.443, accuracy: 0.809\n",
      "epoch 23 iter 60, loss: 1.571, accuracy: 0.801\n",
      "epoch 23 iter 80, loss: 1.437, accuracy: 0.798\n",
      "epoch 23 iter 100, loss: 1.458, accuracy: 0.814\n",
      "epoch 23 iter 120, loss: 1.368, accuracy: 0.806\n",
      "epoch 23 iter 140, loss: 1.360, accuracy: 0.813\n",
      "epoch 23 iter 160, loss: 1.373, accuracy: 0.814\n",
      "epoch 23 iter 180, loss: 1.317, accuracy: 0.815\n",
      "epoch 23 iter 200, loss: 1.346, accuracy: 0.816\n",
      "epoch 23 iter 220, loss: 1.680, accuracy: 0.789\n",
      "epoch 23 iter 240, loss: 1.415, accuracy: 0.817\n",
      "epoch 23 iter 260, loss: 1.367, accuracy: 0.814\n",
      "epoch 23 iter 280, loss: 1.415, accuracy: 0.813\n",
      "epoch 24 iter 0, loss: 1.349, accuracy: 0.819\n",
      "epoch 24 iter 20, loss: 1.364, accuracy: 0.820\n",
      "epoch 24 iter 40, loss: 1.568, accuracy: 0.811\n",
      "epoch 24 iter 60, loss: 1.824, accuracy: 0.782\n",
      "epoch 24 iter 80, loss: 1.466, accuracy: 0.799\n",
      "epoch 24 iter 100, loss: 1.555, accuracy: 0.810\n",
      "epoch 24 iter 120, loss: 1.471, accuracy: 0.803\n",
      "epoch 24 iter 140, loss: 1.449, accuracy: 0.804\n",
      "epoch 24 iter 160, loss: 1.475, accuracy: 0.814\n",
      "epoch 24 iter 180, loss: 1.445, accuracy: 0.814\n",
      "epoch 24 iter 200, loss: 1.511, accuracy: 0.819\n",
      "epoch 24 iter 220, loss: 1.690, accuracy: 0.792\n",
      "epoch 24 iter 240, loss: 1.433, accuracy: 0.807\n",
      "epoch 24 iter 260, loss: 1.517, accuracy: 0.810\n",
      "epoch 24 iter 280, loss: 1.580, accuracy: 0.810\n",
      "epoch 25 iter 0, loss: 1.426, accuracy: 0.810\n",
      "epoch 25 iter 20, loss: 1.473, accuracy: 0.816\n",
      "epoch 25 iter 40, loss: 1.574, accuracy: 0.805\n",
      "epoch 25 iter 60, loss: 1.778, accuracy: 0.793\n",
      "epoch 25 iter 80, loss: 1.520, accuracy: 0.809\n",
      "epoch 25 iter 100, loss: 1.497, accuracy: 0.817\n",
      "epoch 25 iter 120, loss: 1.381, accuracy: 0.812\n",
      "epoch 25 iter 140, loss: 1.534, accuracy: 0.807\n",
      "epoch 25 iter 160, loss: 1.573, accuracy: 0.820\n",
      "epoch 25 iter 180, loss: 1.569, accuracy: 0.813\n",
      "epoch 25 iter 200, loss: 1.516, accuracy: 0.825\n",
      "epoch 25 iter 220, loss: 1.856, accuracy: 0.788\n",
      "epoch 25 iter 240, loss: 1.564, accuracy: 0.809\n",
      "epoch 25 iter 260, loss: 1.562, accuracy: 0.797\n",
      "epoch 25 iter 280, loss: 1.642, accuracy: 0.806\n",
      "epoch 26 iter 0, loss: 1.508, accuracy: 0.813\n",
      "epoch 26 iter 20, loss: 1.701, accuracy: 0.806\n",
      "epoch 26 iter 40, loss: 1.653, accuracy: 0.811\n",
      "epoch 26 iter 60, loss: 1.765, accuracy: 0.804\n",
      "epoch 26 iter 80, loss: 1.621, accuracy: 0.817\n",
      "epoch 26 iter 100, loss: 1.673, accuracy: 0.814\n",
      "epoch 26 iter 120, loss: 1.444, accuracy: 0.805\n",
      "epoch 26 iter 140, loss: 1.511, accuracy: 0.812\n",
      "epoch 26 iter 160, loss: 1.596, accuracy: 0.819\n",
      "epoch 26 iter 180, loss: 1.556, accuracy: 0.820\n",
      "epoch 26 iter 200, loss: 1.617, accuracy: 0.820\n",
      "epoch 26 iter 220, loss: 1.676, accuracy: 0.799\n",
      "epoch 26 iter 240, loss: 1.480, accuracy: 0.795\n",
      "epoch 26 iter 260, loss: 1.460, accuracy: 0.810\n",
      "epoch 26 iter 280, loss: 1.545, accuracy: 0.821\n",
      "epoch 27 iter 0, loss: 1.506, accuracy: 0.821\n",
      "epoch 27 iter 20, loss: 1.585, accuracy: 0.815\n",
      "epoch 27 iter 40, loss: 1.625, accuracy: 0.815\n",
      "epoch 27 iter 60, loss: 1.624, accuracy: 0.807\n",
      "epoch 27 iter 80, loss: 1.525, accuracy: 0.815\n",
      "epoch 27 iter 100, loss: 1.745, accuracy: 0.803\n",
      "epoch 27 iter 120, loss: 1.513, accuracy: 0.810\n",
      "epoch 27 iter 140, loss: 1.575, accuracy: 0.808\n",
      "epoch 27 iter 160, loss: 1.905, accuracy: 0.807\n",
      "epoch 27 iter 180, loss: 1.637, accuracy: 0.819\n",
      "epoch 27 iter 200, loss: 1.694, accuracy: 0.812\n",
      "epoch 27 iter 220, loss: 1.731, accuracy: 0.804\n",
      "epoch 27 iter 240, loss: 1.707, accuracy: 0.806\n",
      "epoch 27 iter 260, loss: 1.557, accuracy: 0.817\n",
      "epoch 27 iter 280, loss: 1.723, accuracy: 0.812\n",
      "epoch 28 iter 0, loss: 1.539, accuracy: 0.824\n",
      "epoch 28 iter 20, loss: 1.569, accuracy: 0.819\n",
      "epoch 28 iter 40, loss: 1.795, accuracy: 0.805\n",
      "epoch 28 iter 60, loss: 1.797, accuracy: 0.807\n",
      "epoch 28 iter 80, loss: 1.556, accuracy: 0.813\n",
      "epoch 28 iter 100, loss: 1.684, accuracy: 0.815\n",
      "epoch 28 iter 120, loss: 1.483, accuracy: 0.816\n",
      "epoch 28 iter 140, loss: 1.567, accuracy: 0.809\n",
      "epoch 28 iter 160, loss: 1.790, accuracy: 0.816\n",
      "epoch 28 iter 180, loss: 1.616, accuracy: 0.825\n",
      "epoch 28 iter 200, loss: 1.536, accuracy: 0.826\n",
      "epoch 28 iter 220, loss: 1.946, accuracy: 0.803\n",
      "epoch 28 iter 240, loss: 1.749, accuracy: 0.819\n",
      "epoch 28 iter 260, loss: 1.619, accuracy: 0.817\n",
      "epoch 28 iter 280, loss: 1.702, accuracy: 0.816\n",
      "epoch 29 iter 0, loss: 1.605, accuracy: 0.822\n",
      "epoch 29 iter 20, loss: 1.675, accuracy: 0.812\n",
      "epoch 29 iter 40, loss: 1.937, accuracy: 0.796\n",
      "epoch 29 iter 60, loss: 1.865, accuracy: 0.801\n",
      "epoch 29 iter 80, loss: 1.706, accuracy: 0.804\n",
      "epoch 29 iter 100, loss: 1.875, accuracy: 0.807\n",
      "epoch 29 iter 120, loss: 1.655, accuracy: 0.820\n",
      "epoch 29 iter 140, loss: 1.838, accuracy: 0.799\n",
      "epoch 29 iter 160, loss: 1.959, accuracy: 0.811\n",
      "epoch 29 iter 180, loss: 1.808, accuracy: 0.816\n",
      "epoch 29 iter 200, loss: 1.809, accuracy: 0.817\n",
      "epoch 29 iter 220, loss: 1.943, accuracy: 0.809\n",
      "epoch 29 iter 240, loss: 1.899, accuracy: 0.811\n",
      "epoch 29 iter 260, loss: 1.689, accuracy: 0.815\n",
      "epoch 29 iter 280, loss: 1.806, accuracy: 0.812\n",
      "epoch 30 iter 0, loss: 1.702, accuracy: 0.816\n",
      "epoch 30 iter 20, loss: 1.576, accuracy: 0.821\n",
      "epoch 30 iter 40, loss: 1.930, accuracy: 0.801\n",
      "epoch 30 iter 60, loss: 1.809, accuracy: 0.802\n",
      "epoch 30 iter 80, loss: 1.759, accuracy: 0.792\n",
      "epoch 30 iter 100, loss: 1.846, accuracy: 0.811\n",
      "epoch 30 iter 120, loss: 1.656, accuracy: 0.820\n",
      "epoch 30 iter 140, loss: 1.755, accuracy: 0.814\n",
      "epoch 30 iter 160, loss: 1.997, accuracy: 0.808\n",
      "epoch 30 iter 180, loss: 1.805, accuracy: 0.811\n",
      "epoch 30 iter 200, loss: 1.935, accuracy: 0.821\n",
      "epoch 30 iter 220, loss: 2.108, accuracy: 0.812\n",
      "epoch 30 iter 240, loss: 1.970, accuracy: 0.810\n",
      "epoch 30 iter 260, loss: 1.728, accuracy: 0.809\n",
      "epoch 30 iter 280, loss: 2.106, accuracy: 0.803\n",
      "epoch 31 iter 0, loss: 1.805, accuracy: 0.814\n",
      "epoch 31 iter 20, loss: 1.641, accuracy: 0.825\n",
      "epoch 31 iter 40, loss: 2.047, accuracy: 0.802\n",
      "epoch 31 iter 60, loss: 1.805, accuracy: 0.805\n",
      "epoch 31 iter 80, loss: 1.765, accuracy: 0.786\n",
      "epoch 31 iter 100, loss: 1.968, accuracy: 0.810\n",
      "epoch 31 iter 120, loss: 1.840, accuracy: 0.814\n",
      "epoch 31 iter 140, loss: 1.870, accuracy: 0.815\n",
      "epoch 31 iter 160, loss: 2.282, accuracy: 0.805\n",
      "epoch 31 iter 180, loss: 1.874, accuracy: 0.812\n",
      "epoch 31 iter 200, loss: 2.095, accuracy: 0.812\n",
      "epoch 31 iter 220, loss: 2.198, accuracy: 0.812\n",
      "epoch 31 iter 240, loss: 1.704, accuracy: 0.817\n",
      "epoch 31 iter 260, loss: 1.713, accuracy: 0.819\n",
      "epoch 31 iter 280, loss: 2.380, accuracy: 0.796\n",
      "epoch 32 iter 0, loss: 1.868, accuracy: 0.814\n",
      "epoch 32 iter 20, loss: 1.734, accuracy: 0.820\n",
      "epoch 32 iter 40, loss: 2.000, accuracy: 0.804\n",
      "epoch 32 iter 60, loss: 1.805, accuracy: 0.805\n",
      "epoch 32 iter 80, loss: 1.995, accuracy: 0.793\n",
      "epoch 32 iter 100, loss: 2.043, accuracy: 0.805\n",
      "epoch 32 iter 120, loss: 1.836, accuracy: 0.819\n",
      "epoch 32 iter 140, loss: 1.882, accuracy: 0.815\n",
      "epoch 32 iter 160, loss: 2.194, accuracy: 0.814\n",
      "epoch 32 iter 180, loss: 1.846, accuracy: 0.815\n",
      "epoch 32 iter 200, loss: 2.372, accuracy: 0.801\n",
      "epoch 32 iter 220, loss: 2.116, accuracy: 0.817\n",
      "epoch 32 iter 240, loss: 1.900, accuracy: 0.817\n",
      "epoch 32 iter 260, loss: 1.814, accuracy: 0.818\n",
      "epoch 32 iter 280, loss: 2.391, accuracy: 0.805\n",
      "epoch 33 iter 0, loss: 1.825, accuracy: 0.818\n",
      "epoch 33 iter 20, loss: 1.797, accuracy: 0.816\n",
      "epoch 33 iter 40, loss: 2.032, accuracy: 0.808\n",
      "epoch 33 iter 60, loss: 1.945, accuracy: 0.813\n",
      "epoch 33 iter 80, loss: 2.050, accuracy: 0.810\n",
      "epoch 33 iter 100, loss: 2.249, accuracy: 0.788\n",
      "epoch 33 iter 120, loss: 2.001, accuracy: 0.807\n",
      "epoch 33 iter 140, loss: 2.258, accuracy: 0.810\n",
      "epoch 33 iter 160, loss: 2.343, accuracy: 0.804\n",
      "epoch 33 iter 180, loss: 1.895, accuracy: 0.800\n",
      "epoch 33 iter 200, loss: 2.577, accuracy: 0.798\n",
      "epoch 33 iter 220, loss: 2.284, accuracy: 0.801\n",
      "epoch 33 iter 240, loss: 1.920, accuracy: 0.812\n",
      "epoch 33 iter 260, loss: 1.899, accuracy: 0.822\n",
      "epoch 33 iter 280, loss: 2.146, accuracy: 0.813\n",
      "epoch 34 iter 0, loss: 2.178, accuracy: 0.812\n",
      "epoch 34 iter 20, loss: 1.958, accuracy: 0.819\n",
      "epoch 34 iter 40, loss: 2.283, accuracy: 0.794\n",
      "epoch 34 iter 60, loss: 1.982, accuracy: 0.804\n",
      "epoch 34 iter 80, loss: 2.146, accuracy: 0.819\n",
      "epoch 34 iter 100, loss: 2.227, accuracy: 0.804\n",
      "epoch 34 iter 120, loss: 2.106, accuracy: 0.802\n",
      "epoch 34 iter 140, loss: 2.047, accuracy: 0.817\n",
      "epoch 34 iter 160, loss: 2.036, accuracy: 0.816\n",
      "epoch 34 iter 180, loss: 2.073, accuracy: 0.804\n",
      "epoch 34 iter 200, loss: 2.428, accuracy: 0.807\n",
      "epoch 34 iter 220, loss: 2.607, accuracy: 0.795\n",
      "epoch 34 iter 240, loss: 2.156, accuracy: 0.801\n",
      "epoch 34 iter 260, loss: 2.070, accuracy: 0.816\n",
      "epoch 34 iter 280, loss: 2.054, accuracy: 0.816\n",
      "epoch 35 iter 0, loss: 2.349, accuracy: 0.809\n",
      "epoch 35 iter 20, loss: 1.986, accuracy: 0.813\n",
      "epoch 35 iter 40, loss: 2.683, accuracy: 0.764\n",
      "epoch 35 iter 60, loss: 2.286, accuracy: 0.802\n",
      "epoch 35 iter 80, loss: 2.207, accuracy: 0.815\n",
      "epoch 35 iter 100, loss: 2.151, accuracy: 0.811\n",
      "epoch 35 iter 120, loss: 2.090, accuracy: 0.814\n",
      "epoch 35 iter 140, loss: 2.245, accuracy: 0.815\n",
      "epoch 35 iter 160, loss: 2.251, accuracy: 0.816\n",
      "epoch 35 iter 180, loss: 2.024, accuracy: 0.813\n",
      "epoch 35 iter 200, loss: 2.734, accuracy: 0.808\n",
      "epoch 35 iter 220, loss: 2.374, accuracy: 0.814\n",
      "epoch 35 iter 240, loss: 2.208, accuracy: 0.793\n",
      "epoch 35 iter 260, loss: 2.109, accuracy: 0.825\n",
      "epoch 35 iter 280, loss: 2.264, accuracy: 0.819\n",
      "epoch 36 iter 0, loss: 2.481, accuracy: 0.805\n",
      "epoch 36 iter 20, loss: 2.113, accuracy: 0.813\n",
      "epoch 36 iter 40, loss: 2.672, accuracy: 0.756\n",
      "epoch 36 iter 60, loss: 2.287, accuracy: 0.790\n",
      "epoch 36 iter 80, loss: 2.376, accuracy: 0.813\n",
      "epoch 36 iter 100, loss: 2.105, accuracy: 0.816\n",
      "epoch 36 iter 120, loss: 2.159, accuracy: 0.811\n",
      "epoch 36 iter 140, loss: 2.142, accuracy: 0.815\n",
      "epoch 36 iter 160, loss: 2.514, accuracy: 0.815\n",
      "epoch 36 iter 180, loss: 2.191, accuracy: 0.817\n",
      "epoch 36 iter 200, loss: 2.593, accuracy: 0.812\n",
      "epoch 36 iter 220, loss: 2.410, accuracy: 0.807\n",
      "epoch 36 iter 240, loss: 2.113, accuracy: 0.803\n",
      "epoch 36 iter 260, loss: 2.121, accuracy: 0.825\n",
      "epoch 36 iter 280, loss: 2.192, accuracy: 0.827\n",
      "epoch 37 iter 0, loss: 2.339, accuracy: 0.826\n",
      "epoch 37 iter 20, loss: 2.132, accuracy: 0.817\n",
      "epoch 37 iter 40, loss: 3.128, accuracy: 0.738\n",
      "epoch 37 iter 60, loss: 2.204, accuracy: 0.795\n",
      "epoch 37 iter 80, loss: 2.370, accuracy: 0.814\n",
      "epoch 37 iter 100, loss: 2.245, accuracy: 0.817\n",
      "epoch 37 iter 120, loss: 2.054, accuracy: 0.818\n",
      "epoch 37 iter 140, loss: 2.151, accuracy: 0.813\n",
      "epoch 37 iter 160, loss: 2.173, accuracy: 0.816\n",
      "epoch 37 iter 180, loss: 2.194, accuracy: 0.810\n",
      "epoch 37 iter 200, loss: 2.674, accuracy: 0.812\n",
      "epoch 37 iter 220, loss: 2.474, accuracy: 0.811\n",
      "epoch 37 iter 240, loss: 2.312, accuracy: 0.807\n",
      "epoch 37 iter 260, loss: 2.202, accuracy: 0.819\n",
      "epoch 37 iter 280, loss: 2.153, accuracy: 0.825\n",
      "epoch 38 iter 0, loss: 2.297, accuracy: 0.821\n",
      "epoch 38 iter 20, loss: 2.098, accuracy: 0.817\n",
      "epoch 38 iter 40, loss: 3.313, accuracy: 0.744\n",
      "epoch 38 iter 60, loss: 2.261, accuracy: 0.799\n",
      "epoch 38 iter 80, loss: 2.564, accuracy: 0.804\n",
      "epoch 38 iter 100, loss: 2.204, accuracy: 0.819\n",
      "epoch 38 iter 120, loss: 2.204, accuracy: 0.809\n",
      "epoch 38 iter 140, loss: 2.389, accuracy: 0.816\n",
      "epoch 38 iter 160, loss: 2.350, accuracy: 0.818\n",
      "epoch 38 iter 180, loss: 2.208, accuracy: 0.817\n",
      "epoch 38 iter 200, loss: 2.567, accuracy: 0.818\n",
      "epoch 38 iter 220, loss: 2.460, accuracy: 0.819\n",
      "epoch 38 iter 240, loss: 2.313, accuracy: 0.805\n",
      "epoch 38 iter 260, loss: 2.293, accuracy: 0.823\n",
      "epoch 38 iter 280, loss: 2.598, accuracy: 0.812\n",
      "epoch 39 iter 0, loss: 2.620, accuracy: 0.817\n",
      "epoch 39 iter 20, loss: 2.164, accuracy: 0.825\n",
      "epoch 39 iter 40, loss: 3.323, accuracy: 0.725\n",
      "epoch 39 iter 60, loss: 2.454, accuracy: 0.795\n",
      "epoch 39 iter 80, loss: 2.543, accuracy: 0.813\n",
      "epoch 39 iter 100, loss: 2.372, accuracy: 0.825\n",
      "epoch 39 iter 120, loss: 2.235, accuracy: 0.818\n",
      "epoch 39 iter 140, loss: 2.352, accuracy: 0.818\n",
      "epoch 39 iter 160, loss: 2.337, accuracy: 0.818\n",
      "epoch 39 iter 180, loss: 2.266, accuracy: 0.820\n",
      "epoch 39 iter 200, loss: 2.580, accuracy: 0.818\n",
      "epoch 39 iter 220, loss: 2.437, accuracy: 0.819\n",
      "epoch 39 iter 240, loss: 2.335, accuracy: 0.806\n",
      "epoch 39 iter 260, loss: 2.307, accuracy: 0.824\n",
      "epoch 39 iter 280, loss: 2.617, accuracy: 0.812\n",
      "epoch 40 iter 0, loss: 2.646, accuracy: 0.814\n",
      "epoch 40 iter 20, loss: 2.326, accuracy: 0.824\n",
      "epoch 40 iter 40, loss: 3.209, accuracy: 0.754\n",
      "epoch 40 iter 60, loss: 2.572, accuracy: 0.788\n",
      "epoch 40 iter 80, loss: 2.791, accuracy: 0.803\n",
      "epoch 40 iter 100, loss: 2.472, accuracy: 0.819\n",
      "epoch 40 iter 120, loss: 2.365, accuracy: 0.814\n",
      "epoch 40 iter 140, loss: 2.618, accuracy: 0.809\n",
      "epoch 40 iter 160, loss: 2.345, accuracy: 0.816\n",
      "epoch 40 iter 180, loss: 2.348, accuracy: 0.820\n",
      "epoch 40 iter 200, loss: 2.561, accuracy: 0.816\n",
      "epoch 40 iter 220, loss: 2.650, accuracy: 0.818\n",
      "epoch 40 iter 240, loss: 2.500, accuracy: 0.812\n",
      "epoch 40 iter 260, loss: 2.526, accuracy: 0.824\n",
      "epoch 40 iter 280, loss: 2.539, accuracy: 0.811\n",
      "epoch 41 iter 0, loss: 2.537, accuracy: 0.821\n",
      "epoch 41 iter 20, loss: 2.277, accuracy: 0.822\n",
      "epoch 41 iter 40, loss: 2.984, accuracy: 0.782\n",
      "epoch 41 iter 60, loss: 2.412, accuracy: 0.784\n",
      "epoch 41 iter 80, loss: 2.516, accuracy: 0.808\n",
      "epoch 41 iter 100, loss: 2.192, accuracy: 0.820\n",
      "epoch 41 iter 120, loss: 2.160, accuracy: 0.818\n",
      "epoch 41 iter 140, loss: 2.242, accuracy: 0.822\n",
      "epoch 41 iter 160, loss: 2.301, accuracy: 0.818\n",
      "epoch 41 iter 180, loss: 2.232, accuracy: 0.814\n",
      "epoch 41 iter 200, loss: 2.253, accuracy: 0.819\n",
      "epoch 41 iter 220, loss: 2.579, accuracy: 0.809\n",
      "epoch 41 iter 240, loss: 2.342, accuracy: 0.816\n",
      "epoch 41 iter 260, loss: 2.323, accuracy: 0.815\n",
      "epoch 41 iter 280, loss: 2.270, accuracy: 0.825\n",
      "epoch 42 iter 0, loss: 2.546, accuracy: 0.811\n",
      "epoch 42 iter 20, loss: 2.208, accuracy: 0.823\n",
      "epoch 42 iter 40, loss: 2.789, accuracy: 0.795\n",
      "epoch 42 iter 60, loss: 2.139, accuracy: 0.799\n",
      "epoch 42 iter 80, loss: 2.589, accuracy: 0.806\n",
      "epoch 42 iter 100, loss: 2.378, accuracy: 0.823\n",
      "epoch 42 iter 120, loss: 2.257, accuracy: 0.817\n",
      "epoch 42 iter 140, loss: 2.284, accuracy: 0.821\n",
      "epoch 42 iter 160, loss: 2.591, accuracy: 0.812\n",
      "epoch 42 iter 180, loss: 2.283, accuracy: 0.823\n",
      "epoch 42 iter 200, loss: 2.426, accuracy: 0.823\n",
      "epoch 42 iter 220, loss: 2.640, accuracy: 0.814\n",
      "epoch 42 iter 240, loss: 2.452, accuracy: 0.821\n",
      "epoch 42 iter 260, loss: 2.179, accuracy: 0.818\n",
      "epoch 42 iter 280, loss: 2.377, accuracy: 0.827\n",
      "epoch 43 iter 0, loss: 2.629, accuracy: 0.825\n",
      "epoch 43 iter 20, loss: 2.199, accuracy: 0.830\n",
      "epoch 43 iter 40, loss: 2.680, accuracy: 0.814\n",
      "epoch 43 iter 60, loss: 2.305, accuracy: 0.792\n",
      "epoch 43 iter 80, loss: 2.952, accuracy: 0.795\n",
      "epoch 43 iter 100, loss: 2.314, accuracy: 0.823\n",
      "epoch 43 iter 120, loss: 2.380, accuracy: 0.815\n",
      "epoch 43 iter 140, loss: 2.425, accuracy: 0.823\n",
      "epoch 43 iter 160, loss: 2.538, accuracy: 0.814\n",
      "epoch 43 iter 180, loss: 2.407, accuracy: 0.818\n",
      "epoch 43 iter 200, loss: 2.426, accuracy: 0.817\n",
      "epoch 43 iter 220, loss: 2.590, accuracy: 0.813\n",
      "epoch 43 iter 240, loss: 2.609, accuracy: 0.817\n",
      "epoch 43 iter 260, loss: 2.457, accuracy: 0.814\n",
      "epoch 43 iter 280, loss: 2.340, accuracy: 0.824\n",
      "epoch 44 iter 0, loss: 2.571, accuracy: 0.818\n",
      "epoch 44 iter 20, loss: 2.443, accuracy: 0.830\n",
      "epoch 44 iter 40, loss: 2.898, accuracy: 0.812\n",
      "epoch 44 iter 60, loss: 2.295, accuracy: 0.790\n",
      "epoch 44 iter 80, loss: 2.964, accuracy: 0.796\n",
      "epoch 44 iter 100, loss: 2.569, accuracy: 0.820\n",
      "epoch 44 iter 120, loss: 2.659, accuracy: 0.812\n",
      "epoch 44 iter 140, loss: 2.677, accuracy: 0.826\n",
      "epoch 44 iter 160, loss: 2.641, accuracy: 0.814\n",
      "epoch 44 iter 180, loss: 2.603, accuracy: 0.815\n",
      "epoch 44 iter 200, loss: 2.538, accuracy: 0.815\n",
      "epoch 44 iter 220, loss: 2.860, accuracy: 0.813\n",
      "epoch 44 iter 240, loss: 2.712, accuracy: 0.821\n",
      "epoch 44 iter 260, loss: 2.436, accuracy: 0.820\n",
      "epoch 44 iter 280, loss: 2.465, accuracy: 0.835\n",
      "epoch 45 iter 0, loss: 2.737, accuracy: 0.824\n",
      "epoch 45 iter 20, loss: 2.425, accuracy: 0.830\n",
      "epoch 45 iter 40, loss: 2.906, accuracy: 0.822\n",
      "epoch 45 iter 60, loss: 2.449, accuracy: 0.789\n",
      "epoch 45 iter 80, loss: 2.908, accuracy: 0.800\n",
      "epoch 45 iter 100, loss: 2.840, accuracy: 0.821\n",
      "epoch 45 iter 120, loss: 2.779, accuracy: 0.815\n",
      "epoch 45 iter 140, loss: 2.945, accuracy: 0.823\n",
      "epoch 45 iter 160, loss: 2.806, accuracy: 0.825\n",
      "epoch 45 iter 180, loss: 2.565, accuracy: 0.819\n",
      "epoch 45 iter 200, loss: 2.724, accuracy: 0.817\n",
      "epoch 45 iter 220, loss: 3.036, accuracy: 0.817\n",
      "epoch 45 iter 240, loss: 2.644, accuracy: 0.817\n",
      "epoch 45 iter 260, loss: 2.623, accuracy: 0.815\n",
      "epoch 45 iter 280, loss: 2.620, accuracy: 0.830\n",
      "epoch 46 iter 0, loss: 2.648, accuracy: 0.827\n",
      "epoch 46 iter 20, loss: 2.527, accuracy: 0.830\n",
      "epoch 46 iter 40, loss: 2.839, accuracy: 0.824\n",
      "epoch 46 iter 60, loss: 2.414, accuracy: 0.779\n",
      "epoch 46 iter 80, loss: 2.807, accuracy: 0.802\n",
      "epoch 46 iter 100, loss: 2.778, accuracy: 0.820\n",
      "epoch 46 iter 120, loss: 2.946, accuracy: 0.817\n",
      "epoch 46 iter 140, loss: 2.797, accuracy: 0.827\n",
      "epoch 46 iter 160, loss: 2.841, accuracy: 0.819\n",
      "epoch 46 iter 180, loss: 2.645, accuracy: 0.818\n",
      "epoch 46 iter 200, loss: 2.712, accuracy: 0.819\n",
      "epoch 46 iter 220, loss: 3.261, accuracy: 0.796\n",
      "epoch 46 iter 240, loss: 2.836, accuracy: 0.820\n",
      "epoch 46 iter 260, loss: 2.623, accuracy: 0.819\n",
      "epoch 46 iter 280, loss: 2.641, accuracy: 0.829\n",
      "epoch 47 iter 0, loss: 2.624, accuracy: 0.826\n",
      "epoch 47 iter 20, loss: 2.549, accuracy: 0.825\n",
      "epoch 47 iter 40, loss: 2.969, accuracy: 0.819\n",
      "epoch 47 iter 60, loss: 2.396, accuracy: 0.797\n",
      "epoch 47 iter 80, loss: 2.901, accuracy: 0.797\n",
      "epoch 47 iter 100, loss: 2.971, accuracy: 0.817\n",
      "epoch 47 iter 120, loss: 3.012, accuracy: 0.812\n",
      "epoch 47 iter 140, loss: 2.906, accuracy: 0.822\n",
      "epoch 47 iter 160, loss: 2.728, accuracy: 0.823\n",
      "epoch 47 iter 180, loss: 2.724, accuracy: 0.825\n",
      "epoch 47 iter 200, loss: 2.741, accuracy: 0.822\n",
      "epoch 47 iter 220, loss: 3.535, accuracy: 0.802\n",
      "epoch 47 iter 240, loss: 2.860, accuracy: 0.819\n",
      "epoch 47 iter 260, loss: 2.667, accuracy: 0.821\n",
      "epoch 47 iter 280, loss: 2.681, accuracy: 0.829\n",
      "epoch 48 iter 0, loss: 2.792, accuracy: 0.825\n",
      "epoch 48 iter 20, loss: 2.727, accuracy: 0.828\n",
      "epoch 48 iter 40, loss: 3.034, accuracy: 0.817\n",
      "epoch 48 iter 60, loss: 2.804, accuracy: 0.796\n",
      "epoch 48 iter 80, loss: 2.887, accuracy: 0.780\n",
      "epoch 48 iter 100, loss: 3.328, accuracy: 0.824\n",
      "epoch 48 iter 120, loss: 3.111, accuracy: 0.820\n",
      "epoch 48 iter 140, loss: 3.149, accuracy: 0.823\n",
      "epoch 48 iter 160, loss: 2.982, accuracy: 0.828\n",
      "epoch 48 iter 180, loss: 3.023, accuracy: 0.825\n",
      "epoch 48 iter 200, loss: 2.976, accuracy: 0.820\n",
      "epoch 48 iter 220, loss: 3.266, accuracy: 0.812\n",
      "epoch 48 iter 240, loss: 2.809, accuracy: 0.815\n",
      "epoch 48 iter 260, loss: 2.816, accuracy: 0.820\n",
      "epoch 48 iter 280, loss: 2.755, accuracy: 0.832\n",
      "epoch 49 iter 0, loss: 2.858, accuracy: 0.823\n",
      "epoch 49 iter 20, loss: 2.953, accuracy: 0.828\n",
      "epoch 49 iter 40, loss: 3.151, accuracy: 0.823\n",
      "epoch 49 iter 60, loss: 2.583, accuracy: 0.802\n",
      "epoch 49 iter 80, loss: 3.089, accuracy: 0.787\n",
      "epoch 49 iter 100, loss: 3.033, accuracy: 0.822\n",
      "epoch 49 iter 120, loss: 3.346, accuracy: 0.809\n",
      "epoch 49 iter 140, loss: 3.211, accuracy: 0.821\n",
      "epoch 49 iter 160, loss: 2.987, accuracy: 0.822\n",
      "epoch 49 iter 180, loss: 3.183, accuracy: 0.822\n",
      "epoch 49 iter 200, loss: 3.181, accuracy: 0.819\n",
      "epoch 49 iter 220, loss: 3.231, accuracy: 0.824\n",
      "epoch 49 iter 240, loss: 2.784, accuracy: 0.822\n",
      "epoch 49 iter 260, loss: 2.901, accuracy: 0.816\n",
      "epoch 49 iter 280, loss: 3.120, accuracy: 0.822\n"
     ]
    }
   ],
   "source": [
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}\n",
    "    \n",
    "model_dict = apply_classification_loss(SVHN_net_v0)\n",
    "train_model(model_dict, dataset_generators, epoch_n=50, print_every=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 Understanding the CNN Architecture\n",
    "(7 points)\n",
    "\n",
    "Explain the definition of the following terms. What is the corresponding setting in our SVHN net? Are there any other choices?\n",
    "\n",
    "  - Stride\n",
    "  - Padding\n",
    "  - Non-linearity\n",
    "  - Pooling\n",
    "  - Optimizer\n",
    "  - Learning rate\n",
    "  - Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Double click here to add your answer]**\n",
    "\n",
    "**Stride and Padding**\n",
    "\n",
    "On the conv layers, we need to operate the filters. There are 2 paremeters that we can control to modify the conv layer behaviors. They are 'Stride' and 'Padding'. The amount by which the filter shifts is the stride. By setting stride to 1, the filter convolves around the input volume by shifting one unit at a time. If we use three 5*5*3 filters in a 32*32*3 input, we will get an output of 28*28*3. There will be a spatial dimensions decreasion. If we want to preserve as much information about the original input volume, we can apply a size 2 zerro padding to the input. So that after the 5*5*3 padding with stride = 1, we can still get an output of 32*32*3.\n",
    "\n",
    "**Non-linearity**\n",
    "\n",
    "Non-linearity or activation function is very important for the CNN. For example, when we using linear classification to compute the scores for different categories, we will use formula $s = Wx$. However, when we use neural network, we will chose a formula like $s = W_2 \\max(0, W_1x)$ ,where $\\max(0,-)$ is a non-linearity. Without it, the two matrices could be collapsed to a single matrix, and therefore the predicted class scores would again be a linear function of the input. Every activation function (or non-linearity) takes a single number and performs a certain fixed mathematical operation on it. Commly used non-linearity: sigmoid, tanh, Relu, Leaky Relu, Maxout and so on.\n",
    "\n",
    "**Pooling**\n",
    "\n",
    "Sometimes you can choose to add Pooling Layers to your CNN. It is also known as a downsampling layer. For example, using maxpooling, it basically takes a filter (normally of size 2x2) and a stride of the same length. It then applies it to the input volume and outputs the maximum number in every subregion that the filter convolves around. The purpose of using pooling is to reduce the comuptation cost and deal with overfitting.\n",
    "\n",
    "**Learning Rate**\n",
    "\n",
    "Learning rate is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient. new_weight = existing_weight — learning_rate * gradient.\n",
    "\n",
    "**Loss Function**\n",
    "\n",
    "After a score function mapped the raw image pixels to class scores. A loss function is a function measured the quality of a particular set of parameters based on how well the induced scores agreed with the ground truth labels in the training data.\n",
    "\n",
    "**Optimizer**\n",
    "\n",
    "The Goal of optimization is to find the parameters for the lowest loss. Opitimizer defined specific gradient descent ways.\n",
    "\n",
    "**SVHN**\n",
    "\n",
    "Stride: Of conv layers should be default as 1, Of Pooling layer should be 2. You can set the stride to other values but to make sure the result of the conv to be integers, it usually sets as 1. And the stride of pooling usually equals to the size of the pooling filter.\n",
    "\n",
    "Padding: Here is Padding = 'same'. By setting it to 'Same' means that we want the output size is equal to the input size. Since our input size is 32*32*3, and the filter size is 5*5*3, to get the same size output, we need zero padding of size 2. You can also use Padding = 'valid', it means no padding at all.\n",
    "\n",
    "Non-linearity: From 'activation=tf.nn.relu' we can get that we used Relu activation function here. We can also use sigmoid, tanh, Leaky Relu, Maxout and so on.\n",
    "\n",
    "Pooling: pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)\n",
    "         We chose maxpooling here. We can also use 'average pooling' and 'mean pooling'.\n",
    "\n",
    "Opitimizer: tf.train.AdamOptimizer(learning_rate=0.001) We using AdamOptimizer here. And we can also choose GD, SGD, NAdam, Adam with Momentum and so on.\n",
    "\n",
    "Learning Rate: learning_rate=0.001\n",
    "\n",
    "Loss function: losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict), sparse softmax cross entropy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Q1.3 SVHN Net Variations\n",
    "(16 points)\n",
    "\n",
    "Now we vary the structure of the network. To keep things simple, we still use  two identical conv layers, but vary their parameters. \n",
    "\n",
    "Report the final test accuracy on 3 different number of filters, 3 different size of kernels, 3 different number of strides, and 3 different dimension of final fully connected layer. Each time when you vary one parameter, keep the other fixed at the original value. Explain the results.\n",
    "\n",
    "|# of Filter|Accuracy|\n",
    "|--|-------------------------------|\n",
    "| / | / |\n",
    "| / | / |\n",
    "| / | / |\n",
    "\n",
    "|Kernel size|Accuracy|\n",
    "|--|-------------------------------|\n",
    "| / | / |\n",
    "| / | / |\n",
    "| / | / |\n",
    "\n",
    "|Stride|Accuracy|\n",
    "|--|-------------------------------|\n",
    "| / | / |\n",
    "| / | / |\n",
    "| / | / |\n",
    "\n",
    "|FC size|Accuracy|\n",
    "|--|-------------------------------|\n",
    "| / | / |\n",
    "| / | / |\n",
    "| / | / |\n",
    "\n",
    "A template for one sample modification is given below. \n",
    "\n",
    "**Note:** you're welcome to decide how many training epochs to use, if that gets you the same results but faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 98.486, accuracy: 0.184\n",
      "epoch 0 iter 50, loss: 2.245, accuracy: 0.200\n",
      "epoch 0 iter 100, loss: 2.218, accuracy: 0.212\n",
      "epoch 0 iter 150, loss: 2.133, accuracy: 0.255\n",
      "epoch 0 iter 200, loss: 1.534, accuracy: 0.503\n",
      "epoch 0 iter 250, loss: 1.158, accuracy: 0.645\n",
      "epoch 1 iter 0, loss: 1.023, accuracy: 0.694\n",
      "epoch 1 iter 50, loss: 0.932, accuracy: 0.725\n",
      "epoch 1 iter 100, loss: 0.830, accuracy: 0.757\n",
      "epoch 1 iter 150, loss: 0.831, accuracy: 0.755\n",
      "epoch 1 iter 200, loss: 0.782, accuracy: 0.774\n",
      "epoch 1 iter 250, loss: 0.757, accuracy: 0.781\n",
      "epoch 2 iter 0, loss: 0.704, accuracy: 0.801\n",
      "epoch 2 iter 50, loss: 0.718, accuracy: 0.796\n",
      "epoch 2 iter 100, loss: 0.713, accuracy: 0.798\n",
      "epoch 2 iter 150, loss: 0.683, accuracy: 0.805\n",
      "epoch 2 iter 200, loss: 0.681, accuracy: 0.807\n",
      "epoch 2 iter 250, loss: 0.655, accuracy: 0.815\n",
      "epoch 3 iter 0, loss: 0.683, accuracy: 0.811\n",
      "epoch 3 iter 50, loss: 0.680, accuracy: 0.812\n",
      "epoch 3 iter 100, loss: 0.658, accuracy: 0.816\n",
      "epoch 3 iter 150, loss: 0.661, accuracy: 0.816\n",
      "epoch 3 iter 200, loss: 0.650, accuracy: 0.819\n",
      "epoch 3 iter 250, loss: 0.668, accuracy: 0.813\n",
      "epoch 4 iter 0, loss: 0.705, accuracy: 0.813\n",
      "epoch 4 iter 50, loss: 0.656, accuracy: 0.819\n",
      "epoch 4 iter 100, loss: 0.642, accuracy: 0.826\n",
      "epoch 4 iter 150, loss: 0.649, accuracy: 0.829\n",
      "epoch 4 iter 200, loss: 0.644, accuracy: 0.828\n",
      "epoch 4 iter 250, loss: 0.645, accuracy: 0.828\n",
      "epoch 5 iter 0, loss: 0.661, accuracy: 0.826\n",
      "epoch 5 iter 50, loss: 0.659, accuracy: 0.825\n",
      "epoch 5 iter 100, loss: 0.661, accuracy: 0.827\n",
      "epoch 5 iter 150, loss: 0.728, accuracy: 0.826\n",
      "epoch 5 iter 200, loss: 0.684, accuracy: 0.828\n",
      "epoch 5 iter 250, loss: 0.663, accuracy: 0.838\n",
      "epoch 6 iter 0, loss: 0.697, accuracy: 0.827\n",
      "epoch 6 iter 50, loss: 0.669, accuracy: 0.832\n",
      "epoch 6 iter 100, loss: 0.704, accuracy: 0.815\n",
      "epoch 6 iter 150, loss: 0.759, accuracy: 0.825\n",
      "epoch 6 iter 200, loss: 0.725, accuracy: 0.831\n",
      "epoch 6 iter 250, loss: 0.692, accuracy: 0.836\n",
      "epoch 7 iter 0, loss: 0.725, accuracy: 0.829\n",
      "epoch 7 iter 50, loss: 0.720, accuracy: 0.827\n",
      "epoch 7 iter 100, loss: 0.752, accuracy: 0.814\n",
      "epoch 7 iter 150, loss: 0.771, accuracy: 0.825\n",
      "epoch 7 iter 200, loss: 0.775, accuracy: 0.830\n",
      "epoch 7 iter 250, loss: 0.717, accuracy: 0.839\n",
      "epoch 8 iter 0, loss: 0.768, accuracy: 0.824\n",
      "epoch 8 iter 50, loss: 0.786, accuracy: 0.821\n",
      "epoch 8 iter 100, loss: 0.817, accuracy: 0.824\n",
      "epoch 8 iter 150, loss: 0.851, accuracy: 0.824\n",
      "epoch 8 iter 200, loss: 0.777, accuracy: 0.832\n",
      "epoch 8 iter 250, loss: 0.741, accuracy: 0.839\n",
      "epoch 9 iter 0, loss: 0.838, accuracy: 0.815\n",
      "epoch 9 iter 50, loss: 0.863, accuracy: 0.815\n",
      "epoch 9 iter 100, loss: 0.807, accuracy: 0.826\n",
      "epoch 9 iter 150, loss: 0.855, accuracy: 0.826\n",
      "epoch 9 iter 200, loss: 0.770, accuracy: 0.837\n",
      "epoch 9 iter 250, loss: 0.799, accuracy: 0.836\n",
      "epoch 10 iter 0, loss: 0.859, accuracy: 0.824\n",
      "epoch 10 iter 50, loss: 0.908, accuracy: 0.813\n",
      "epoch 10 iter 100, loss: 0.807, accuracy: 0.836\n",
      "epoch 10 iter 150, loss: 0.923, accuracy: 0.813\n",
      "epoch 10 iter 200, loss: 0.822, accuracy: 0.835\n",
      "epoch 10 iter 250, loss: 0.812, accuracy: 0.841\n",
      "epoch 11 iter 0, loss: 0.930, accuracy: 0.817\n",
      "epoch 11 iter 50, loss: 0.917, accuracy: 0.822\n",
      "epoch 11 iter 100, loss: 0.849, accuracy: 0.834\n",
      "epoch 11 iter 150, loss: 0.946, accuracy: 0.819\n",
      "epoch 11 iter 200, loss: 0.890, accuracy: 0.832\n",
      "epoch 11 iter 250, loss: 0.896, accuracy: 0.831\n",
      "epoch 12 iter 0, loss: 0.945, accuracy: 0.824\n",
      "epoch 12 iter 50, loss: 0.971, accuracy: 0.825\n",
      "epoch 12 iter 100, loss: 0.871, accuracy: 0.832\n",
      "epoch 12 iter 150, loss: 0.914, accuracy: 0.827\n",
      "epoch 12 iter 200, loss: 0.955, accuracy: 0.832\n",
      "epoch 12 iter 250, loss: 0.909, accuracy: 0.836\n",
      "epoch 13 iter 0, loss: 0.968, accuracy: 0.829\n",
      "epoch 13 iter 50, loss: 0.993, accuracy: 0.832\n",
      "epoch 13 iter 100, loss: 0.994, accuracy: 0.827\n",
      "epoch 13 iter 150, loss: 1.073, accuracy: 0.817\n",
      "epoch 13 iter 200, loss: 1.047, accuracy: 0.827\n",
      "epoch 13 iter 250, loss: 0.961, accuracy: 0.839\n",
      "epoch 14 iter 0, loss: 1.098, accuracy: 0.822\n",
      "epoch 14 iter 50, loss: 1.045, accuracy: 0.833\n",
      "epoch 14 iter 100, loss: 1.039, accuracy: 0.825\n",
      "epoch 14 iter 150, loss: 1.143, accuracy: 0.821\n",
      "epoch 14 iter 200, loss: 0.989, accuracy: 0.834\n",
      "epoch 14 iter 250, loss: 1.008, accuracy: 0.837\n",
      "epoch 15 iter 0, loss: 1.024, accuracy: 0.838\n",
      "epoch 15 iter 50, loss: 1.101, accuracy: 0.831\n",
      "epoch 15 iter 100, loss: 1.081, accuracy: 0.825\n",
      "epoch 15 iter 150, loss: 1.167, accuracy: 0.831\n",
      "epoch 15 iter 200, loss: 1.057, accuracy: 0.838\n",
      "epoch 15 iter 250, loss: 1.007, accuracy: 0.846\n",
      "epoch 16 iter 0, loss: 1.097, accuracy: 0.830\n",
      "epoch 16 iter 50, loss: 1.234, accuracy: 0.822\n",
      "epoch 16 iter 100, loss: 1.171, accuracy: 0.820\n",
      "epoch 16 iter 150, loss: 1.233, accuracy: 0.822\n",
      "epoch 16 iter 200, loss: 1.116, accuracy: 0.840\n",
      "epoch 16 iter 250, loss: 1.069, accuracy: 0.840\n",
      "epoch 17 iter 0, loss: 1.100, accuracy: 0.833\n",
      "epoch 17 iter 50, loss: 1.291, accuracy: 0.823\n",
      "epoch 17 iter 100, loss: 1.230, accuracy: 0.813\n",
      "epoch 17 iter 150, loss: 1.133, accuracy: 0.836\n",
      "epoch 17 iter 200, loss: 1.112, accuracy: 0.839\n",
      "epoch 17 iter 250, loss: 1.119, accuracy: 0.839\n",
      "epoch 18 iter 0, loss: 1.177, accuracy: 0.823\n",
      "epoch 18 iter 50, loss: 1.354, accuracy: 0.825\n",
      "epoch 18 iter 100, loss: 1.232, accuracy: 0.824\n",
      "epoch 18 iter 150, loss: 1.175, accuracy: 0.839\n",
      "epoch 18 iter 200, loss: 1.168, accuracy: 0.835\n",
      "epoch 18 iter 250, loss: 1.206, accuracy: 0.832\n",
      "epoch 19 iter 0, loss: 1.231, accuracy: 0.828\n",
      "epoch 19 iter 50, loss: 1.381, accuracy: 0.829\n",
      "epoch 19 iter 100, loss: 1.200, accuracy: 0.823\n",
      "epoch 19 iter 150, loss: 1.348, accuracy: 0.830\n",
      "epoch 19 iter 200, loss: 1.226, accuracy: 0.839\n",
      "epoch 19 iter 250, loss: 1.246, accuracy: 0.833\n",
      "epoch 20 iter 0, loss: 1.263, accuracy: 0.834\n",
      "epoch 20 iter 50, loss: 1.361, accuracy: 0.826\n",
      "epoch 20 iter 100, loss: 1.258, accuracy: 0.827\n",
      "epoch 20 iter 150, loss: 1.422, accuracy: 0.830\n",
      "epoch 20 iter 200, loss: 1.296, accuracy: 0.835\n",
      "epoch 20 iter 250, loss: 1.338, accuracy: 0.837\n",
      "epoch 21 iter 0, loss: 1.207, accuracy: 0.840\n",
      "epoch 21 iter 50, loss: 1.374, accuracy: 0.833\n",
      "epoch 21 iter 100, loss: 1.269, accuracy: 0.837\n",
      "epoch 21 iter 150, loss: 1.606, accuracy: 0.826\n",
      "epoch 21 iter 200, loss: 1.379, accuracy: 0.838\n",
      "epoch 21 iter 250, loss: 1.366, accuracy: 0.839\n",
      "epoch 22 iter 0, loss: 1.380, accuracy: 0.835\n",
      "epoch 22 iter 50, loss: 1.396, accuracy: 0.826\n",
      "epoch 22 iter 100, loss: 1.358, accuracy: 0.820\n",
      "epoch 22 iter 150, loss: 1.508, accuracy: 0.831\n",
      "epoch 22 iter 200, loss: 1.484, accuracy: 0.842\n",
      "epoch 22 iter 250, loss: 1.343, accuracy: 0.845\n",
      "epoch 23 iter 0, loss: 1.424, accuracy: 0.841\n",
      "epoch 23 iter 50, loss: 1.558, accuracy: 0.818\n",
      "epoch 23 iter 100, loss: 1.344, accuracy: 0.826\n",
      "epoch 23 iter 150, loss: 1.580, accuracy: 0.827\n",
      "epoch 23 iter 200, loss: 1.476, accuracy: 0.834\n",
      "epoch 23 iter 250, loss: 1.407, accuracy: 0.839\n",
      "epoch 24 iter 0, loss: 1.451, accuracy: 0.845\n",
      "epoch 24 iter 50, loss: 1.675, accuracy: 0.825\n",
      "epoch 24 iter 100, loss: 1.428, accuracy: 0.837\n",
      "epoch 24 iter 150, loss: 1.824, accuracy: 0.820\n",
      "epoch 24 iter 200, loss: 1.667, accuracy: 0.834\n",
      "epoch 24 iter 250, loss: 1.440, accuracy: 0.842\n",
      "epoch 25 iter 0, loss: 1.652, accuracy: 0.835\n",
      "epoch 25 iter 50, loss: 1.716, accuracy: 0.820\n",
      "epoch 25 iter 100, loss: 1.407, accuracy: 0.833\n",
      "epoch 25 iter 150, loss: 1.707, accuracy: 0.827\n",
      "epoch 25 iter 200, loss: 1.745, accuracy: 0.832\n",
      "epoch 25 iter 250, loss: 1.526, accuracy: 0.841\n",
      "epoch 26 iter 0, loss: 1.571, accuracy: 0.838\n",
      "epoch 26 iter 50, loss: 1.882, accuracy: 0.816\n",
      "epoch 26 iter 100, loss: 1.514, accuracy: 0.832\n",
      "epoch 26 iter 150, loss: 1.959, accuracy: 0.826\n",
      "epoch 26 iter 200, loss: 1.781, accuracy: 0.830\n",
      "epoch 26 iter 250, loss: 1.614, accuracy: 0.839\n",
      "epoch 27 iter 0, loss: 1.725, accuracy: 0.839\n",
      "epoch 27 iter 50, loss: 2.096, accuracy: 0.806\n",
      "epoch 27 iter 100, loss: 1.553, accuracy: 0.828\n",
      "epoch 27 iter 150, loss: 1.897, accuracy: 0.824\n",
      "epoch 27 iter 200, loss: 1.855, accuracy: 0.827\n",
      "epoch 27 iter 250, loss: 1.599, accuracy: 0.844\n",
      "epoch 28 iter 0, loss: 1.669, accuracy: 0.838\n",
      "epoch 28 iter 50, loss: 2.197, accuracy: 0.806\n",
      "epoch 28 iter 100, loss: 1.633, accuracy: 0.833\n",
      "epoch 28 iter 150, loss: 1.942, accuracy: 0.828\n",
      "epoch 28 iter 200, loss: 1.770, accuracy: 0.834\n",
      "epoch 28 iter 250, loss: 1.557, accuracy: 0.846\n",
      "epoch 29 iter 0, loss: 1.853, accuracy: 0.830\n",
      "epoch 29 iter 50, loss: 1.933, accuracy: 0.822\n",
      "epoch 29 iter 100, loss: 1.741, accuracy: 0.831\n",
      "epoch 29 iter 150, loss: 1.940, accuracy: 0.824\n",
      "epoch 29 iter 200, loss: 1.967, accuracy: 0.834\n",
      "epoch 29 iter 250, loss: 1.822, accuracy: 0.841\n",
      "epoch 30 iter 0, loss: 1.880, accuracy: 0.840\n",
      "epoch 30 iter 50, loss: 1.945, accuracy: 0.825\n",
      "epoch 30 iter 100, loss: 1.688, accuracy: 0.835\n",
      "epoch 30 iter 150, loss: 1.895, accuracy: 0.830\n",
      "epoch 30 iter 200, loss: 1.986, accuracy: 0.829\n",
      "epoch 30 iter 250, loss: 1.905, accuracy: 0.842\n",
      "epoch 31 iter 0, loss: 1.883, accuracy: 0.840\n",
      "epoch 31 iter 50, loss: 2.287, accuracy: 0.820\n",
      "epoch 31 iter 100, loss: 1.612, accuracy: 0.837\n",
      "epoch 31 iter 150, loss: 2.089, accuracy: 0.822\n",
      "epoch 31 iter 200, loss: 1.857, accuracy: 0.838\n",
      "epoch 31 iter 250, loss: 1.839, accuracy: 0.836\n",
      "epoch 32 iter 0, loss: 1.837, accuracy: 0.840\n",
      "epoch 32 iter 50, loss: 2.006, accuracy: 0.825\n",
      "epoch 32 iter 100, loss: 1.845, accuracy: 0.833\n",
      "epoch 32 iter 150, loss: 2.032, accuracy: 0.829\n",
      "epoch 32 iter 200, loss: 1.851, accuracy: 0.841\n",
      "epoch 32 iter 250, loss: 1.899, accuracy: 0.841\n",
      "epoch 33 iter 0, loss: 2.102, accuracy: 0.831\n",
      "epoch 33 iter 50, loss: 2.004, accuracy: 0.816\n",
      "epoch 33 iter 100, loss: 1.979, accuracy: 0.833\n",
      "epoch 33 iter 150, loss: 2.117, accuracy: 0.827\n",
      "epoch 33 iter 200, loss: 2.011, accuracy: 0.841\n",
      "epoch 33 iter 250, loss: 1.874, accuracy: 0.832\n",
      "epoch 34 iter 0, loss: 2.021, accuracy: 0.836\n",
      "epoch 34 iter 50, loss: 1.954, accuracy: 0.819\n",
      "epoch 34 iter 100, loss: 2.038, accuracy: 0.830\n",
      "epoch 34 iter 150, loss: 1.986, accuracy: 0.834\n",
      "epoch 34 iter 200, loss: 1.970, accuracy: 0.835\n",
      "epoch 34 iter 250, loss: 1.901, accuracy: 0.846\n",
      "epoch 35 iter 0, loss: 2.057, accuracy: 0.839\n",
      "epoch 35 iter 50, loss: 2.076, accuracy: 0.821\n",
      "epoch 35 iter 100, loss: 2.109, accuracy: 0.836\n",
      "epoch 35 iter 150, loss: 2.332, accuracy: 0.830\n",
      "epoch 35 iter 200, loss: 2.181, accuracy: 0.841\n",
      "epoch 35 iter 250, loss: 2.168, accuracy: 0.840\n",
      "epoch 36 iter 0, loss: 2.145, accuracy: 0.839\n",
      "epoch 36 iter 50, loss: 1.972, accuracy: 0.826\n",
      "epoch 36 iter 100, loss: 2.119, accuracy: 0.834\n",
      "epoch 36 iter 150, loss: 2.246, accuracy: 0.831\n",
      "epoch 36 iter 200, loss: 2.047, accuracy: 0.841\n",
      "epoch 36 iter 250, loss: 2.057, accuracy: 0.843\n",
      "epoch 37 iter 0, loss: 2.068, accuracy: 0.850\n",
      "epoch 37 iter 50, loss: 2.055, accuracy: 0.834\n",
      "epoch 37 iter 100, loss: 2.215, accuracy: 0.830\n",
      "epoch 37 iter 150, loss: 2.179, accuracy: 0.839\n",
      "epoch 37 iter 200, loss: 2.243, accuracy: 0.840\n",
      "epoch 37 iter 250, loss: 2.058, accuracy: 0.841\n",
      "epoch 38 iter 0, loss: 2.012, accuracy: 0.847\n",
      "epoch 38 iter 50, loss: 2.072, accuracy: 0.824\n",
      "epoch 38 iter 100, loss: 2.137, accuracy: 0.840\n",
      "epoch 38 iter 150, loss: 2.241, accuracy: 0.832\n",
      "epoch 38 iter 200, loss: 2.246, accuracy: 0.837\n",
      "epoch 38 iter 250, loss: 2.221, accuracy: 0.843\n",
      "epoch 39 iter 0, loss: 2.243, accuracy: 0.846\n",
      "epoch 39 iter 50, loss: 2.208, accuracy: 0.830\n",
      "epoch 39 iter 100, loss: 2.261, accuracy: 0.833\n",
      "epoch 39 iter 150, loss: 2.529, accuracy: 0.828\n",
      "epoch 39 iter 200, loss: 2.254, accuracy: 0.835\n",
      "epoch 39 iter 250, loss: 2.174, accuracy: 0.834\n",
      "epoch 40 iter 0, loss: 2.177, accuracy: 0.848\n",
      "epoch 40 iter 50, loss: 2.192, accuracy: 0.829\n",
      "epoch 40 iter 100, loss: 2.259, accuracy: 0.841\n",
      "epoch 40 iter 150, loss: 2.478, accuracy: 0.835\n",
      "epoch 40 iter 200, loss: 2.386, accuracy: 0.834\n",
      "epoch 40 iter 250, loss: 2.095, accuracy: 0.841\n",
      "epoch 41 iter 0, loss: 2.313, accuracy: 0.841\n",
      "epoch 41 iter 50, loss: 2.244, accuracy: 0.833\n",
      "epoch 41 iter 100, loss: 2.335, accuracy: 0.838\n",
      "epoch 41 iter 150, loss: 2.595, accuracy: 0.830\n",
      "epoch 41 iter 200, loss: 2.227, accuracy: 0.837\n",
      "epoch 41 iter 250, loss: 2.318, accuracy: 0.840\n",
      "epoch 42 iter 0, loss: 2.431, accuracy: 0.844\n",
      "epoch 42 iter 50, loss: 2.354, accuracy: 0.820\n",
      "epoch 42 iter 100, loss: 2.450, accuracy: 0.836\n",
      "epoch 42 iter 150, loss: 2.661, accuracy: 0.833\n",
      "epoch 42 iter 200, loss: 2.369, accuracy: 0.836\n",
      "epoch 42 iter 250, loss: 2.580, accuracy: 0.828\n",
      "epoch 43 iter 0, loss: 2.459, accuracy: 0.835\n",
      "epoch 43 iter 50, loss: 2.604, accuracy: 0.825\n",
      "epoch 43 iter 100, loss: 2.596, accuracy: 0.842\n",
      "epoch 43 iter 150, loss: 2.606, accuracy: 0.838\n",
      "epoch 43 iter 200, loss: 2.584, accuracy: 0.837\n",
      "epoch 43 iter 250, loss: 2.401, accuracy: 0.835\n",
      "epoch 44 iter 0, loss: 2.514, accuracy: 0.841\n",
      "epoch 44 iter 50, loss: 2.602, accuracy: 0.814\n",
      "epoch 44 iter 100, loss: 2.566, accuracy: 0.841\n",
      "epoch 44 iter 150, loss: 2.681, accuracy: 0.835\n",
      "epoch 44 iter 200, loss: 2.767, accuracy: 0.831\n",
      "epoch 44 iter 250, loss: 2.363, accuracy: 0.837\n",
      "epoch 45 iter 0, loss: 2.512, accuracy: 0.841\n",
      "epoch 45 iter 50, loss: 2.703, accuracy: 0.832\n",
      "epoch 45 iter 100, loss: 2.722, accuracy: 0.843\n",
      "epoch 45 iter 150, loss: 2.641, accuracy: 0.840\n",
      "epoch 45 iter 200, loss: 2.878, accuracy: 0.830\n",
      "epoch 45 iter 250, loss: 2.499, accuracy: 0.836\n",
      "epoch 46 iter 0, loss: 2.553, accuracy: 0.843\n",
      "epoch 46 iter 50, loss: 2.619, accuracy: 0.830\n",
      "epoch 46 iter 100, loss: 2.690, accuracy: 0.840\n",
      "epoch 46 iter 150, loss: 2.611, accuracy: 0.839\n",
      "epoch 46 iter 200, loss: 2.748, accuracy: 0.841\n",
      "epoch 46 iter 250, loss: 2.730, accuracy: 0.832\n",
      "epoch 47 iter 0, loss: 2.860, accuracy: 0.841\n",
      "epoch 47 iter 50, loss: 2.834, accuracy: 0.827\n",
      "epoch 47 iter 100, loss: 2.684, accuracy: 0.845\n",
      "epoch 47 iter 150, loss: 2.925, accuracy: 0.844\n",
      "epoch 47 iter 200, loss: 2.942, accuracy: 0.826\n",
      "epoch 47 iter 250, loss: 2.653, accuracy: 0.838\n",
      "epoch 48 iter 0, loss: 2.530, accuracy: 0.850\n",
      "epoch 48 iter 50, loss: 2.601, accuracy: 0.841\n",
      "epoch 48 iter 100, loss: 2.660, accuracy: 0.835\n",
      "epoch 48 iter 150, loss: 2.901, accuracy: 0.840\n",
      "epoch 48 iter 200, loss: 2.679, accuracy: 0.839\n",
      "epoch 48 iter 250, loss: 2.633, accuracy: 0.844\n",
      "epoch 49 iter 0, loss: 2.594, accuracy: 0.852\n",
      "epoch 49 iter 50, loss: 2.597, accuracy: 0.848\n",
      "epoch 49 iter 100, loss: 2.817, accuracy: 0.841\n",
      "epoch 49 iter 150, loss: 2.729, accuracy: 0.839\n",
      "epoch 49 iter 200, loss: 2.630, accuracy: 0.848\n",
      "epoch 49 iter 250, loss: 2.676, accuracy: 0.845\n",
      "epoch 50 iter 0, loss: 2.652, accuracy: 0.851\n",
      "epoch 50 iter 50, loss: 2.728, accuracy: 0.841\n",
      "epoch 50 iter 100, loss: 2.828, accuracy: 0.835\n",
      "epoch 50 iter 150, loss: 2.897, accuracy: 0.836\n",
      "epoch 50 iter 200, loss: 2.889, accuracy: 0.838\n",
      "epoch 50 iter 250, loss: 2.658, accuracy: 0.848\n",
      "epoch 51 iter 0, loss: 2.972, accuracy: 0.844\n",
      "epoch 51 iter 50, loss: 2.932, accuracy: 0.839\n",
      "epoch 51 iter 100, loss: 3.001, accuracy: 0.838\n",
      "epoch 51 iter 150, loss: 2.824, accuracy: 0.840\n",
      "epoch 51 iter 200, loss: 2.737, accuracy: 0.846\n",
      "epoch 51 iter 250, loss: 2.833, accuracy: 0.846\n",
      "epoch 52 iter 0, loss: 2.710, accuracy: 0.848\n",
      "epoch 52 iter 50, loss: 2.837, accuracy: 0.842\n",
      "epoch 52 iter 100, loss: 2.975, accuracy: 0.836\n",
      "epoch 52 iter 150, loss: 2.945, accuracy: 0.846\n",
      "epoch 52 iter 200, loss: 2.668, accuracy: 0.840\n",
      "epoch 52 iter 250, loss: 2.975, accuracy: 0.850\n",
      "epoch 53 iter 0, loss: 3.082, accuracy: 0.839\n",
      "epoch 53 iter 50, loss: 2.954, accuracy: 0.837\n",
      "epoch 53 iter 100, loss: 3.018, accuracy: 0.846\n",
      "epoch 53 iter 150, loss: 3.269, accuracy: 0.841\n",
      "epoch 53 iter 200, loss: 2.820, accuracy: 0.842\n",
      "epoch 53 iter 250, loss: 3.084, accuracy: 0.842\n",
      "epoch 54 iter 0, loss: 3.206, accuracy: 0.843\n",
      "epoch 54 iter 50, loss: 3.105, accuracy: 0.836\n",
      "epoch 54 iter 100, loss: 3.664, accuracy: 0.827\n",
      "epoch 54 iter 150, loss: 3.316, accuracy: 0.844\n",
      "epoch 54 iter 200, loss: 2.718, accuracy: 0.845\n",
      "epoch 54 iter 250, loss: 2.835, accuracy: 0.845\n",
      "epoch 55 iter 0, loss: 3.077, accuracy: 0.848\n",
      "epoch 55 iter 50, loss: 3.014, accuracy: 0.847\n",
      "epoch 55 iter 100, loss: 2.993, accuracy: 0.841\n",
      "epoch 55 iter 150, loss: 3.180, accuracy: 0.845\n",
      "epoch 55 iter 200, loss: 2.929, accuracy: 0.841\n",
      "epoch 55 iter 250, loss: 2.956, accuracy: 0.837\n",
      "epoch 56 iter 0, loss: 3.175, accuracy: 0.846\n",
      "epoch 56 iter 50, loss: 2.928, accuracy: 0.845\n",
      "epoch 56 iter 100, loss: 3.006, accuracy: 0.842\n",
      "epoch 56 iter 150, loss: 3.371, accuracy: 0.845\n",
      "epoch 56 iter 200, loss: 2.848, accuracy: 0.849\n",
      "epoch 56 iter 250, loss: 2.852, accuracy: 0.851\n",
      "epoch 57 iter 0, loss: 2.961, accuracy: 0.850\n",
      "epoch 57 iter 50, loss: 2.958, accuracy: 0.844\n",
      "epoch 57 iter 100, loss: 3.130, accuracy: 0.844\n",
      "epoch 57 iter 150, loss: 3.580, accuracy: 0.843\n",
      "epoch 57 iter 200, loss: 3.192, accuracy: 0.847\n",
      "epoch 57 iter 250, loss: 3.022, accuracy: 0.849\n",
      "epoch 58 iter 0, loss: 3.035, accuracy: 0.843\n",
      "epoch 58 iter 50, loss: 3.095, accuracy: 0.839\n",
      "epoch 58 iter 100, loss: 2.865, accuracy: 0.843\n",
      "epoch 58 iter 150, loss: 3.211, accuracy: 0.842\n",
      "epoch 58 iter 200, loss: 3.094, accuracy: 0.852\n",
      "epoch 58 iter 250, loss: 3.001, accuracy: 0.843\n",
      "epoch 59 iter 0, loss: 3.128, accuracy: 0.851\n",
      "epoch 59 iter 50, loss: 3.095, accuracy: 0.846\n",
      "epoch 59 iter 100, loss: 3.342, accuracy: 0.839\n",
      "epoch 59 iter 150, loss: 3.474, accuracy: 0.844\n",
      "epoch 59 iter 200, loss: 3.534, accuracy: 0.845\n",
      "epoch 59 iter 250, loss: 3.293, accuracy: 0.839\n",
      "epoch 60 iter 0, loss: 3.299, accuracy: 0.855\n",
      "epoch 60 iter 50, loss: 3.339, accuracy: 0.842\n",
      "epoch 60 iter 100, loss: 3.203, accuracy: 0.844\n",
      "epoch 60 iter 150, loss: 3.575, accuracy: 0.846\n",
      "epoch 60 iter 200, loss: 3.188, accuracy: 0.850\n",
      "epoch 60 iter 250, loss: 3.185, accuracy: 0.849\n",
      "epoch 61 iter 0, loss: 3.197, accuracy: 0.848\n",
      "epoch 61 iter 50, loss: 3.411, accuracy: 0.844\n",
      "epoch 61 iter 100, loss: 3.306, accuracy: 0.842\n",
      "epoch 61 iter 150, loss: 3.635, accuracy: 0.842\n",
      "epoch 61 iter 200, loss: 3.390, accuracy: 0.846\n",
      "epoch 61 iter 250, loss: 3.431, accuracy: 0.845\n",
      "epoch 62 iter 0, loss: 3.471, accuracy: 0.855\n",
      "epoch 62 iter 50, loss: 3.325, accuracy: 0.836\n",
      "epoch 62 iter 100, loss: 3.194, accuracy: 0.842\n",
      "epoch 62 iter 150, loss: 3.472, accuracy: 0.844\n",
      "epoch 62 iter 200, loss: 3.332, accuracy: 0.837\n",
      "epoch 62 iter 250, loss: 3.390, accuracy: 0.841\n",
      "epoch 63 iter 0, loss: 3.343, accuracy: 0.845\n",
      "epoch 63 iter 50, loss: 3.637, accuracy: 0.837\n",
      "epoch 63 iter 100, loss: 3.467, accuracy: 0.833\n",
      "epoch 63 iter 150, loss: 3.529, accuracy: 0.844\n",
      "epoch 63 iter 200, loss: 3.541, accuracy: 0.840\n",
      "epoch 63 iter 250, loss: 3.394, accuracy: 0.844\n",
      "epoch 64 iter 0, loss: 3.505, accuracy: 0.849\n",
      "epoch 64 iter 50, loss: 3.602, accuracy: 0.840\n",
      "epoch 64 iter 100, loss: 3.317, accuracy: 0.837\n",
      "epoch 64 iter 150, loss: 3.712, accuracy: 0.848\n",
      "epoch 64 iter 200, loss: 3.264, accuracy: 0.839\n",
      "epoch 64 iter 250, loss: 3.493, accuracy: 0.849\n",
      "epoch 65 iter 0, loss: 3.545, accuracy: 0.852\n",
      "epoch 65 iter 50, loss: 3.575, accuracy: 0.850\n",
      "epoch 65 iter 100, loss: 3.405, accuracy: 0.843\n",
      "epoch 65 iter 150, loss: 4.160, accuracy: 0.847\n",
      "epoch 65 iter 200, loss: 3.450, accuracy: 0.841\n",
      "epoch 65 iter 250, loss: 3.631, accuracy: 0.846\n",
      "epoch 66 iter 0, loss: 3.553, accuracy: 0.851\n",
      "epoch 66 iter 50, loss: 3.465, accuracy: 0.843\n",
      "epoch 66 iter 100, loss: 3.480, accuracy: 0.843\n",
      "epoch 66 iter 150, loss: 3.571, accuracy: 0.846\n",
      "epoch 66 iter 200, loss: 3.321, accuracy: 0.845\n",
      "epoch 66 iter 250, loss: 3.488, accuracy: 0.845\n",
      "epoch 67 iter 0, loss: 3.752, accuracy: 0.847\n",
      "epoch 67 iter 50, loss: 3.899, accuracy: 0.846\n",
      "epoch 67 iter 100, loss: 3.354, accuracy: 0.847\n",
      "epoch 67 iter 150, loss: 3.783, accuracy: 0.841\n",
      "epoch 67 iter 200, loss: 3.508, accuracy: 0.849\n",
      "epoch 67 iter 250, loss: 3.533, accuracy: 0.851\n",
      "epoch 68 iter 0, loss: 3.641, accuracy: 0.854\n",
      "epoch 68 iter 50, loss: 4.067, accuracy: 0.839\n",
      "epoch 68 iter 100, loss: 3.541, accuracy: 0.840\n",
      "epoch 68 iter 150, loss: 4.125, accuracy: 0.843\n",
      "epoch 68 iter 200, loss: 3.825, accuracy: 0.836\n",
      "epoch 68 iter 250, loss: 3.743, accuracy: 0.851\n",
      "epoch 69 iter 0, loss: 4.076, accuracy: 0.848\n",
      "epoch 69 iter 50, loss: 4.170, accuracy: 0.847\n",
      "epoch 69 iter 100, loss: 3.867, accuracy: 0.848\n",
      "epoch 69 iter 150, loss: 4.355, accuracy: 0.850\n",
      "epoch 69 iter 200, loss: 3.546, accuracy: 0.853\n",
      "epoch 69 iter 250, loss: 3.905, accuracy: 0.852\n",
      "epoch 70 iter 0, loss: 3.950, accuracy: 0.857\n",
      "epoch 70 iter 50, loss: 4.035, accuracy: 0.844\n",
      "epoch 70 iter 100, loss: 3.781, accuracy: 0.841\n",
      "epoch 70 iter 150, loss: 4.428, accuracy: 0.845\n",
      "epoch 70 iter 200, loss: 3.705, accuracy: 0.844\n",
      "epoch 70 iter 250, loss: 3.797, accuracy: 0.840\n",
      "epoch 71 iter 0, loss: 4.006, accuracy: 0.851\n",
      "epoch 71 iter 50, loss: 4.048, accuracy: 0.842\n",
      "epoch 71 iter 100, loss: 3.630, accuracy: 0.842\n",
      "epoch 71 iter 150, loss: 4.534, accuracy: 0.843\n",
      "epoch 71 iter 200, loss: 4.060, accuracy: 0.842\n",
      "epoch 71 iter 250, loss: 3.959, accuracy: 0.850\n",
      "epoch 72 iter 0, loss: 4.025, accuracy: 0.847\n",
      "epoch 72 iter 50, loss: 4.466, accuracy: 0.845\n",
      "epoch 72 iter 100, loss: 3.833, accuracy: 0.839\n",
      "epoch 72 iter 150, loss: 4.377, accuracy: 0.844\n",
      "epoch 72 iter 200, loss: 3.980, accuracy: 0.844\n",
      "epoch 72 iter 250, loss: 4.169, accuracy: 0.853\n",
      "epoch 73 iter 0, loss: 4.179, accuracy: 0.851\n",
      "epoch 73 iter 50, loss: 4.330, accuracy: 0.841\n",
      "epoch 73 iter 100, loss: 4.098, accuracy: 0.842\n",
      "epoch 73 iter 150, loss: 4.718, accuracy: 0.836\n",
      "epoch 73 iter 200, loss: 4.173, accuracy: 0.841\n",
      "epoch 73 iter 250, loss: 4.186, accuracy: 0.846\n",
      "epoch 74 iter 0, loss: 4.431, accuracy: 0.844\n",
      "epoch 74 iter 50, loss: 4.523, accuracy: 0.844\n",
      "epoch 74 iter 100, loss: 4.027, accuracy: 0.836\n",
      "epoch 74 iter 150, loss: 4.896, accuracy: 0.835\n",
      "epoch 74 iter 200, loss: 4.210, accuracy: 0.836\n",
      "epoch 74 iter 250, loss: 4.057, accuracy: 0.845\n",
      "epoch 75 iter 0, loss: 4.156, accuracy: 0.847\n",
      "epoch 75 iter 50, loss: 4.207, accuracy: 0.838\n",
      "epoch 75 iter 100, loss: 3.883, accuracy: 0.841\n",
      "epoch 75 iter 150, loss: 4.915, accuracy: 0.834\n",
      "epoch 75 iter 200, loss: 4.282, accuracy: 0.847\n",
      "epoch 75 iter 250, loss: 4.285, accuracy: 0.850\n",
      "epoch 76 iter 0, loss: 4.630, accuracy: 0.848\n",
      "epoch 76 iter 50, loss: 4.419, accuracy: 0.850\n",
      "epoch 76 iter 100, loss: 4.143, accuracy: 0.844\n",
      "epoch 76 iter 150, loss: 5.055, accuracy: 0.842\n",
      "epoch 76 iter 200, loss: 4.297, accuracy: 0.851\n",
      "epoch 76 iter 250, loss: 4.253, accuracy: 0.854\n",
      "epoch 77 iter 0, loss: 4.113, accuracy: 0.849\n",
      "epoch 77 iter 50, loss: 4.621, accuracy: 0.841\n",
      "epoch 77 iter 100, loss: 4.098, accuracy: 0.845\n",
      "epoch 77 iter 150, loss: 5.613, accuracy: 0.827\n",
      "epoch 77 iter 200, loss: 4.428, accuracy: 0.843\n",
      "epoch 77 iter 250, loss: 4.283, accuracy: 0.849\n",
      "epoch 78 iter 0, loss: 4.782, accuracy: 0.843\n",
      "epoch 78 iter 50, loss: 4.808, accuracy: 0.848\n",
      "epoch 78 iter 100, loss: 4.099, accuracy: 0.846\n",
      "epoch 78 iter 150, loss: 4.693, accuracy: 0.839\n",
      "epoch 78 iter 200, loss: 4.542, accuracy: 0.851\n",
      "epoch 78 iter 250, loss: 4.440, accuracy: 0.850\n",
      "epoch 79 iter 0, loss: 4.213, accuracy: 0.851\n",
      "epoch 79 iter 50, loss: 4.775, accuracy: 0.835\n",
      "epoch 79 iter 100, loss: 4.173, accuracy: 0.849\n",
      "epoch 79 iter 150, loss: 4.836, accuracy: 0.838\n",
      "epoch 79 iter 200, loss: 4.404, accuracy: 0.851\n",
      "epoch 79 iter 250, loss: 4.391, accuracy: 0.849\n",
      "epoch 80 iter 0, loss: 4.315, accuracy: 0.848\n",
      "epoch 80 iter 50, loss: 4.793, accuracy: 0.843\n",
      "epoch 80 iter 100, loss: 4.439, accuracy: 0.848\n",
      "epoch 80 iter 150, loss: 4.931, accuracy: 0.842\n",
      "epoch 80 iter 200, loss: 4.461, accuracy: 0.846\n",
      "epoch 80 iter 250, loss: 4.503, accuracy: 0.857\n",
      "epoch 81 iter 0, loss: 4.838, accuracy: 0.860\n",
      "epoch 81 iter 50, loss: 5.016, accuracy: 0.844\n",
      "epoch 81 iter 100, loss: 4.831, accuracy: 0.847\n",
      "epoch 81 iter 150, loss: 5.298, accuracy: 0.836\n",
      "epoch 81 iter 200, loss: 4.777, accuracy: 0.844\n",
      "epoch 81 iter 250, loss: 4.335, accuracy: 0.851\n",
      "epoch 82 iter 0, loss: 4.579, accuracy: 0.854\n",
      "epoch 82 iter 50, loss: 4.980, accuracy: 0.843\n",
      "epoch 82 iter 100, loss: 4.658, accuracy: 0.844\n",
      "epoch 82 iter 150, loss: 5.149, accuracy: 0.842\n",
      "epoch 82 iter 200, loss: 4.486, accuracy: 0.844\n",
      "epoch 82 iter 250, loss: 4.420, accuracy: 0.854\n",
      "epoch 83 iter 0, loss: 4.463, accuracy: 0.854\n",
      "epoch 83 iter 50, loss: 4.488, accuracy: 0.846\n",
      "epoch 83 iter 100, loss: 4.531, accuracy: 0.834\n",
      "epoch 83 iter 150, loss: 5.291, accuracy: 0.839\n",
      "epoch 83 iter 200, loss: 5.038, accuracy: 0.847\n",
      "epoch 83 iter 250, loss: 4.567, accuracy: 0.849\n",
      "epoch 84 iter 0, loss: 4.881, accuracy: 0.855\n",
      "epoch 84 iter 50, loss: 4.866, accuracy: 0.846\n",
      "epoch 84 iter 100, loss: 5.086, accuracy: 0.845\n",
      "epoch 84 iter 150, loss: 4.998, accuracy: 0.840\n",
      "epoch 84 iter 200, loss: 4.609, accuracy: 0.847\n",
      "epoch 84 iter 250, loss: 4.732, accuracy: 0.852\n",
      "epoch 85 iter 0, loss: 4.656, accuracy: 0.853\n",
      "epoch 85 iter 50, loss: 5.240, accuracy: 0.840\n",
      "epoch 85 iter 100, loss: 4.956, accuracy: 0.846\n",
      "epoch 85 iter 150, loss: 5.403, accuracy: 0.846\n",
      "epoch 85 iter 200, loss: 4.999, accuracy: 0.843\n",
      "epoch 85 iter 250, loss: 4.480, accuracy: 0.850\n",
      "epoch 86 iter 0, loss: 4.446, accuracy: 0.854\n",
      "epoch 86 iter 50, loss: 4.787, accuracy: 0.849\n",
      "epoch 86 iter 100, loss: 4.822, accuracy: 0.844\n",
      "epoch 86 iter 150, loss: 5.123, accuracy: 0.846\n",
      "epoch 86 iter 200, loss: 4.744, accuracy: 0.855\n",
      "epoch 86 iter 250, loss: 4.574, accuracy: 0.852\n",
      "epoch 87 iter 0, loss: 4.844, accuracy: 0.854\n",
      "epoch 87 iter 50, loss: 5.001, accuracy: 0.845\n",
      "epoch 87 iter 100, loss: 5.079, accuracy: 0.848\n",
      "epoch 87 iter 150, loss: 5.484, accuracy: 0.846\n",
      "epoch 87 iter 200, loss: 4.990, accuracy: 0.848\n",
      "epoch 87 iter 250, loss: 4.766, accuracy: 0.848\n",
      "epoch 88 iter 0, loss: 4.761, accuracy: 0.853\n",
      "epoch 88 iter 50, loss: 5.236, accuracy: 0.849\n",
      "epoch 88 iter 100, loss: 5.086, accuracy: 0.846\n",
      "epoch 88 iter 150, loss: 5.530, accuracy: 0.850\n",
      "epoch 88 iter 200, loss: 4.859, accuracy: 0.851\n",
      "epoch 88 iter 250, loss: 5.078, accuracy: 0.849\n",
      "epoch 89 iter 0, loss: 5.440, accuracy: 0.849\n",
      "epoch 89 iter 50, loss: 5.788, accuracy: 0.847\n",
      "epoch 89 iter 100, loss: 5.247, accuracy: 0.847\n",
      "epoch 89 iter 150, loss: 5.423, accuracy: 0.851\n",
      "epoch 89 iter 200, loss: 5.204, accuracy: 0.850\n",
      "epoch 89 iter 250, loss: 4.995, accuracy: 0.854\n",
      "epoch 90 iter 0, loss: 5.063, accuracy: 0.858\n",
      "epoch 90 iter 50, loss: 5.154, accuracy: 0.852\n",
      "epoch 90 iter 100, loss: 5.369, accuracy: 0.841\n",
      "epoch 90 iter 150, loss: 5.335, accuracy: 0.844\n",
      "epoch 90 iter 200, loss: 5.012, accuracy: 0.850\n",
      "epoch 90 iter 250, loss: 5.245, accuracy: 0.849\n",
      "epoch 91 iter 0, loss: 5.335, accuracy: 0.849\n",
      "epoch 91 iter 50, loss: 5.168, accuracy: 0.846\n",
      "epoch 91 iter 100, loss: 5.624, accuracy: 0.841\n",
      "epoch 91 iter 150, loss: 5.694, accuracy: 0.847\n",
      "epoch 91 iter 200, loss: 5.380, accuracy: 0.851\n",
      "epoch 91 iter 250, loss: 4.918, accuracy: 0.850\n",
      "epoch 92 iter 0, loss: 5.029, accuracy: 0.850\n",
      "epoch 92 iter 50, loss: 5.095, accuracy: 0.847\n",
      "epoch 92 iter 100, loss: 4.876, accuracy: 0.841\n",
      "epoch 92 iter 150, loss: 5.606, accuracy: 0.834\n",
      "epoch 92 iter 200, loss: 5.256, accuracy: 0.850\n",
      "epoch 92 iter 250, loss: 5.247, accuracy: 0.853\n",
      "epoch 93 iter 0, loss: 5.241, accuracy: 0.848\n",
      "epoch 93 iter 50, loss: 5.498, accuracy: 0.847\n",
      "epoch 93 iter 100, loss: 5.212, accuracy: 0.844\n",
      "epoch 93 iter 150, loss: 6.005, accuracy: 0.835\n",
      "epoch 93 iter 200, loss: 5.330, accuracy: 0.849\n",
      "epoch 93 iter 250, loss: 4.952, accuracy: 0.854\n",
      "epoch 94 iter 0, loss: 5.786, accuracy: 0.854\n",
      "epoch 94 iter 50, loss: 5.434, accuracy: 0.849\n",
      "epoch 94 iter 100, loss: 5.666, accuracy: 0.845\n",
      "epoch 94 iter 150, loss: 6.405, accuracy: 0.839\n",
      "epoch 94 iter 200, loss: 5.530, accuracy: 0.843\n",
      "epoch 94 iter 250, loss: 5.549, accuracy: 0.857\n",
      "epoch 95 iter 0, loss: 5.482, accuracy: 0.852\n",
      "epoch 95 iter 50, loss: 5.577, accuracy: 0.843\n",
      "epoch 95 iter 100, loss: 5.394, accuracy: 0.848\n",
      "epoch 95 iter 150, loss: 5.755, accuracy: 0.855\n",
      "epoch 95 iter 200, loss: 6.734, accuracy: 0.846\n",
      "epoch 95 iter 250, loss: 5.522, accuracy: 0.856\n",
      "epoch 96 iter 0, loss: 5.760, accuracy: 0.854\n",
      "epoch 96 iter 50, loss: 6.095, accuracy: 0.849\n",
      "epoch 96 iter 100, loss: 5.684, accuracy: 0.847\n",
      "epoch 96 iter 150, loss: 6.500, accuracy: 0.851\n",
      "epoch 96 iter 200, loss: 5.914, accuracy: 0.844\n",
      "epoch 96 iter 250, loss: 5.466, accuracy: 0.853\n",
      "epoch 97 iter 0, loss: 5.483, accuracy: 0.855\n",
      "epoch 97 iter 50, loss: 5.635, accuracy: 0.844\n",
      "epoch 97 iter 100, loss: 5.722, accuracy: 0.841\n",
      "epoch 97 iter 150, loss: 6.045, accuracy: 0.843\n",
      "epoch 97 iter 200, loss: 6.009, accuracy: 0.848\n",
      "epoch 97 iter 250, loss: 5.538, accuracy: 0.851\n",
      "epoch 98 iter 0, loss: 5.581, accuracy: 0.856\n",
      "epoch 98 iter 50, loss: 6.145, accuracy: 0.839\n",
      "epoch 98 iter 100, loss: 5.819, accuracy: 0.849\n",
      "epoch 98 iter 150, loss: 6.103, accuracy: 0.851\n",
      "epoch 98 iter 200, loss: 5.813, accuracy: 0.852\n",
      "epoch 98 iter 250, loss: 5.402, accuracy: 0.851\n",
      "epoch 99 iter 0, loss: 5.510, accuracy: 0.857\n",
      "epoch 99 iter 50, loss: 6.182, accuracy: 0.842\n",
      "epoch 99 iter 100, loss: 6.158, accuracy: 0.847\n",
      "epoch 99 iter 150, loss: 6.902, accuracy: 0.844\n",
      "epoch 99 iter 200, loss: 5.776, accuracy: 0.847\n",
      "epoch 99 iter 250, loss: 5.693, accuracy: 0.853\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=1,\n",
    "            filters=16,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=1,\n",
    "            filters=16, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 112.212, accuracy: 0.092\n",
      "epoch 0 iter 50, loss: 2.242, accuracy: 0.195\n",
      "epoch 0 iter 100, loss: 2.220, accuracy: 0.219\n",
      "epoch 0 iter 150, loss: 2.121, accuracy: 0.254\n",
      "epoch 0 iter 200, loss: 2.096, accuracy: 0.268\n",
      "epoch 0 iter 250, loss: 2.026, accuracy: 0.287\n",
      "epoch 1 iter 0, loss: 2.046, accuracy: 0.280\n",
      "epoch 1 iter 50, loss: 1.958, accuracy: 0.308\n",
      "epoch 1 iter 100, loss: 2.173, accuracy: 0.211\n",
      "epoch 1 iter 150, loss: 1.942, accuracy: 0.315\n",
      "epoch 1 iter 200, loss: 1.980, accuracy: 0.299\n",
      "epoch 1 iter 250, loss: 1.906, accuracy: 0.316\n",
      "epoch 2 iter 0, loss: 1.885, accuracy: 0.335\n",
      "epoch 2 iter 50, loss: 1.867, accuracy: 0.340\n",
      "epoch 2 iter 100, loss: 2.227, accuracy: 0.196\n",
      "epoch 2 iter 150, loss: 2.224, accuracy: 0.196\n",
      "epoch 2 iter 200, loss: 2.224, accuracy: 0.196\n",
      "epoch 2 iter 250, loss: 2.222, accuracy: 0.196\n",
      "epoch 3 iter 0, loss: 2.224, accuracy: 0.196\n",
      "epoch 3 iter 50, loss: 2.224, accuracy: 0.196\n",
      "epoch 3 iter 100, loss: 2.224, accuracy: 0.196\n",
      "epoch 3 iter 150, loss: 2.224, accuracy: 0.196\n",
      "epoch 3 iter 200, loss: 2.222, accuracy: 0.196\n",
      "epoch 3 iter 250, loss: 2.224, accuracy: 0.196\n",
      "epoch 4 iter 0, loss: 2.224, accuracy: 0.196\n",
      "epoch 4 iter 50, loss: 2.224, accuracy: 0.196\n",
      "epoch 4 iter 100, loss: 2.224, accuracy: 0.196\n",
      "epoch 4 iter 150, loss: 2.224, accuracy: 0.196\n",
      "epoch 4 iter 200, loss: 2.224, accuracy: 0.196\n",
      "epoch 4 iter 250, loss: 2.224, accuracy: 0.196\n",
      "epoch 5 iter 0, loss: 2.224, accuracy: 0.197\n",
      "epoch 5 iter 50, loss: 2.219, accuracy: 0.199\n",
      "epoch 5 iter 100, loss: 2.220, accuracy: 0.198\n",
      "epoch 5 iter 150, loss: 2.222, accuracy: 0.198\n",
      "epoch 5 iter 200, loss: 2.177, accuracy: 0.188\n",
      "epoch 5 iter 250, loss: 2.005, accuracy: 0.292\n",
      "epoch 6 iter 0, loss: 1.990, accuracy: 0.306\n",
      "epoch 6 iter 50, loss: 1.499, accuracy: 0.516\n",
      "epoch 6 iter 100, loss: 1.202, accuracy: 0.630\n",
      "epoch 6 iter 150, loss: 1.148, accuracy: 0.643\n",
      "epoch 6 iter 200, loss: 1.077, accuracy: 0.672\n",
      "epoch 6 iter 250, loss: 1.003, accuracy: 0.695\n",
      "epoch 7 iter 0, loss: 0.935, accuracy: 0.716\n",
      "epoch 7 iter 50, loss: 0.937, accuracy: 0.718\n",
      "epoch 7 iter 100, loss: 0.876, accuracy: 0.741\n",
      "epoch 7 iter 150, loss: 0.810, accuracy: 0.764\n",
      "epoch 7 iter 200, loss: 0.781, accuracy: 0.774\n",
      "epoch 7 iter 250, loss: 0.728, accuracy: 0.791\n",
      "epoch 8 iter 0, loss: 0.766, accuracy: 0.779\n",
      "epoch 8 iter 50, loss: 0.688, accuracy: 0.809\n",
      "epoch 8 iter 100, loss: 0.617, accuracy: 0.825\n",
      "epoch 8 iter 150, loss: 0.672, accuracy: 0.811\n",
      "epoch 8 iter 200, loss: 0.631, accuracy: 0.822\n",
      "epoch 8 iter 250, loss: 0.583, accuracy: 0.840\n",
      "epoch 9 iter 0, loss: 0.591, accuracy: 0.838\n",
      "epoch 9 iter 50, loss: 0.607, accuracy: 0.835\n",
      "epoch 9 iter 100, loss: 0.586, accuracy: 0.839\n",
      "epoch 9 iter 150, loss: 0.636, accuracy: 0.826\n",
      "epoch 9 iter 200, loss: 0.598, accuracy: 0.837\n",
      "epoch 9 iter 250, loss: 0.608, accuracy: 0.834\n",
      "epoch 10 iter 0, loss: 0.572, accuracy: 0.847\n",
      "epoch 10 iter 50, loss: 0.590, accuracy: 0.847\n",
      "epoch 10 iter 100, loss: 0.603, accuracy: 0.835\n",
      "epoch 10 iter 150, loss: 0.668, accuracy: 0.817\n",
      "epoch 10 iter 200, loss: 0.617, accuracy: 0.841\n",
      "epoch 10 iter 250, loss: 0.602, accuracy: 0.844\n",
      "epoch 11 iter 0, loss: 0.596, accuracy: 0.850\n",
      "epoch 11 iter 50, loss: 0.583, accuracy: 0.857\n",
      "epoch 11 iter 100, loss: 0.613, accuracy: 0.842\n",
      "epoch 11 iter 150, loss: 0.648, accuracy: 0.832\n",
      "epoch 11 iter 200, loss: 0.587, accuracy: 0.853\n",
      "epoch 11 iter 250, loss: 0.598, accuracy: 0.847\n",
      "epoch 12 iter 0, loss: 0.654, accuracy: 0.838\n",
      "epoch 12 iter 50, loss: 0.583, accuracy: 0.855\n",
      "epoch 12 iter 100, loss: 0.605, accuracy: 0.851\n",
      "epoch 12 iter 150, loss: 0.603, accuracy: 0.855\n",
      "epoch 12 iter 200, loss: 0.639, accuracy: 0.842\n",
      "epoch 12 iter 250, loss: 0.628, accuracy: 0.851\n",
      "epoch 13 iter 0, loss: 0.638, accuracy: 0.850\n",
      "epoch 13 iter 50, loss: 0.689, accuracy: 0.845\n",
      "epoch 13 iter 100, loss: 0.657, accuracy: 0.850\n",
      "epoch 13 iter 150, loss: 0.628, accuracy: 0.855\n",
      "epoch 13 iter 200, loss: 0.700, accuracy: 0.850\n",
      "epoch 13 iter 250, loss: 0.692, accuracy: 0.838\n",
      "epoch 14 iter 0, loss: 0.661, accuracy: 0.850\n",
      "epoch 14 iter 50, loss: 0.692, accuracy: 0.850\n",
      "epoch 14 iter 100, loss: 0.688, accuracy: 0.844\n",
      "epoch 14 iter 150, loss: 0.678, accuracy: 0.851\n",
      "epoch 14 iter 200, loss: 0.715, accuracy: 0.847\n",
      "epoch 14 iter 250, loss: 0.701, accuracy: 0.843\n",
      "epoch 15 iter 0, loss: 0.735, accuracy: 0.838\n",
      "epoch 15 iter 50, loss: 0.717, accuracy: 0.852\n",
      "epoch 15 iter 100, loss: 0.722, accuracy: 0.855\n",
      "epoch 15 iter 150, loss: 0.726, accuracy: 0.850\n",
      "epoch 15 iter 200, loss: 0.787, accuracy: 0.842\n",
      "epoch 15 iter 250, loss: 0.728, accuracy: 0.848\n",
      "epoch 16 iter 0, loss: 0.718, accuracy: 0.851\n",
      "epoch 16 iter 50, loss: 0.753, accuracy: 0.859\n",
      "epoch 16 iter 100, loss: 0.804, accuracy: 0.838\n",
      "epoch 16 iter 150, loss: 0.781, accuracy: 0.848\n",
      "epoch 16 iter 200, loss: 0.771, accuracy: 0.855\n",
      "epoch 16 iter 250, loss: 0.808, accuracy: 0.843\n",
      "epoch 17 iter 0, loss: 0.922, accuracy: 0.828\n",
      "epoch 17 iter 50, loss: 0.789, accuracy: 0.855\n",
      "epoch 17 iter 100, loss: 0.882, accuracy: 0.841\n",
      "epoch 17 iter 150, loss: 0.893, accuracy: 0.838\n",
      "epoch 17 iter 200, loss: 0.772, accuracy: 0.857\n",
      "epoch 17 iter 250, loss: 0.860, accuracy: 0.842\n",
      "epoch 18 iter 0, loss: 0.801, accuracy: 0.856\n",
      "epoch 18 iter 50, loss: 0.831, accuracy: 0.861\n",
      "epoch 18 iter 100, loss: 1.014, accuracy: 0.831\n",
      "epoch 18 iter 150, loss: 0.913, accuracy: 0.851\n",
      "epoch 18 iter 200, loss: 0.875, accuracy: 0.852\n",
      "epoch 18 iter 250, loss: 0.969, accuracy: 0.831\n",
      "epoch 19 iter 0, loss: 0.859, accuracy: 0.849\n",
      "epoch 19 iter 50, loss: 0.903, accuracy: 0.858\n",
      "epoch 19 iter 100, loss: 1.020, accuracy: 0.846\n",
      "epoch 19 iter 150, loss: 0.984, accuracy: 0.847\n",
      "epoch 19 iter 200, loss: 0.957, accuracy: 0.845\n",
      "epoch 19 iter 250, loss: 0.977, accuracy: 0.832\n",
      "epoch 20 iter 0, loss: 0.942, accuracy: 0.839\n",
      "epoch 20 iter 50, loss: 0.932, accuracy: 0.856\n",
      "epoch 20 iter 100, loss: 1.038, accuracy: 0.843\n",
      "epoch 20 iter 150, loss: 1.304, accuracy: 0.814\n",
      "epoch 20 iter 200, loss: 0.960, accuracy: 0.850\n",
      "epoch 20 iter 250, loss: 0.977, accuracy: 0.836\n",
      "epoch 21 iter 0, loss: 1.003, accuracy: 0.849\n",
      "epoch 21 iter 50, loss: 1.135, accuracy: 0.839\n",
      "epoch 21 iter 100, loss: 0.997, accuracy: 0.849\n",
      "epoch 21 iter 150, loss: 1.159, accuracy: 0.834\n",
      "epoch 21 iter 200, loss: 0.934, accuracy: 0.858\n",
      "epoch 21 iter 250, loss: 1.044, accuracy: 0.841\n",
      "epoch 22 iter 0, loss: 1.008, accuracy: 0.849\n",
      "epoch 22 iter 50, loss: 1.134, accuracy: 0.848\n",
      "epoch 22 iter 100, loss: 1.031, accuracy: 0.853\n",
      "epoch 22 iter 150, loss: 1.158, accuracy: 0.844\n",
      "epoch 22 iter 200, loss: 0.943, accuracy: 0.861\n",
      "epoch 22 iter 250, loss: 1.087, accuracy: 0.844\n",
      "epoch 23 iter 0, loss: 1.116, accuracy: 0.839\n",
      "epoch 23 iter 50, loss: 1.252, accuracy: 0.825\n",
      "epoch 23 iter 100, loss: 1.191, accuracy: 0.843\n",
      "epoch 23 iter 150, loss: 1.286, accuracy: 0.837\n",
      "epoch 23 iter 200, loss: 1.135, accuracy: 0.852\n",
      "epoch 23 iter 250, loss: 1.111, accuracy: 0.843\n",
      "epoch 24 iter 0, loss: 1.111, accuracy: 0.847\n",
      "epoch 24 iter 50, loss: 1.194, accuracy: 0.840\n",
      "epoch 24 iter 100, loss: 1.196, accuracy: 0.846\n",
      "epoch 24 iter 150, loss: 1.379, accuracy: 0.833\n",
      "epoch 24 iter 200, loss: 1.179, accuracy: 0.852\n",
      "epoch 24 iter 250, loss: 1.256, accuracy: 0.836\n",
      "epoch 25 iter 0, loss: 1.164, accuracy: 0.851\n",
      "epoch 25 iter 50, loss: 1.252, accuracy: 0.839\n",
      "epoch 25 iter 100, loss: 1.316, accuracy: 0.830\n",
      "epoch 25 iter 150, loss: 1.342, accuracy: 0.831\n",
      "epoch 25 iter 200, loss: 1.201, accuracy: 0.854\n",
      "epoch 25 iter 250, loss: 1.214, accuracy: 0.841\n",
      "epoch 26 iter 0, loss: 1.212, accuracy: 0.845\n",
      "epoch 26 iter 50, loss: 1.280, accuracy: 0.854\n",
      "epoch 26 iter 100, loss: 1.424, accuracy: 0.842\n",
      "epoch 26 iter 150, loss: 1.592, accuracy: 0.829\n",
      "epoch 26 iter 200, loss: 1.347, accuracy: 0.845\n",
      "epoch 26 iter 250, loss: 1.307, accuracy: 0.845\n",
      "epoch 27 iter 0, loss: 1.251, accuracy: 0.849\n",
      "epoch 27 iter 50, loss: 1.349, accuracy: 0.846\n",
      "epoch 27 iter 100, loss: 1.428, accuracy: 0.838\n",
      "epoch 27 iter 150, loss: 1.457, accuracy: 0.842\n",
      "epoch 27 iter 200, loss: 1.367, accuracy: 0.838\n",
      "epoch 27 iter 250, loss: 1.275, accuracy: 0.846\n",
      "epoch 28 iter 0, loss: 1.283, accuracy: 0.847\n",
      "epoch 28 iter 50, loss: 1.417, accuracy: 0.840\n",
      "epoch 28 iter 100, loss: 1.589, accuracy: 0.834\n",
      "epoch 28 iter 150, loss: 1.503, accuracy: 0.824\n",
      "epoch 28 iter 200, loss: 1.290, accuracy: 0.853\n",
      "epoch 28 iter 250, loss: 1.452, accuracy: 0.845\n",
      "epoch 29 iter 0, loss: 1.307, accuracy: 0.848\n",
      "epoch 29 iter 50, loss: 1.374, accuracy: 0.855\n",
      "epoch 29 iter 100, loss: 1.632, accuracy: 0.833\n",
      "epoch 29 iter 150, loss: 1.491, accuracy: 0.819\n",
      "epoch 29 iter 200, loss: 1.366, accuracy: 0.857\n",
      "epoch 29 iter 250, loss: 1.517, accuracy: 0.842\n",
      "epoch 30 iter 0, loss: 1.382, accuracy: 0.851\n",
      "epoch 30 iter 50, loss: 1.478, accuracy: 0.851\n",
      "epoch 30 iter 100, loss: 1.636, accuracy: 0.843\n",
      "epoch 30 iter 150, loss: 1.597, accuracy: 0.829\n",
      "epoch 30 iter 200, loss: 1.434, accuracy: 0.846\n",
      "epoch 30 iter 250, loss: 1.538, accuracy: 0.840\n",
      "epoch 31 iter 0, loss: 1.374, accuracy: 0.855\n",
      "epoch 31 iter 50, loss: 1.517, accuracy: 0.850\n",
      "epoch 31 iter 100, loss: 1.694, accuracy: 0.842\n",
      "epoch 31 iter 150, loss: 1.685, accuracy: 0.835\n",
      "epoch 31 iter 200, loss: 1.452, accuracy: 0.854\n",
      "epoch 31 iter 250, loss: 1.633, accuracy: 0.841\n",
      "epoch 32 iter 0, loss: 1.545, accuracy: 0.844\n",
      "epoch 32 iter 50, loss: 1.546, accuracy: 0.854\n",
      "epoch 32 iter 100, loss: 1.719, accuracy: 0.845\n",
      "epoch 32 iter 150, loss: 1.670, accuracy: 0.831\n",
      "epoch 32 iter 200, loss: 1.472, accuracy: 0.858\n",
      "epoch 32 iter 250, loss: 1.613, accuracy: 0.845\n",
      "epoch 33 iter 0, loss: 1.525, accuracy: 0.850\n",
      "epoch 33 iter 50, loss: 1.537, accuracy: 0.855\n",
      "epoch 33 iter 100, loss: 1.694, accuracy: 0.847\n",
      "epoch 33 iter 150, loss: 1.671, accuracy: 0.826\n",
      "epoch 33 iter 200, loss: 1.409, accuracy: 0.862\n",
      "epoch 33 iter 250, loss: 1.684, accuracy: 0.840\n",
      "epoch 34 iter 0, loss: 1.546, accuracy: 0.853\n",
      "epoch 34 iter 50, loss: 1.678, accuracy: 0.849\n",
      "epoch 34 iter 100, loss: 1.898, accuracy: 0.844\n",
      "epoch 34 iter 150, loss: 1.819, accuracy: 0.838\n",
      "epoch 34 iter 200, loss: 1.678, accuracy: 0.852\n",
      "epoch 34 iter 250, loss: 1.738, accuracy: 0.844\n",
      "epoch 35 iter 0, loss: 1.573, accuracy: 0.860\n",
      "epoch 35 iter 50, loss: 1.649, accuracy: 0.848\n",
      "epoch 35 iter 100, loss: 1.827, accuracy: 0.846\n",
      "epoch 35 iter 150, loss: 1.682, accuracy: 0.848\n",
      "epoch 35 iter 200, loss: 1.767, accuracy: 0.847\n",
      "epoch 35 iter 250, loss: 1.854, accuracy: 0.848\n",
      "epoch 36 iter 0, loss: 1.725, accuracy: 0.855\n",
      "epoch 36 iter 50, loss: 1.793, accuracy: 0.848\n",
      "epoch 36 iter 100, loss: 1.901, accuracy: 0.843\n",
      "epoch 36 iter 150, loss: 1.929, accuracy: 0.843\n",
      "epoch 36 iter 200, loss: 1.715, accuracy: 0.853\n",
      "epoch 36 iter 250, loss: 1.793, accuracy: 0.855\n",
      "epoch 37 iter 0, loss: 1.769, accuracy: 0.852\n",
      "epoch 37 iter 50, loss: 1.665, accuracy: 0.856\n",
      "epoch 37 iter 100, loss: 2.000, accuracy: 0.850\n",
      "epoch 37 iter 150, loss: 1.943, accuracy: 0.852\n",
      "epoch 37 iter 200, loss: 1.779, accuracy: 0.855\n",
      "epoch 37 iter 250, loss: 1.959, accuracy: 0.852\n",
      "epoch 38 iter 0, loss: 1.788, accuracy: 0.850\n",
      "epoch 38 iter 50, loss: 1.724, accuracy: 0.857\n",
      "epoch 38 iter 100, loss: 2.235, accuracy: 0.839\n",
      "epoch 38 iter 150, loss: 1.915, accuracy: 0.851\n",
      "epoch 38 iter 200, loss: 1.929, accuracy: 0.856\n",
      "epoch 38 iter 250, loss: 2.000, accuracy: 0.851\n",
      "epoch 39 iter 0, loss: 1.857, accuracy: 0.847\n",
      "epoch 39 iter 50, loss: 1.800, accuracy: 0.855\n",
      "epoch 39 iter 100, loss: 2.153, accuracy: 0.841\n",
      "epoch 39 iter 150, loss: 2.024, accuracy: 0.847\n",
      "epoch 39 iter 200, loss: 1.943, accuracy: 0.850\n",
      "epoch 39 iter 250, loss: 2.085, accuracy: 0.851\n",
      "epoch 40 iter 0, loss: 2.006, accuracy: 0.849\n",
      "epoch 40 iter 50, loss: 1.859, accuracy: 0.852\n",
      "epoch 40 iter 100, loss: 2.209, accuracy: 0.846\n",
      "epoch 40 iter 150, loss: 2.014, accuracy: 0.847\n",
      "epoch 40 iter 200, loss: 1.977, accuracy: 0.856\n",
      "epoch 40 iter 250, loss: 2.240, accuracy: 0.852\n",
      "epoch 41 iter 0, loss: 2.230, accuracy: 0.841\n",
      "epoch 41 iter 50, loss: 2.004, accuracy: 0.855\n",
      "epoch 41 iter 100, loss: 2.348, accuracy: 0.839\n",
      "epoch 41 iter 150, loss: 2.150, accuracy: 0.848\n",
      "epoch 41 iter 200, loss: 2.106, accuracy: 0.854\n",
      "epoch 41 iter 250, loss: 2.229, accuracy: 0.854\n",
      "epoch 42 iter 0, loss: 2.218, accuracy: 0.847\n",
      "epoch 42 iter 50, loss: 2.185, accuracy: 0.849\n",
      "epoch 42 iter 100, loss: 2.520, accuracy: 0.844\n",
      "epoch 42 iter 150, loss: 2.099, accuracy: 0.852\n",
      "epoch 42 iter 200, loss: 2.128, accuracy: 0.853\n",
      "epoch 42 iter 250, loss: 2.247, accuracy: 0.853\n",
      "epoch 43 iter 0, loss: 2.031, accuracy: 0.851\n",
      "epoch 43 iter 50, loss: 2.075, accuracy: 0.848\n",
      "epoch 43 iter 100, loss: 2.436, accuracy: 0.844\n",
      "epoch 43 iter 150, loss: 2.136, accuracy: 0.850\n",
      "epoch 43 iter 200, loss: 2.227, accuracy: 0.855\n",
      "epoch 43 iter 250, loss: 2.283, accuracy: 0.857\n",
      "epoch 44 iter 0, loss: 2.284, accuracy: 0.843\n",
      "epoch 44 iter 50, loss: 2.314, accuracy: 0.844\n",
      "epoch 44 iter 100, loss: 2.528, accuracy: 0.840\n",
      "epoch 44 iter 150, loss: 2.382, accuracy: 0.853\n",
      "epoch 44 iter 200, loss: 2.261, accuracy: 0.852\n",
      "epoch 44 iter 250, loss: 2.295, accuracy: 0.849\n",
      "epoch 45 iter 0, loss: 2.208, accuracy: 0.848\n",
      "epoch 45 iter 50, loss: 2.285, accuracy: 0.843\n",
      "epoch 45 iter 100, loss: 2.721, accuracy: 0.841\n",
      "epoch 45 iter 150, loss: 2.419, accuracy: 0.856\n",
      "epoch 45 iter 200, loss: 2.414, accuracy: 0.851\n",
      "epoch 45 iter 250, loss: 2.348, accuracy: 0.850\n",
      "epoch 46 iter 0, loss: 2.219, accuracy: 0.854\n",
      "epoch 46 iter 50, loss: 2.348, accuracy: 0.838\n",
      "epoch 46 iter 100, loss: 2.672, accuracy: 0.848\n",
      "epoch 46 iter 150, loss: 2.184, accuracy: 0.848\n",
      "epoch 46 iter 200, loss: 2.453, accuracy: 0.846\n",
      "epoch 46 iter 250, loss: 2.374, accuracy: 0.856\n",
      "epoch 47 iter 0, loss: 2.306, accuracy: 0.858\n",
      "epoch 47 iter 50, loss: 2.472, accuracy: 0.840\n",
      "epoch 47 iter 100, loss: 2.776, accuracy: 0.837\n",
      "epoch 47 iter 150, loss: 2.476, accuracy: 0.846\n",
      "epoch 47 iter 200, loss: 2.451, accuracy: 0.848\n",
      "epoch 47 iter 250, loss: 2.411, accuracy: 0.853\n",
      "epoch 48 iter 0, loss: 2.411, accuracy: 0.850\n",
      "epoch 48 iter 50, loss: 2.296, accuracy: 0.851\n",
      "epoch 48 iter 100, loss: 2.590, accuracy: 0.848\n",
      "epoch 48 iter 150, loss: 2.411, accuracy: 0.855\n",
      "epoch 48 iter 200, loss: 2.437, accuracy: 0.850\n",
      "epoch 48 iter 250, loss: 2.518, accuracy: 0.853\n",
      "epoch 49 iter 0, loss: 2.535, accuracy: 0.855\n",
      "epoch 49 iter 50, loss: 2.481, accuracy: 0.856\n",
      "epoch 49 iter 100, loss: 2.907, accuracy: 0.846\n",
      "epoch 49 iter 150, loss: 2.550, accuracy: 0.851\n",
      "epoch 49 iter 200, loss: 2.665, accuracy: 0.851\n",
      "epoch 49 iter 250, loss: 2.750, accuracy: 0.852\n",
      "epoch 50 iter 0, loss: 2.543, accuracy: 0.851\n",
      "epoch 50 iter 50, loss: 2.560, accuracy: 0.847\n",
      "epoch 50 iter 100, loss: 2.910, accuracy: 0.839\n",
      "epoch 50 iter 150, loss: 2.652, accuracy: 0.846\n",
      "epoch 50 iter 200, loss: 2.842, accuracy: 0.847\n",
      "epoch 50 iter 250, loss: 2.749, accuracy: 0.850\n",
      "epoch 51 iter 0, loss: 2.378, accuracy: 0.857\n",
      "epoch 51 iter 50, loss: 2.641, accuracy: 0.842\n",
      "epoch 51 iter 100, loss: 2.966, accuracy: 0.849\n",
      "epoch 51 iter 150, loss: 2.635, accuracy: 0.847\n",
      "epoch 51 iter 200, loss: 2.899, accuracy: 0.851\n",
      "epoch 51 iter 250, loss: 2.623, accuracy: 0.856\n",
      "epoch 52 iter 0, loss: 2.476, accuracy: 0.854\n",
      "epoch 52 iter 50, loss: 2.683, accuracy: 0.852\n",
      "epoch 52 iter 100, loss: 3.095, accuracy: 0.846\n",
      "epoch 52 iter 150, loss: 2.696, accuracy: 0.848\n",
      "epoch 52 iter 200, loss: 2.744, accuracy: 0.850\n",
      "epoch 52 iter 250, loss: 2.875, accuracy: 0.854\n",
      "epoch 53 iter 0, loss: 2.570, accuracy: 0.854\n",
      "epoch 53 iter 50, loss: 2.661, accuracy: 0.853\n",
      "epoch 53 iter 100, loss: 2.798, accuracy: 0.855\n",
      "epoch 53 iter 150, loss: 2.700, accuracy: 0.854\n",
      "epoch 53 iter 200, loss: 2.755, accuracy: 0.855\n",
      "epoch 53 iter 250, loss: 2.865, accuracy: 0.855\n",
      "epoch 54 iter 0, loss: 2.382, accuracy: 0.856\n",
      "epoch 54 iter 50, loss: 2.973, accuracy: 0.832\n",
      "epoch 54 iter 100, loss: 2.736, accuracy: 0.859\n",
      "epoch 54 iter 150, loss: 2.722, accuracy: 0.857\n",
      "epoch 54 iter 200, loss: 2.667, accuracy: 0.857\n",
      "epoch 54 iter 250, loss: 2.874, accuracy: 0.860\n",
      "epoch 55 iter 0, loss: 2.568, accuracy: 0.861\n",
      "epoch 55 iter 50, loss: 2.943, accuracy: 0.843\n",
      "epoch 55 iter 100, loss: 2.960, accuracy: 0.853\n",
      "epoch 55 iter 150, loss: 3.015, accuracy: 0.856\n",
      "epoch 55 iter 200, loss: 2.868, accuracy: 0.859\n",
      "epoch 55 iter 250, loss: 2.853, accuracy: 0.862\n",
      "epoch 56 iter 0, loss: 2.740, accuracy: 0.861\n",
      "epoch 56 iter 50, loss: 2.976, accuracy: 0.850\n",
      "epoch 56 iter 100, loss: 3.026, accuracy: 0.856\n",
      "epoch 56 iter 150, loss: 2.969, accuracy: 0.854\n",
      "epoch 56 iter 200, loss: 2.850, accuracy: 0.859\n",
      "epoch 56 iter 250, loss: 2.962, accuracy: 0.858\n",
      "epoch 57 iter 0, loss: 2.932, accuracy: 0.861\n",
      "epoch 57 iter 50, loss: 3.139, accuracy: 0.855\n",
      "epoch 57 iter 100, loss: 3.019, accuracy: 0.855\n",
      "epoch 57 iter 150, loss: 3.006, accuracy: 0.852\n",
      "epoch 57 iter 200, loss: 3.130, accuracy: 0.853\n",
      "epoch 57 iter 250, loss: 3.007, accuracy: 0.856\n",
      "epoch 58 iter 0, loss: 2.803, accuracy: 0.862\n",
      "epoch 58 iter 50, loss: 2.940, accuracy: 0.858\n",
      "epoch 58 iter 100, loss: 3.385, accuracy: 0.851\n",
      "epoch 58 iter 150, loss: 3.004, accuracy: 0.854\n",
      "epoch 58 iter 200, loss: 3.015, accuracy: 0.857\n",
      "epoch 58 iter 250, loss: 3.194, accuracy: 0.859\n",
      "epoch 59 iter 0, loss: 2.823, accuracy: 0.855\n",
      "epoch 59 iter 50, loss: 3.014, accuracy: 0.860\n",
      "epoch 59 iter 100, loss: 3.268, accuracy: 0.849\n",
      "epoch 59 iter 150, loss: 3.011, accuracy: 0.847\n",
      "epoch 59 iter 200, loss: 3.163, accuracy: 0.855\n",
      "epoch 59 iter 250, loss: 3.117, accuracy: 0.854\n",
      "epoch 60 iter 0, loss: 2.895, accuracy: 0.856\n",
      "epoch 60 iter 50, loss: 3.273, accuracy: 0.856\n",
      "epoch 60 iter 100, loss: 3.552, accuracy: 0.849\n",
      "epoch 60 iter 150, loss: 3.062, accuracy: 0.850\n",
      "epoch 60 iter 200, loss: 3.205, accuracy: 0.854\n",
      "epoch 60 iter 250, loss: 3.187, accuracy: 0.856\n",
      "epoch 61 iter 0, loss: 3.232, accuracy: 0.851\n",
      "epoch 61 iter 50, loss: 3.212, accuracy: 0.850\n",
      "epoch 61 iter 100, loss: 3.282, accuracy: 0.855\n",
      "epoch 61 iter 150, loss: 3.111, accuracy: 0.855\n",
      "epoch 61 iter 200, loss: 3.128, accuracy: 0.854\n",
      "epoch 61 iter 250, loss: 3.270, accuracy: 0.862\n",
      "epoch 62 iter 0, loss: 3.257, accuracy: 0.857\n",
      "epoch 62 iter 50, loss: 3.293, accuracy: 0.854\n",
      "epoch 62 iter 100, loss: 3.291, accuracy: 0.855\n",
      "epoch 62 iter 150, loss: 3.514, accuracy: 0.843\n",
      "epoch 62 iter 200, loss: 3.253, accuracy: 0.857\n",
      "epoch 62 iter 250, loss: 3.433, accuracy: 0.854\n",
      "epoch 63 iter 0, loss: 3.143, accuracy: 0.859\n",
      "epoch 63 iter 50, loss: 3.358, accuracy: 0.855\n",
      "epoch 63 iter 100, loss: 3.584, accuracy: 0.854\n",
      "epoch 63 iter 150, loss: 3.356, accuracy: 0.853\n",
      "epoch 63 iter 200, loss: 3.554, accuracy: 0.857\n",
      "epoch 63 iter 250, loss: 3.747, accuracy: 0.849\n",
      "epoch 64 iter 0, loss: 3.320, accuracy: 0.857\n",
      "epoch 64 iter 50, loss: 3.592, accuracy: 0.849\n",
      "epoch 64 iter 100, loss: 3.418, accuracy: 0.856\n",
      "epoch 64 iter 150, loss: 3.171, accuracy: 0.856\n",
      "epoch 64 iter 200, loss: 3.244, accuracy: 0.853\n",
      "epoch 64 iter 250, loss: 3.525, accuracy: 0.853\n",
      "epoch 65 iter 0, loss: 3.210, accuracy: 0.857\n",
      "epoch 65 iter 50, loss: 3.155, accuracy: 0.856\n",
      "epoch 65 iter 100, loss: 3.568, accuracy: 0.855\n",
      "epoch 65 iter 150, loss: 3.297, accuracy: 0.852\n",
      "epoch 65 iter 200, loss: 3.249, accuracy: 0.855\n",
      "epoch 65 iter 250, loss: 3.467, accuracy: 0.859\n",
      "epoch 66 iter 0, loss: 3.283, accuracy: 0.856\n",
      "epoch 66 iter 50, loss: 3.200, accuracy: 0.859\n",
      "epoch 66 iter 100, loss: 3.861, accuracy: 0.853\n",
      "epoch 66 iter 150, loss: 3.298, accuracy: 0.852\n",
      "epoch 66 iter 200, loss: 3.370, accuracy: 0.854\n",
      "epoch 66 iter 250, loss: 3.441, accuracy: 0.857\n",
      "epoch 67 iter 0, loss: 3.453, accuracy: 0.858\n",
      "epoch 67 iter 50, loss: 3.477, accuracy: 0.852\n",
      "epoch 67 iter 100, loss: 3.920, accuracy: 0.853\n",
      "epoch 67 iter 150, loss: 3.491, accuracy: 0.853\n",
      "epoch 67 iter 200, loss: 3.600, accuracy: 0.853\n",
      "epoch 67 iter 250, loss: 3.553, accuracy: 0.853\n",
      "epoch 68 iter 0, loss: 3.190, accuracy: 0.856\n",
      "epoch 68 iter 50, loss: 3.597, accuracy: 0.854\n",
      "epoch 68 iter 100, loss: 3.751, accuracy: 0.854\n",
      "epoch 68 iter 150, loss: 3.376, accuracy: 0.853\n",
      "epoch 68 iter 200, loss: 3.458, accuracy: 0.852\n",
      "epoch 68 iter 250, loss: 3.409, accuracy: 0.858\n",
      "epoch 69 iter 0, loss: 3.270, accuracy: 0.859\n",
      "epoch 69 iter 50, loss: 3.270, accuracy: 0.856\n",
      "epoch 69 iter 100, loss: 3.342, accuracy: 0.858\n",
      "epoch 69 iter 150, loss: 3.622, accuracy: 0.851\n",
      "epoch 69 iter 200, loss: 3.475, accuracy: 0.856\n",
      "epoch 69 iter 250, loss: 3.623, accuracy: 0.861\n",
      "epoch 70 iter 0, loss: 3.468, accuracy: 0.859\n",
      "epoch 70 iter 50, loss: 3.559, accuracy: 0.854\n",
      "epoch 70 iter 100, loss: 3.762, accuracy: 0.858\n",
      "epoch 70 iter 150, loss: 3.961, accuracy: 0.847\n",
      "epoch 70 iter 200, loss: 3.483, accuracy: 0.853\n",
      "epoch 70 iter 250, loss: 3.493, accuracy: 0.861\n",
      "epoch 71 iter 0, loss: 3.615, accuracy: 0.859\n",
      "epoch 71 iter 50, loss: 3.654, accuracy: 0.857\n",
      "epoch 71 iter 100, loss: 3.839, accuracy: 0.854\n",
      "epoch 71 iter 150, loss: 3.725, accuracy: 0.850\n",
      "epoch 71 iter 200, loss: 3.926, accuracy: 0.857\n",
      "epoch 71 iter 250, loss: 3.738, accuracy: 0.859\n",
      "epoch 72 iter 0, loss: 3.724, accuracy: 0.860\n",
      "epoch 72 iter 50, loss: 3.527, accuracy: 0.853\n",
      "epoch 72 iter 100, loss: 3.772, accuracy: 0.857\n",
      "epoch 72 iter 150, loss: 3.827, accuracy: 0.857\n",
      "epoch 72 iter 200, loss: 3.680, accuracy: 0.848\n",
      "epoch 72 iter 250, loss: 3.691, accuracy: 0.856\n",
      "epoch 73 iter 0, loss: 3.381, accuracy: 0.862\n",
      "epoch 73 iter 50, loss: 3.842, accuracy: 0.856\n",
      "epoch 73 iter 100, loss: 3.760, accuracy: 0.853\n",
      "epoch 73 iter 150, loss: 3.632, accuracy: 0.855\n",
      "epoch 73 iter 200, loss: 3.572, accuracy: 0.856\n",
      "epoch 73 iter 250, loss: 3.682, accuracy: 0.859\n",
      "epoch 74 iter 0, loss: 3.650, accuracy: 0.858\n",
      "epoch 74 iter 50, loss: 3.783, accuracy: 0.855\n",
      "epoch 74 iter 100, loss: 3.669, accuracy: 0.858\n",
      "epoch 74 iter 150, loss: 3.858, accuracy: 0.847\n",
      "epoch 74 iter 200, loss: 3.754, accuracy: 0.856\n",
      "epoch 74 iter 250, loss: 3.900, accuracy: 0.861\n",
      "epoch 75 iter 0, loss: 3.602, accuracy: 0.860\n",
      "epoch 75 iter 50, loss: 4.147, accuracy: 0.848\n",
      "epoch 75 iter 100, loss: 3.954, accuracy: 0.854\n",
      "epoch 75 iter 150, loss: 3.755, accuracy: 0.855\n",
      "epoch 75 iter 200, loss: 3.676, accuracy: 0.855\n",
      "epoch 75 iter 250, loss: 3.751, accuracy: 0.858\n",
      "epoch 76 iter 0, loss: 3.611, accuracy: 0.855\n",
      "epoch 76 iter 50, loss: 3.716, accuracy: 0.853\n",
      "epoch 76 iter 100, loss: 3.777, accuracy: 0.857\n",
      "epoch 76 iter 150, loss: 3.856, accuracy: 0.853\n",
      "epoch 76 iter 200, loss: 3.503, accuracy: 0.855\n",
      "epoch 76 iter 250, loss: 3.873, accuracy: 0.845\n",
      "epoch 77 iter 0, loss: 3.761, accuracy: 0.855\n",
      "epoch 77 iter 50, loss: 3.708, accuracy: 0.862\n",
      "epoch 77 iter 100, loss: 3.640, accuracy: 0.858\n",
      "epoch 77 iter 150, loss: 4.084, accuracy: 0.861\n",
      "epoch 77 iter 200, loss: 3.653, accuracy: 0.861\n",
      "epoch 77 iter 250, loss: 4.029, accuracy: 0.862\n",
      "epoch 78 iter 0, loss: 3.859, accuracy: 0.862\n",
      "epoch 78 iter 50, loss: 4.078, accuracy: 0.861\n",
      "epoch 78 iter 100, loss: 4.123, accuracy: 0.862\n",
      "epoch 78 iter 150, loss: 3.974, accuracy: 0.860\n",
      "epoch 78 iter 200, loss: 3.840, accuracy: 0.856\n",
      "epoch 78 iter 250, loss: 4.464, accuracy: 0.854\n",
      "epoch 79 iter 0, loss: 4.089, accuracy: 0.861\n",
      "epoch 79 iter 50, loss: 4.373, accuracy: 0.855\n",
      "epoch 79 iter 100, loss: 3.945, accuracy: 0.860\n",
      "epoch 79 iter 150, loss: 4.039, accuracy: 0.859\n",
      "epoch 79 iter 200, loss: 4.158, accuracy: 0.855\n",
      "epoch 79 iter 250, loss: 4.430, accuracy: 0.855\n",
      "epoch 80 iter 0, loss: 3.781, accuracy: 0.854\n",
      "epoch 80 iter 50, loss: 4.104, accuracy: 0.852\n",
      "epoch 80 iter 100, loss: 4.100, accuracy: 0.854\n",
      "epoch 80 iter 150, loss: 4.106, accuracy: 0.858\n",
      "epoch 80 iter 200, loss: 4.207, accuracy: 0.852\n",
      "epoch 80 iter 250, loss: 4.186, accuracy: 0.858\n",
      "epoch 81 iter 0, loss: 4.286, accuracy: 0.857\n",
      "epoch 81 iter 50, loss: 4.368, accuracy: 0.857\n",
      "epoch 81 iter 100, loss: 4.282, accuracy: 0.856\n",
      "epoch 81 iter 150, loss: 4.304, accuracy: 0.855\n",
      "epoch 81 iter 200, loss: 4.193, accuracy: 0.856\n",
      "epoch 81 iter 250, loss: 4.672, accuracy: 0.851\n",
      "epoch 82 iter 0, loss: 4.145, accuracy: 0.851\n",
      "epoch 82 iter 50, loss: 4.224, accuracy: 0.859\n",
      "epoch 82 iter 100, loss: 4.743, accuracy: 0.850\n",
      "epoch 82 iter 150, loss: 4.178, accuracy: 0.855\n",
      "epoch 82 iter 200, loss: 4.087, accuracy: 0.858\n",
      "epoch 82 iter 250, loss: 4.396, accuracy: 0.858\n",
      "epoch 83 iter 0, loss: 4.194, accuracy: 0.853\n",
      "epoch 83 iter 50, loss: 4.474, accuracy: 0.850\n",
      "epoch 83 iter 100, loss: 4.784, accuracy: 0.858\n",
      "epoch 83 iter 150, loss: 4.556, accuracy: 0.854\n",
      "epoch 83 iter 200, loss: 4.313, accuracy: 0.853\n",
      "epoch 83 iter 250, loss: 4.450, accuracy: 0.858\n",
      "epoch 84 iter 0, loss: 4.139, accuracy: 0.862\n",
      "epoch 84 iter 50, loss: 4.327, accuracy: 0.861\n",
      "epoch 84 iter 100, loss: 4.547, accuracy: 0.863\n",
      "epoch 84 iter 150, loss: 4.854, accuracy: 0.859\n",
      "epoch 84 iter 200, loss: 4.099, accuracy: 0.855\n",
      "epoch 84 iter 250, loss: 4.654, accuracy: 0.858\n",
      "epoch 85 iter 0, loss: 4.200, accuracy: 0.859\n",
      "epoch 85 iter 50, loss: 4.383, accuracy: 0.864\n",
      "epoch 85 iter 100, loss: 5.001, accuracy: 0.853\n",
      "epoch 85 iter 150, loss: 4.432, accuracy: 0.864\n",
      "epoch 85 iter 200, loss: 4.815, accuracy: 0.838\n",
      "epoch 85 iter 250, loss: 5.108, accuracy: 0.854\n",
      "epoch 86 iter 0, loss: 4.620, accuracy: 0.859\n",
      "epoch 86 iter 50, loss: 4.515, accuracy: 0.861\n",
      "epoch 86 iter 100, loss: 4.602, accuracy: 0.855\n",
      "epoch 86 iter 150, loss: 4.913, accuracy: 0.856\n",
      "epoch 86 iter 200, loss: 4.818, accuracy: 0.850\n",
      "epoch 86 iter 250, loss: 4.962, accuracy: 0.856\n",
      "epoch 87 iter 0, loss: 4.496, accuracy: 0.858\n",
      "epoch 87 iter 50, loss: 4.716, accuracy: 0.854\n",
      "epoch 87 iter 100, loss: 4.807, accuracy: 0.857\n",
      "epoch 87 iter 150, loss: 4.418, accuracy: 0.855\n",
      "epoch 87 iter 200, loss: 4.740, accuracy: 0.847\n",
      "epoch 87 iter 250, loss: 5.088, accuracy: 0.852\n",
      "epoch 88 iter 0, loss: 4.376, accuracy: 0.860\n",
      "epoch 88 iter 50, loss: 4.892, accuracy: 0.856\n",
      "epoch 88 iter 100, loss: 4.607, accuracy: 0.857\n",
      "epoch 88 iter 150, loss: 4.851, accuracy: 0.852\n",
      "epoch 88 iter 200, loss: 4.321, accuracy: 0.858\n",
      "epoch 88 iter 250, loss: 4.633, accuracy: 0.857\n",
      "epoch 89 iter 0, loss: 4.951, accuracy: 0.857\n",
      "epoch 89 iter 50, loss: 4.706, accuracy: 0.857\n",
      "epoch 89 iter 100, loss: 4.611, accuracy: 0.851\n",
      "epoch 89 iter 150, loss: 4.913, accuracy: 0.856\n",
      "epoch 89 iter 200, loss: 4.777, accuracy: 0.857\n",
      "epoch 89 iter 250, loss: 4.758, accuracy: 0.856\n",
      "epoch 90 iter 0, loss: 4.623, accuracy: 0.861\n",
      "epoch 90 iter 50, loss: 4.921, accuracy: 0.862\n",
      "epoch 90 iter 100, loss: 4.585, accuracy: 0.860\n",
      "epoch 90 iter 150, loss: 4.822, accuracy: 0.858\n",
      "epoch 90 iter 200, loss: 4.615, accuracy: 0.856\n",
      "epoch 90 iter 250, loss: 5.348, accuracy: 0.851\n",
      "epoch 91 iter 0, loss: 4.902, accuracy: 0.850\n",
      "epoch 91 iter 50, loss: 5.187, accuracy: 0.848\n",
      "epoch 91 iter 100, loss: 4.698, accuracy: 0.858\n",
      "epoch 91 iter 150, loss: 5.062, accuracy: 0.860\n",
      "epoch 91 iter 200, loss: 5.012, accuracy: 0.860\n",
      "epoch 91 iter 250, loss: 5.283, accuracy: 0.857\n",
      "epoch 92 iter 0, loss: 4.853, accuracy: 0.861\n",
      "epoch 92 iter 50, loss: 5.280, accuracy: 0.849\n",
      "epoch 92 iter 100, loss: 5.240, accuracy: 0.858\n",
      "epoch 92 iter 150, loss: 5.382, accuracy: 0.858\n",
      "epoch 92 iter 200, loss: 4.716, accuracy: 0.856\n",
      "epoch 92 iter 250, loss: 5.337, accuracy: 0.861\n",
      "epoch 93 iter 0, loss: 5.221, accuracy: 0.863\n",
      "epoch 93 iter 50, loss: 5.295, accuracy: 0.858\n",
      "epoch 93 iter 100, loss: 5.057, accuracy: 0.855\n",
      "epoch 93 iter 150, loss: 5.017, accuracy: 0.852\n",
      "epoch 93 iter 200, loss: 4.998, accuracy: 0.854\n",
      "epoch 93 iter 250, loss: 5.317, accuracy: 0.858\n",
      "epoch 94 iter 0, loss: 4.857, accuracy: 0.849\n",
      "epoch 94 iter 50, loss: 4.999, accuracy: 0.848\n",
      "epoch 94 iter 100, loss: 4.866, accuracy: 0.860\n",
      "epoch 94 iter 150, loss: 5.940, accuracy: 0.856\n",
      "epoch 94 iter 200, loss: 5.404, accuracy: 0.857\n",
      "epoch 94 iter 250, loss: 5.292, accuracy: 0.856\n",
      "epoch 95 iter 0, loss: 4.875, accuracy: 0.857\n",
      "epoch 95 iter 50, loss: 5.193, accuracy: 0.853\n",
      "epoch 95 iter 100, loss: 5.140, accuracy: 0.856\n",
      "epoch 95 iter 150, loss: 5.582, accuracy: 0.855\n",
      "epoch 95 iter 200, loss: 5.171, accuracy: 0.854\n",
      "epoch 95 iter 250, loss: 5.400, accuracy: 0.855\n",
      "epoch 96 iter 0, loss: 5.335, accuracy: 0.858\n",
      "epoch 96 iter 50, loss: 5.713, accuracy: 0.857\n",
      "epoch 96 iter 100, loss: 5.132, accuracy: 0.860\n",
      "epoch 96 iter 150, loss: 5.231, accuracy: 0.856\n",
      "epoch 96 iter 200, loss: 5.295, accuracy: 0.861\n",
      "epoch 96 iter 250, loss: 5.517, accuracy: 0.858\n",
      "epoch 97 iter 0, loss: 5.384, accuracy: 0.860\n",
      "epoch 97 iter 50, loss: 5.485, accuracy: 0.859\n",
      "epoch 97 iter 100, loss: 5.653, accuracy: 0.850\n",
      "epoch 97 iter 150, loss: 5.550, accuracy: 0.855\n",
      "epoch 97 iter 200, loss: 5.196, accuracy: 0.857\n",
      "epoch 97 iter 250, loss: 5.720, accuracy: 0.857\n",
      "epoch 98 iter 0, loss: 5.867, accuracy: 0.858\n",
      "epoch 98 iter 50, loss: 5.683, accuracy: 0.861\n",
      "epoch 98 iter 100, loss: 5.666, accuracy: 0.862\n",
      "epoch 98 iter 150, loss: 5.789, accuracy: 0.854\n",
      "epoch 98 iter 200, loss: 5.278, accuracy: 0.853\n",
      "epoch 98 iter 250, loss: 5.959, accuracy: 0.859\n",
      "epoch 99 iter 0, loss: 5.663, accuracy: 0.859\n",
      "epoch 99 iter 50, loss: 5.697, accuracy: 0.852\n",
      "epoch 99 iter 100, loss: 5.698, accuracy: 0.856\n",
      "epoch 99 iter 150, loss: 5.164, accuracy: 0.847\n",
      "epoch 99 iter 200, loss: 5.425, accuracy: 0.856\n",
      "epoch 99 iter 250, loss: 6.395, accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=1,\n",
    "            filters=64,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=1,\n",
    "            filters=64, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 161.557, accuracy: 0.111\n",
      "epoch 0 iter 70, loss: 2.245, accuracy: 0.196\n",
      "epoch 0 iter 140, loss: 2.232, accuracy: 0.196\n",
      "epoch 0 iter 210, loss: 2.225, accuracy: 0.196\n",
      "epoch 0 iter 280, loss: 2.222, accuracy: 0.196\n",
      "epoch 1 iter 0, loss: 2.223, accuracy: 0.196\n",
      "epoch 1 iter 70, loss: 2.219, accuracy: 0.197\n",
      "epoch 1 iter 140, loss: 2.221, accuracy: 0.197\n",
      "epoch 1 iter 210, loss: 2.215, accuracy: 0.199\n",
      "epoch 1 iter 280, loss: 2.215, accuracy: 0.199\n",
      "epoch 2 iter 0, loss: 2.212, accuracy: 0.199\n",
      "epoch 2 iter 70, loss: 2.216, accuracy: 0.196\n",
      "epoch 2 iter 140, loss: 2.202, accuracy: 0.206\n",
      "epoch 2 iter 210, loss: 2.190, accuracy: 0.223\n",
      "epoch 2 iter 280, loss: 2.148, accuracy: 0.248\n",
      "epoch 3 iter 0, loss: 2.147, accuracy: 0.241\n",
      "epoch 3 iter 70, loss: 2.205, accuracy: 0.204\n",
      "epoch 3 iter 140, loss: 2.147, accuracy: 0.244\n",
      "epoch 3 iter 210, loss: 2.120, accuracy: 0.279\n",
      "epoch 3 iter 280, loss: 1.382, accuracy: 0.555\n",
      "epoch 4 iter 0, loss: 1.359, accuracy: 0.572\n",
      "epoch 4 iter 70, loss: 1.184, accuracy: 0.637\n",
      "epoch 4 iter 140, loss: 1.082, accuracy: 0.673\n",
      "epoch 4 iter 210, loss: 1.037, accuracy: 0.684\n",
      "epoch 4 iter 280, loss: 1.002, accuracy: 0.702\n",
      "epoch 5 iter 0, loss: 0.992, accuracy: 0.704\n",
      "epoch 5 iter 70, loss: 0.978, accuracy: 0.711\n",
      "epoch 5 iter 140, loss: 0.965, accuracy: 0.718\n",
      "epoch 5 iter 210, loss: 0.938, accuracy: 0.721\n",
      "epoch 5 iter 280, loss: 0.944, accuracy: 0.724\n",
      "epoch 6 iter 0, loss: 0.963, accuracy: 0.718\n",
      "epoch 6 iter 70, loss: 0.975, accuracy: 0.713\n",
      "epoch 6 iter 140, loss: 0.928, accuracy: 0.738\n",
      "epoch 6 iter 210, loss: 0.916, accuracy: 0.732\n",
      "epoch 6 iter 280, loss: 0.891, accuracy: 0.746\n",
      "epoch 7 iter 0, loss: 0.919, accuracy: 0.733\n",
      "epoch 7 iter 70, loss: 0.889, accuracy: 0.746\n",
      "epoch 7 iter 140, loss: 0.903, accuracy: 0.748\n",
      "epoch 7 iter 210, loss: 0.951, accuracy: 0.724\n",
      "epoch 7 iter 280, loss: 0.874, accuracy: 0.752\n",
      "epoch 8 iter 0, loss: 0.850, accuracy: 0.761\n",
      "epoch 8 iter 70, loss: 0.886, accuracy: 0.750\n",
      "epoch 8 iter 140, loss: 0.852, accuracy: 0.765\n",
      "epoch 8 iter 210, loss: 0.882, accuracy: 0.750\n",
      "epoch 8 iter 280, loss: 0.842, accuracy: 0.766\n",
      "epoch 9 iter 0, loss: 0.824, accuracy: 0.774\n",
      "epoch 9 iter 70, loss: 0.999, accuracy: 0.718\n",
      "epoch 9 iter 140, loss: 0.934, accuracy: 0.752\n",
      "epoch 9 iter 210, loss: 0.848, accuracy: 0.768\n",
      "epoch 9 iter 280, loss: 0.854, accuracy: 0.772\n",
      "epoch 10 iter 0, loss: 0.839, accuracy: 0.778\n",
      "epoch 10 iter 70, loss: 0.896, accuracy: 0.767\n",
      "epoch 10 iter 140, loss: 0.849, accuracy: 0.778\n",
      "epoch 10 iter 210, loss: 0.812, accuracy: 0.787\n",
      "epoch 10 iter 280, loss: 0.834, accuracy: 0.782\n",
      "epoch 11 iter 0, loss: 0.899, accuracy: 0.759\n",
      "epoch 11 iter 70, loss: 0.876, accuracy: 0.776\n",
      "epoch 11 iter 140, loss: 0.884, accuracy: 0.766\n",
      "epoch 11 iter 210, loss: 0.824, accuracy: 0.791\n",
      "epoch 11 iter 280, loss: 0.840, accuracy: 0.793\n",
      "epoch 12 iter 0, loss: 0.900, accuracy: 0.764\n",
      "epoch 12 iter 70, loss: 0.905, accuracy: 0.769\n",
      "epoch 12 iter 140, loss: 0.855, accuracy: 0.788\n",
      "epoch 12 iter 210, loss: 0.846, accuracy: 0.792\n",
      "epoch 12 iter 280, loss: 0.943, accuracy: 0.782\n",
      "epoch 13 iter 0, loss: 0.898, accuracy: 0.776\n",
      "epoch 13 iter 70, loss: 0.876, accuracy: 0.795\n",
      "epoch 13 iter 140, loss: 0.837, accuracy: 0.796\n",
      "epoch 13 iter 210, loss: 0.853, accuracy: 0.793\n",
      "epoch 13 iter 280, loss: 0.939, accuracy: 0.789\n",
      "epoch 14 iter 0, loss: 0.908, accuracy: 0.791\n",
      "epoch 14 iter 70, loss: 0.917, accuracy: 0.790\n",
      "epoch 14 iter 140, loss: 0.898, accuracy: 0.789\n",
      "epoch 14 iter 210, loss: 0.910, accuracy: 0.786\n",
      "epoch 14 iter 280, loss: 0.968, accuracy: 0.788\n",
      "epoch 15 iter 0, loss: 1.112, accuracy: 0.769\n",
      "epoch 15 iter 70, loss: 0.928, accuracy: 0.794\n",
      "epoch 15 iter 140, loss: 0.922, accuracy: 0.788\n",
      "epoch 15 iter 210, loss: 0.978, accuracy: 0.789\n",
      "epoch 15 iter 280, loss: 0.956, accuracy: 0.792\n",
      "epoch 16 iter 0, loss: 0.943, accuracy: 0.798\n",
      "epoch 16 iter 70, loss: 0.947, accuracy: 0.786\n",
      "epoch 16 iter 140, loss: 0.982, accuracy: 0.781\n",
      "epoch 16 iter 210, loss: 1.006, accuracy: 0.792\n",
      "epoch 16 iter 280, loss: 0.993, accuracy: 0.794\n",
      "epoch 17 iter 0, loss: 1.016, accuracy: 0.789\n",
      "epoch 17 iter 70, loss: 0.977, accuracy: 0.805\n",
      "epoch 17 iter 140, loss: 1.011, accuracy: 0.780\n",
      "epoch 17 iter 210, loss: 1.004, accuracy: 0.803\n",
      "epoch 17 iter 280, loss: 1.043, accuracy: 0.794\n",
      "epoch 18 iter 0, loss: 1.116, accuracy: 0.773\n",
      "epoch 18 iter 70, loss: 1.071, accuracy: 0.787\n",
      "epoch 18 iter 140, loss: 1.017, accuracy: 0.796\n",
      "epoch 18 iter 210, loss: 1.079, accuracy: 0.788\n",
      "epoch 18 iter 280, loss: 1.100, accuracy: 0.793\n",
      "epoch 19 iter 0, loss: 1.176, accuracy: 0.785\n",
      "epoch 19 iter 70, loss: 1.119, accuracy: 0.793\n",
      "epoch 19 iter 140, loss: 1.108, accuracy: 0.794\n",
      "epoch 19 iter 210, loss: 1.096, accuracy: 0.795\n",
      "epoch 19 iter 280, loss: 1.152, accuracy: 0.791\n",
      "epoch 20 iter 0, loss: 1.160, accuracy: 0.792\n",
      "epoch 20 iter 70, loss: 1.192, accuracy: 0.780\n",
      "epoch 20 iter 140, loss: 1.140, accuracy: 0.798\n",
      "epoch 20 iter 210, loss: 1.128, accuracy: 0.803\n",
      "epoch 20 iter 280, loss: 1.225, accuracy: 0.783\n",
      "epoch 21 iter 0, loss: 1.140, accuracy: 0.797\n",
      "epoch 21 iter 70, loss: 1.175, accuracy: 0.778\n",
      "epoch 21 iter 140, loss: 1.178, accuracy: 0.797\n",
      "epoch 21 iter 210, loss: 1.164, accuracy: 0.804\n",
      "epoch 21 iter 280, loss: 1.285, accuracy: 0.787\n",
      "epoch 22 iter 0, loss: 1.222, accuracy: 0.794\n",
      "epoch 22 iter 70, loss: 1.250, accuracy: 0.773\n",
      "epoch 22 iter 140, loss: 1.299, accuracy: 0.784\n",
      "epoch 22 iter 210, loss: 1.242, accuracy: 0.803\n",
      "epoch 22 iter 280, loss: 1.326, accuracy: 0.797\n",
      "epoch 23 iter 0, loss: 1.371, accuracy: 0.785\n",
      "epoch 23 iter 70, loss: 1.304, accuracy: 0.789\n",
      "epoch 23 iter 140, loss: 1.328, accuracy: 0.787\n",
      "epoch 23 iter 210, loss: 1.214, accuracy: 0.805\n",
      "epoch 23 iter 280, loss: 1.368, accuracy: 0.792\n",
      "epoch 24 iter 0, loss: 1.312, accuracy: 0.795\n",
      "epoch 24 iter 70, loss: 1.214, accuracy: 0.801\n",
      "epoch 24 iter 140, loss: 1.384, accuracy: 0.788\n",
      "epoch 24 iter 210, loss: 1.284, accuracy: 0.803\n",
      "epoch 24 iter 280, loss: 1.410, accuracy: 0.793\n",
      "epoch 25 iter 0, loss: 1.413, accuracy: 0.796\n",
      "epoch 25 iter 70, loss: 1.268, accuracy: 0.796\n",
      "epoch 25 iter 140, loss: 1.454, accuracy: 0.785\n",
      "epoch 25 iter 210, loss: 1.339, accuracy: 0.799\n",
      "epoch 25 iter 280, loss: 1.413, accuracy: 0.788\n",
      "epoch 26 iter 0, loss: 1.488, accuracy: 0.790\n",
      "epoch 26 iter 70, loss: 1.340, accuracy: 0.776\n",
      "epoch 26 iter 140, loss: 1.470, accuracy: 0.800\n",
      "epoch 26 iter 210, loss: 1.410, accuracy: 0.797\n",
      "epoch 26 iter 280, loss: 1.466, accuracy: 0.789\n",
      "epoch 27 iter 0, loss: 1.534, accuracy: 0.793\n",
      "epoch 27 iter 70, loss: 1.348, accuracy: 0.784\n",
      "epoch 27 iter 140, loss: 1.571, accuracy: 0.790\n",
      "epoch 27 iter 210, loss: 1.449, accuracy: 0.803\n",
      "epoch 27 iter 280, loss: 1.531, accuracy: 0.786\n",
      "epoch 28 iter 0, loss: 1.660, accuracy: 0.790\n",
      "epoch 28 iter 70, loss: 1.410, accuracy: 0.777\n",
      "epoch 28 iter 140, loss: 1.519, accuracy: 0.798\n",
      "epoch 28 iter 210, loss: 1.555, accuracy: 0.799\n",
      "epoch 28 iter 280, loss: 1.507, accuracy: 0.795\n",
      "epoch 29 iter 0, loss: 1.569, accuracy: 0.798\n",
      "epoch 29 iter 70, loss: 1.483, accuracy: 0.779\n",
      "epoch 29 iter 140, loss: 1.815, accuracy: 0.788\n",
      "epoch 29 iter 210, loss: 1.543, accuracy: 0.804\n",
      "epoch 29 iter 280, loss: 1.512, accuracy: 0.791\n",
      "epoch 30 iter 0, loss: 1.611, accuracy: 0.799\n",
      "epoch 30 iter 70, loss: 1.539, accuracy: 0.794\n",
      "epoch 30 iter 140, loss: 1.752, accuracy: 0.805\n",
      "epoch 30 iter 210, loss: 1.663, accuracy: 0.804\n",
      "epoch 30 iter 280, loss: 1.571, accuracy: 0.792\n",
      "epoch 31 iter 0, loss: 1.615, accuracy: 0.801\n",
      "epoch 31 iter 70, loss: 1.540, accuracy: 0.793\n",
      "epoch 31 iter 140, loss: 1.563, accuracy: 0.807\n",
      "epoch 31 iter 210, loss: 1.626, accuracy: 0.815\n",
      "epoch 31 iter 280, loss: 1.595, accuracy: 0.792\n",
      "epoch 32 iter 0, loss: 1.728, accuracy: 0.782\n",
      "epoch 32 iter 70, loss: 1.619, accuracy: 0.786\n",
      "epoch 32 iter 140, loss: 1.626, accuracy: 0.811\n",
      "epoch 32 iter 210, loss: 1.745, accuracy: 0.812\n",
      "epoch 32 iter 280, loss: 1.725, accuracy: 0.795\n",
      "epoch 33 iter 0, loss: 1.726, accuracy: 0.791\n",
      "epoch 33 iter 70, loss: 1.754, accuracy: 0.793\n",
      "epoch 33 iter 140, loss: 1.750, accuracy: 0.809\n",
      "epoch 33 iter 210, loss: 1.844, accuracy: 0.805\n",
      "epoch 33 iter 280, loss: 1.682, accuracy: 0.801\n",
      "epoch 34 iter 0, loss: 1.724, accuracy: 0.798\n",
      "epoch 34 iter 70, loss: 1.746, accuracy: 0.792\n",
      "epoch 34 iter 140, loss: 1.831, accuracy: 0.800\n",
      "epoch 34 iter 210, loss: 1.870, accuracy: 0.807\n",
      "epoch 34 iter 280, loss: 1.861, accuracy: 0.794\n",
      "epoch 35 iter 0, loss: 1.782, accuracy: 0.800\n",
      "epoch 35 iter 70, loss: 1.759, accuracy: 0.794\n",
      "epoch 35 iter 140, loss: 1.997, accuracy: 0.792\n",
      "epoch 35 iter 210, loss: 1.848, accuracy: 0.813\n",
      "epoch 35 iter 280, loss: 1.924, accuracy: 0.796\n",
      "epoch 36 iter 0, loss: 1.854, accuracy: 0.808\n",
      "epoch 36 iter 70, loss: 1.916, accuracy: 0.790\n",
      "epoch 36 iter 140, loss: 2.035, accuracy: 0.801\n",
      "epoch 36 iter 210, loss: 1.794, accuracy: 0.817\n",
      "epoch 36 iter 280, loss: 2.024, accuracy: 0.801\n",
      "epoch 37 iter 0, loss: 1.872, accuracy: 0.799\n",
      "epoch 37 iter 70, loss: 1.971, accuracy: 0.799\n",
      "epoch 37 iter 140, loss: 2.251, accuracy: 0.795\n",
      "epoch 37 iter 210, loss: 1.956, accuracy: 0.817\n",
      "epoch 37 iter 280, loss: 2.213, accuracy: 0.787\n",
      "epoch 38 iter 0, loss: 1.860, accuracy: 0.803\n",
      "epoch 38 iter 70, loss: 2.193, accuracy: 0.800\n",
      "epoch 38 iter 140, loss: 2.292, accuracy: 0.800\n",
      "epoch 38 iter 210, loss: 2.127, accuracy: 0.805\n",
      "epoch 38 iter 280, loss: 2.331, accuracy: 0.786\n",
      "epoch 39 iter 0, loss: 2.011, accuracy: 0.803\n",
      "epoch 39 iter 70, loss: 2.021, accuracy: 0.812\n",
      "epoch 39 iter 140, loss: 2.443, accuracy: 0.801\n",
      "epoch 39 iter 210, loss: 2.210, accuracy: 0.810\n",
      "epoch 39 iter 280, loss: 2.295, accuracy: 0.790\n",
      "epoch 40 iter 0, loss: 2.111, accuracy: 0.795\n",
      "epoch 40 iter 70, loss: 2.160, accuracy: 0.807\n",
      "epoch 40 iter 140, loss: 2.466, accuracy: 0.792\n",
      "epoch 40 iter 210, loss: 2.259, accuracy: 0.803\n",
      "epoch 40 iter 280, loss: 2.343, accuracy: 0.800\n",
      "epoch 41 iter 0, loss: 2.103, accuracy: 0.799\n",
      "epoch 41 iter 70, loss: 2.175, accuracy: 0.808\n",
      "epoch 41 iter 140, loss: 2.432, accuracy: 0.793\n",
      "epoch 41 iter 210, loss: 2.145, accuracy: 0.805\n",
      "epoch 41 iter 280, loss: 2.438, accuracy: 0.796\n",
      "epoch 42 iter 0, loss: 2.142, accuracy: 0.804\n",
      "epoch 42 iter 70, loss: 2.260, accuracy: 0.810\n",
      "epoch 42 iter 140, loss: 2.426, accuracy: 0.788\n",
      "epoch 42 iter 210, loss: 2.218, accuracy: 0.811\n",
      "epoch 42 iter 280, loss: 2.616, accuracy: 0.796\n",
      "epoch 43 iter 0, loss: 2.248, accuracy: 0.798\n",
      "epoch 43 iter 70, loss: 2.315, accuracy: 0.804\n",
      "epoch 43 iter 140, loss: 2.563, accuracy: 0.797\n",
      "epoch 43 iter 210, loss: 2.288, accuracy: 0.811\n",
      "epoch 43 iter 280, loss: 2.765, accuracy: 0.786\n",
      "epoch 44 iter 0, loss: 2.443, accuracy: 0.795\n",
      "epoch 44 iter 70, loss: 2.352, accuracy: 0.809\n",
      "epoch 44 iter 140, loss: 2.466, accuracy: 0.799\n",
      "epoch 44 iter 210, loss: 2.329, accuracy: 0.816\n",
      "epoch 44 iter 280, loss: 2.459, accuracy: 0.806\n",
      "epoch 45 iter 0, loss: 2.382, accuracy: 0.805\n",
      "epoch 45 iter 70, loss: 2.536, accuracy: 0.805\n",
      "epoch 45 iter 140, loss: 2.373, accuracy: 0.814\n",
      "epoch 45 iter 210, loss: 2.291, accuracy: 0.818\n",
      "epoch 45 iter 280, loss: 2.716, accuracy: 0.805\n",
      "epoch 46 iter 0, loss: 2.708, accuracy: 0.790\n",
      "epoch 46 iter 70, loss: 2.534, accuracy: 0.795\n",
      "epoch 46 iter 140, loss: 2.486, accuracy: 0.817\n",
      "epoch 46 iter 210, loss: 2.407, accuracy: 0.817\n",
      "epoch 46 iter 280, loss: 2.521, accuracy: 0.812\n",
      "epoch 47 iter 0, loss: 2.611, accuracy: 0.805\n",
      "epoch 47 iter 70, loss: 2.590, accuracy: 0.798\n",
      "epoch 47 iter 140, loss: 2.498, accuracy: 0.827\n",
      "epoch 47 iter 210, loss: 2.641, accuracy: 0.807\n",
      "epoch 47 iter 280, loss: 2.674, accuracy: 0.806\n",
      "epoch 48 iter 0, loss: 2.814, accuracy: 0.801\n",
      "epoch 48 iter 70, loss: 2.850, accuracy: 0.794\n",
      "epoch 48 iter 140, loss: 2.412, accuracy: 0.819\n",
      "epoch 48 iter 210, loss: 2.489, accuracy: 0.820\n",
      "epoch 48 iter 280, loss: 2.708, accuracy: 0.820\n",
      "epoch 49 iter 0, loss: 2.734, accuracy: 0.810\n",
      "epoch 49 iter 70, loss: 2.650, accuracy: 0.805\n",
      "epoch 49 iter 140, loss: 2.573, accuracy: 0.819\n",
      "epoch 49 iter 210, loss: 2.465, accuracy: 0.818\n",
      "epoch 49 iter 280, loss: 2.986, accuracy: 0.807\n",
      "epoch 50 iter 0, loss: 2.861, accuracy: 0.802\n",
      "epoch 50 iter 70, loss: 2.929, accuracy: 0.796\n",
      "epoch 50 iter 140, loss: 2.620, accuracy: 0.818\n",
      "epoch 50 iter 210, loss: 2.659, accuracy: 0.820\n",
      "epoch 50 iter 280, loss: 2.705, accuracy: 0.818\n",
      "epoch 51 iter 0, loss: 2.688, accuracy: 0.814\n",
      "epoch 51 iter 70, loss: 2.789, accuracy: 0.804\n",
      "epoch 51 iter 140, loss: 2.674, accuracy: 0.821\n",
      "epoch 51 iter 210, loss: 2.792, accuracy: 0.821\n",
      "epoch 51 iter 280, loss: 3.032, accuracy: 0.812\n",
      "epoch 52 iter 0, loss: 3.090, accuracy: 0.809\n",
      "epoch 52 iter 70, loss: 2.950, accuracy: 0.806\n",
      "epoch 52 iter 140, loss: 2.529, accuracy: 0.823\n",
      "epoch 52 iter 210, loss: 2.788, accuracy: 0.815\n",
      "epoch 52 iter 280, loss: 2.870, accuracy: 0.817\n",
      "epoch 53 iter 0, loss: 2.921, accuracy: 0.809\n",
      "epoch 53 iter 70, loss: 2.808, accuracy: 0.803\n",
      "epoch 53 iter 140, loss: 2.631, accuracy: 0.811\n",
      "epoch 53 iter 210, loss: 2.888, accuracy: 0.817\n",
      "epoch 53 iter 280, loss: 2.887, accuracy: 0.824\n",
      "epoch 54 iter 0, loss: 2.874, accuracy: 0.819\n",
      "epoch 54 iter 70, loss: 2.943, accuracy: 0.801\n",
      "epoch 54 iter 140, loss: 2.784, accuracy: 0.817\n",
      "epoch 54 iter 210, loss: 2.766, accuracy: 0.822\n",
      "epoch 54 iter 280, loss: 3.026, accuracy: 0.827\n",
      "epoch 55 iter 0, loss: 2.815, accuracy: 0.825\n",
      "epoch 55 iter 70, loss: 2.821, accuracy: 0.815\n",
      "epoch 55 iter 140, loss: 2.833, accuracy: 0.819\n",
      "epoch 55 iter 210, loss: 2.797, accuracy: 0.830\n",
      "epoch 55 iter 280, loss: 3.020, accuracy: 0.824\n",
      "epoch 56 iter 0, loss: 2.890, accuracy: 0.822\n",
      "epoch 56 iter 70, loss: 3.179, accuracy: 0.809\n",
      "epoch 56 iter 140, loss: 2.888, accuracy: 0.825\n",
      "epoch 56 iter 210, loss: 2.996, accuracy: 0.824\n",
      "epoch 56 iter 280, loss: 3.230, accuracy: 0.822\n",
      "epoch 57 iter 0, loss: 3.189, accuracy: 0.813\n",
      "epoch 57 iter 70, loss: 2.999, accuracy: 0.809\n",
      "epoch 57 iter 140, loss: 2.964, accuracy: 0.818\n",
      "epoch 57 iter 210, loss: 3.162, accuracy: 0.817\n",
      "epoch 57 iter 280, loss: 3.255, accuracy: 0.815\n",
      "epoch 58 iter 0, loss: 3.209, accuracy: 0.819\n",
      "epoch 58 iter 70, loss: 3.018, accuracy: 0.801\n",
      "epoch 58 iter 140, loss: 3.102, accuracy: 0.819\n",
      "epoch 58 iter 210, loss: 3.103, accuracy: 0.824\n",
      "epoch 58 iter 280, loss: 3.307, accuracy: 0.817\n",
      "epoch 59 iter 0, loss: 3.325, accuracy: 0.814\n",
      "epoch 59 iter 70, loss: 3.200, accuracy: 0.803\n",
      "epoch 59 iter 140, loss: 3.253, accuracy: 0.819\n",
      "epoch 59 iter 210, loss: 3.298, accuracy: 0.818\n",
      "epoch 59 iter 280, loss: 3.148, accuracy: 0.820\n",
      "epoch 60 iter 0, loss: 3.290, accuracy: 0.815\n",
      "epoch 60 iter 70, loss: 3.369, accuracy: 0.800\n",
      "epoch 60 iter 140, loss: 3.335, accuracy: 0.822\n",
      "epoch 60 iter 210, loss: 3.400, accuracy: 0.815\n",
      "epoch 60 iter 280, loss: 3.289, accuracy: 0.819\n",
      "epoch 61 iter 0, loss: 3.367, accuracy: 0.818\n",
      "epoch 61 iter 70, loss: 3.243, accuracy: 0.812\n",
      "epoch 61 iter 140, loss: 3.422, accuracy: 0.823\n",
      "epoch 61 iter 210, loss: 3.144, accuracy: 0.824\n",
      "epoch 61 iter 280, loss: 3.394, accuracy: 0.816\n",
      "epoch 62 iter 0, loss: 3.420, accuracy: 0.812\n",
      "epoch 62 iter 70, loss: 3.168, accuracy: 0.810\n",
      "epoch 62 iter 140, loss: 3.512, accuracy: 0.823\n",
      "epoch 62 iter 210, loss: 3.352, accuracy: 0.812\n",
      "epoch 62 iter 280, loss: 3.455, accuracy: 0.816\n",
      "epoch 63 iter 0, loss: 3.378, accuracy: 0.818\n",
      "epoch 63 iter 70, loss: 3.285, accuracy: 0.812\n",
      "epoch 63 iter 140, loss: 3.482, accuracy: 0.816\n",
      "epoch 63 iter 210, loss: 3.231, accuracy: 0.820\n",
      "epoch 63 iter 280, loss: 3.490, accuracy: 0.817\n",
      "epoch 64 iter 0, loss: 3.361, accuracy: 0.818\n",
      "epoch 64 iter 70, loss: 3.196, accuracy: 0.815\n",
      "epoch 64 iter 140, loss: 3.436, accuracy: 0.821\n",
      "epoch 64 iter 210, loss: 3.467, accuracy: 0.817\n",
      "epoch 64 iter 280, loss: 3.516, accuracy: 0.811\n",
      "epoch 65 iter 0, loss: 3.736, accuracy: 0.813\n",
      "epoch 65 iter 70, loss: 3.392, accuracy: 0.820\n",
      "epoch 65 iter 140, loss: 3.513, accuracy: 0.825\n",
      "epoch 65 iter 210, loss: 3.618, accuracy: 0.825\n",
      "epoch 65 iter 280, loss: 3.665, accuracy: 0.812\n",
      "epoch 66 iter 0, loss: 3.505, accuracy: 0.813\n",
      "epoch 66 iter 70, loss: 3.281, accuracy: 0.822\n",
      "epoch 66 iter 140, loss: 3.612, accuracy: 0.818\n",
      "epoch 66 iter 210, loss: 3.626, accuracy: 0.824\n",
      "epoch 66 iter 280, loss: 3.506, accuracy: 0.815\n",
      "epoch 67 iter 0, loss: 3.688, accuracy: 0.816\n",
      "epoch 67 iter 70, loss: 3.526, accuracy: 0.810\n",
      "epoch 67 iter 140, loss: 3.554, accuracy: 0.829\n",
      "epoch 67 iter 210, loss: 3.433, accuracy: 0.825\n",
      "epoch 67 iter 280, loss: 3.327, accuracy: 0.822\n",
      "epoch 68 iter 0, loss: 3.546, accuracy: 0.817\n",
      "epoch 68 iter 70, loss: 3.530, accuracy: 0.816\n",
      "epoch 68 iter 140, loss: 3.668, accuracy: 0.819\n",
      "epoch 68 iter 210, loss: 3.588, accuracy: 0.824\n",
      "epoch 68 iter 280, loss: 3.440, accuracy: 0.812\n",
      "epoch 69 iter 0, loss: 3.844, accuracy: 0.812\n",
      "epoch 69 iter 70, loss: 3.480, accuracy: 0.818\n",
      "epoch 69 iter 140, loss: 3.671, accuracy: 0.837\n",
      "epoch 69 iter 210, loss: 3.630, accuracy: 0.821\n",
      "epoch 69 iter 280, loss: 3.644, accuracy: 0.809\n",
      "epoch 70 iter 0, loss: 3.489, accuracy: 0.820\n",
      "epoch 70 iter 70, loss: 3.638, accuracy: 0.814\n",
      "epoch 70 iter 140, loss: 3.818, accuracy: 0.832\n",
      "epoch 70 iter 210, loss: 3.766, accuracy: 0.830\n",
      "epoch 70 iter 280, loss: 3.668, accuracy: 0.814\n",
      "epoch 71 iter 0, loss: 3.727, accuracy: 0.821\n",
      "epoch 71 iter 70, loss: 3.597, accuracy: 0.820\n",
      "epoch 71 iter 140, loss: 3.545, accuracy: 0.835\n",
      "epoch 71 iter 210, loss: 3.843, accuracy: 0.834\n",
      "epoch 71 iter 280, loss: 3.708, accuracy: 0.823\n",
      "epoch 72 iter 0, loss: 3.777, accuracy: 0.828\n",
      "epoch 72 iter 70, loss: 3.697, accuracy: 0.812\n",
      "epoch 72 iter 140, loss: 3.761, accuracy: 0.839\n",
      "epoch 72 iter 210, loss: 4.033, accuracy: 0.824\n",
      "epoch 72 iter 280, loss: 3.993, accuracy: 0.817\n",
      "epoch 73 iter 0, loss: 3.950, accuracy: 0.817\n",
      "epoch 73 iter 70, loss: 3.647, accuracy: 0.817\n",
      "epoch 73 iter 140, loss: 3.651, accuracy: 0.831\n",
      "epoch 73 iter 210, loss: 3.690, accuracy: 0.832\n",
      "epoch 73 iter 280, loss: 4.023, accuracy: 0.825\n",
      "epoch 74 iter 0, loss: 3.929, accuracy: 0.821\n",
      "epoch 74 iter 70, loss: 3.528, accuracy: 0.817\n",
      "epoch 74 iter 140, loss: 3.779, accuracy: 0.836\n",
      "epoch 74 iter 210, loss: 4.000, accuracy: 0.825\n",
      "epoch 74 iter 280, loss: 3.887, accuracy: 0.818\n",
      "epoch 75 iter 0, loss: 3.949, accuracy: 0.825\n",
      "epoch 75 iter 70, loss: 3.929, accuracy: 0.809\n",
      "epoch 75 iter 140, loss: 3.921, accuracy: 0.835\n",
      "epoch 75 iter 210, loss: 3.722, accuracy: 0.834\n",
      "epoch 75 iter 280, loss: 3.757, accuracy: 0.823\n",
      "epoch 76 iter 0, loss: 3.811, accuracy: 0.823\n",
      "epoch 76 iter 70, loss: 3.781, accuracy: 0.821\n",
      "epoch 76 iter 140, loss: 3.853, accuracy: 0.837\n",
      "epoch 76 iter 210, loss: 4.100, accuracy: 0.832\n",
      "epoch 76 iter 280, loss: 4.112, accuracy: 0.827\n",
      "epoch 77 iter 0, loss: 4.159, accuracy: 0.822\n",
      "epoch 77 iter 70, loss: 4.266, accuracy: 0.818\n",
      "epoch 77 iter 140, loss: 3.873, accuracy: 0.836\n",
      "epoch 77 iter 210, loss: 4.070, accuracy: 0.834\n",
      "epoch 77 iter 280, loss: 3.914, accuracy: 0.827\n",
      "epoch 78 iter 0, loss: 4.014, accuracy: 0.823\n",
      "epoch 78 iter 70, loss: 4.103, accuracy: 0.820\n",
      "epoch 78 iter 140, loss: 3.782, accuracy: 0.837\n",
      "epoch 78 iter 210, loss: 4.433, accuracy: 0.830\n",
      "epoch 78 iter 280, loss: 4.040, accuracy: 0.827\n",
      "epoch 79 iter 0, loss: 4.236, accuracy: 0.823\n",
      "epoch 79 iter 70, loss: 4.125, accuracy: 0.820\n",
      "epoch 79 iter 140, loss: 4.233, accuracy: 0.831\n",
      "epoch 79 iter 210, loss: 4.356, accuracy: 0.826\n",
      "epoch 79 iter 280, loss: 4.232, accuracy: 0.824\n",
      "epoch 80 iter 0, loss: 4.370, accuracy: 0.818\n",
      "epoch 80 iter 70, loss: 4.222, accuracy: 0.821\n",
      "epoch 80 iter 140, loss: 4.096, accuracy: 0.834\n",
      "epoch 80 iter 210, loss: 4.113, accuracy: 0.831\n",
      "epoch 80 iter 280, loss: 4.229, accuracy: 0.825\n",
      "epoch 81 iter 0, loss: 4.404, accuracy: 0.819\n",
      "epoch 81 iter 70, loss: 4.209, accuracy: 0.815\n",
      "epoch 81 iter 140, loss: 4.698, accuracy: 0.822\n",
      "epoch 81 iter 210, loss: 4.137, accuracy: 0.825\n",
      "epoch 81 iter 280, loss: 4.062, accuracy: 0.827\n",
      "epoch 82 iter 0, loss: 4.101, accuracy: 0.822\n",
      "epoch 82 iter 70, loss: 3.905, accuracy: 0.821\n",
      "epoch 82 iter 140, loss: 4.158, accuracy: 0.838\n",
      "epoch 82 iter 210, loss: 4.380, accuracy: 0.828\n",
      "epoch 82 iter 280, loss: 4.264, accuracy: 0.825\n",
      "epoch 83 iter 0, loss: 4.458, accuracy: 0.816\n",
      "epoch 83 iter 70, loss: 3.974, accuracy: 0.821\n",
      "epoch 83 iter 140, loss: 4.339, accuracy: 0.830\n",
      "epoch 83 iter 210, loss: 4.346, accuracy: 0.820\n",
      "epoch 83 iter 280, loss: 4.341, accuracy: 0.820\n",
      "epoch 84 iter 0, loss: 4.282, accuracy: 0.821\n",
      "epoch 84 iter 70, loss: 4.031, accuracy: 0.821\n",
      "epoch 84 iter 140, loss: 4.246, accuracy: 0.838\n",
      "epoch 84 iter 210, loss: 4.673, accuracy: 0.826\n",
      "epoch 84 iter 280, loss: 4.449, accuracy: 0.829\n",
      "epoch 85 iter 0, loss: 4.418, accuracy: 0.822\n",
      "epoch 85 iter 70, loss: 4.093, accuracy: 0.819\n",
      "epoch 85 iter 140, loss: 4.492, accuracy: 0.837\n",
      "epoch 85 iter 210, loss: 4.457, accuracy: 0.831\n",
      "epoch 85 iter 280, loss: 4.501, accuracy: 0.827\n",
      "epoch 86 iter 0, loss: 4.712, accuracy: 0.824\n",
      "epoch 86 iter 70, loss: 4.425, accuracy: 0.823\n",
      "epoch 86 iter 140, loss: 4.612, accuracy: 0.832\n",
      "epoch 86 iter 210, loss: 4.533, accuracy: 0.833\n",
      "epoch 86 iter 280, loss: 4.332, accuracy: 0.834\n",
      "epoch 87 iter 0, loss: 4.629, accuracy: 0.816\n",
      "epoch 87 iter 70, loss: 4.229, accuracy: 0.809\n",
      "epoch 87 iter 140, loss: 4.431, accuracy: 0.826\n",
      "epoch 87 iter 210, loss: 4.945, accuracy: 0.834\n",
      "epoch 87 iter 280, loss: 4.373, accuracy: 0.830\n",
      "epoch 88 iter 0, loss: 4.393, accuracy: 0.823\n",
      "epoch 88 iter 70, loss: 4.356, accuracy: 0.824\n",
      "epoch 88 iter 140, loss: 4.409, accuracy: 0.832\n",
      "epoch 88 iter 210, loss: 4.567, accuracy: 0.833\n",
      "epoch 88 iter 280, loss: 4.318, accuracy: 0.834\n",
      "epoch 89 iter 0, loss: 4.392, accuracy: 0.829\n",
      "epoch 89 iter 70, loss: 4.239, accuracy: 0.829\n",
      "epoch 89 iter 140, loss: 4.524, accuracy: 0.833\n",
      "epoch 89 iter 210, loss: 4.385, accuracy: 0.830\n",
      "epoch 89 iter 280, loss: 4.392, accuracy: 0.834\n",
      "epoch 90 iter 0, loss: 4.477, accuracy: 0.826\n",
      "epoch 90 iter 70, loss: 4.159, accuracy: 0.833\n",
      "epoch 90 iter 140, loss: 4.363, accuracy: 0.836\n",
      "epoch 90 iter 210, loss: 4.768, accuracy: 0.825\n",
      "epoch 90 iter 280, loss: 4.561, accuracy: 0.830\n",
      "epoch 91 iter 0, loss: 4.653, accuracy: 0.826\n",
      "epoch 91 iter 70, loss: 4.342, accuracy: 0.813\n",
      "epoch 91 iter 140, loss: 4.447, accuracy: 0.830\n",
      "epoch 91 iter 210, loss: 4.461, accuracy: 0.832\n",
      "epoch 91 iter 280, loss: 4.466, accuracy: 0.838\n",
      "epoch 92 iter 0, loss: 4.590, accuracy: 0.834\n",
      "epoch 92 iter 70, loss: 4.445, accuracy: 0.820\n",
      "epoch 92 iter 140, loss: 4.497, accuracy: 0.835\n",
      "epoch 92 iter 210, loss: 4.724, accuracy: 0.828\n",
      "epoch 92 iter 280, loss: 4.533, accuracy: 0.837\n",
      "epoch 93 iter 0, loss: 4.667, accuracy: 0.829\n",
      "epoch 93 iter 70, loss: 4.637, accuracy: 0.826\n",
      "epoch 93 iter 140, loss: 4.613, accuracy: 0.835\n",
      "epoch 93 iter 210, loss: 4.516, accuracy: 0.831\n",
      "epoch 93 iter 280, loss: 4.576, accuracy: 0.830\n",
      "epoch 94 iter 0, loss: 4.589, accuracy: 0.827\n",
      "epoch 94 iter 70, loss: 4.360, accuracy: 0.822\n",
      "epoch 94 iter 140, loss: 4.551, accuracy: 0.829\n",
      "epoch 94 iter 210, loss: 4.567, accuracy: 0.835\n",
      "epoch 94 iter 280, loss: 4.818, accuracy: 0.834\n",
      "epoch 95 iter 0, loss: 4.797, accuracy: 0.836\n",
      "epoch 95 iter 70, loss: 4.459, accuracy: 0.831\n",
      "epoch 95 iter 140, loss: 4.606, accuracy: 0.829\n",
      "epoch 95 iter 210, loss: 4.394, accuracy: 0.832\n",
      "epoch 95 iter 280, loss: 4.558, accuracy: 0.837\n",
      "epoch 96 iter 0, loss: 4.791, accuracy: 0.837\n",
      "epoch 96 iter 70, loss: 4.728, accuracy: 0.831\n",
      "epoch 96 iter 140, loss: 4.874, accuracy: 0.831\n",
      "epoch 96 iter 210, loss: 5.032, accuracy: 0.839\n",
      "epoch 96 iter 280, loss: 4.675, accuracy: 0.844\n",
      "epoch 97 iter 0, loss: 4.880, accuracy: 0.834\n",
      "epoch 97 iter 70, loss: 4.285, accuracy: 0.834\n",
      "epoch 97 iter 140, loss: 5.003, accuracy: 0.833\n",
      "epoch 97 iter 210, loss: 4.673, accuracy: 0.834\n",
      "epoch 97 iter 280, loss: 4.730, accuracy: 0.838\n",
      "epoch 98 iter 0, loss: 4.856, accuracy: 0.828\n",
      "epoch 98 iter 70, loss: 4.933, accuracy: 0.829\n",
      "epoch 98 iter 140, loss: 4.882, accuracy: 0.832\n",
      "epoch 98 iter 210, loss: 4.814, accuracy: 0.829\n",
      "epoch 98 iter 280, loss: 4.480, accuracy: 0.828\n",
      "epoch 99 iter 0, loss: 4.688, accuracy: 0.829\n",
      "epoch 99 iter 70, loss: 4.602, accuracy: 0.834\n",
      "epoch 99 iter 140, loss: 4.902, accuracy: 0.834\n",
      "epoch 99 iter 210, loss: 4.972, accuracy: 0.829\n",
      "epoch 99 iter 280, loss: 4.912, accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=1,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 109.549, accuracy: 0.159\n",
      "epoch 0 iter 70, loss: 2.167, accuracy: 0.238\n",
      "epoch 0 iter 140, loss: 1.648, accuracy: 0.468\n",
      "epoch 0 iter 210, loss: 1.317, accuracy: 0.586\n",
      "epoch 0 iter 280, loss: 1.141, accuracy: 0.649\n",
      "epoch 1 iter 0, loss: 1.123, accuracy: 0.658\n",
      "epoch 1 iter 70, loss: 1.059, accuracy: 0.678\n",
      "epoch 1 iter 140, loss: 0.986, accuracy: 0.707\n",
      "epoch 1 iter 210, loss: 0.961, accuracy: 0.718\n",
      "epoch 1 iter 280, loss: 0.933, accuracy: 0.728\n",
      "epoch 2 iter 0, loss: 0.928, accuracy: 0.731\n",
      "epoch 2 iter 70, loss: 0.945, accuracy: 0.720\n",
      "epoch 2 iter 140, loss: 0.877, accuracy: 0.748\n",
      "epoch 2 iter 210, loss: 0.867, accuracy: 0.751\n",
      "epoch 2 iter 280, loss: 0.872, accuracy: 0.748\n",
      "epoch 3 iter 0, loss: 0.850, accuracy: 0.756\n",
      "epoch 3 iter 70, loss: 0.853, accuracy: 0.751\n",
      "epoch 3 iter 140, loss: 0.823, accuracy: 0.766\n",
      "epoch 3 iter 210, loss: 0.835, accuracy: 0.762\n",
      "epoch 3 iter 280, loss: 0.817, accuracy: 0.769\n",
      "epoch 4 iter 0, loss: 0.822, accuracy: 0.765\n",
      "epoch 4 iter 70, loss: 0.796, accuracy: 0.773\n",
      "epoch 4 iter 140, loss: 0.803, accuracy: 0.773\n",
      "epoch 4 iter 210, loss: 0.800, accuracy: 0.775\n",
      "epoch 4 iter 280, loss: 0.764, accuracy: 0.785\n",
      "epoch 5 iter 0, loss: 0.807, accuracy: 0.773\n",
      "epoch 5 iter 70, loss: 0.786, accuracy: 0.778\n",
      "epoch 5 iter 140, loss: 0.773, accuracy: 0.781\n",
      "epoch 5 iter 210, loss: 0.787, accuracy: 0.780\n",
      "epoch 5 iter 280, loss: 0.745, accuracy: 0.795\n",
      "epoch 6 iter 0, loss: 0.795, accuracy: 0.781\n",
      "epoch 6 iter 70, loss: 0.753, accuracy: 0.790\n",
      "epoch 6 iter 140, loss: 0.730, accuracy: 0.799\n",
      "epoch 6 iter 210, loss: 0.758, accuracy: 0.796\n",
      "epoch 6 iter 280, loss: 0.742, accuracy: 0.802\n",
      "epoch 7 iter 0, loss: 0.774, accuracy: 0.791\n",
      "epoch 7 iter 70, loss: 0.766, accuracy: 0.796\n",
      "epoch 7 iter 140, loss: 0.744, accuracy: 0.801\n",
      "epoch 7 iter 210, loss: 0.755, accuracy: 0.798\n",
      "epoch 7 iter 280, loss: 0.772, accuracy: 0.799\n",
      "epoch 8 iter 0, loss: 0.811, accuracy: 0.790\n",
      "epoch 8 iter 70, loss: 0.771, accuracy: 0.796\n",
      "epoch 8 iter 140, loss: 0.794, accuracy: 0.791\n",
      "epoch 8 iter 210, loss: 0.785, accuracy: 0.797\n",
      "epoch 8 iter 280, loss: 0.777, accuracy: 0.807\n",
      "epoch 9 iter 0, loss: 0.800, accuracy: 0.798\n",
      "epoch 9 iter 70, loss: 0.805, accuracy: 0.802\n",
      "epoch 9 iter 140, loss: 0.805, accuracy: 0.800\n",
      "epoch 9 iter 210, loss: 0.879, accuracy: 0.782\n",
      "epoch 9 iter 280, loss: 0.781, accuracy: 0.811\n",
      "epoch 10 iter 0, loss: 0.791, accuracy: 0.808\n",
      "epoch 10 iter 70, loss: 0.908, accuracy: 0.790\n",
      "epoch 10 iter 140, loss: 0.850, accuracy: 0.798\n",
      "epoch 10 iter 210, loss: 0.859, accuracy: 0.791\n",
      "epoch 10 iter 280, loss: 0.841, accuracy: 0.807\n",
      "epoch 11 iter 0, loss: 0.830, accuracy: 0.802\n",
      "epoch 11 iter 70, loss: 0.932, accuracy: 0.792\n",
      "epoch 11 iter 140, loss: 0.910, accuracy: 0.796\n",
      "epoch 11 iter 210, loss: 0.877, accuracy: 0.800\n",
      "epoch 11 iter 280, loss: 0.866, accuracy: 0.805\n",
      "epoch 12 iter 0, loss: 0.869, accuracy: 0.800\n",
      "epoch 12 iter 70, loss: 0.979, accuracy: 0.789\n",
      "epoch 12 iter 140, loss: 0.998, accuracy: 0.785\n",
      "epoch 12 iter 210, loss: 1.058, accuracy: 0.789\n",
      "epoch 12 iter 280, loss: 0.963, accuracy: 0.784\n",
      "epoch 13 iter 0, loss: 0.976, accuracy: 0.800\n",
      "epoch 13 iter 70, loss: 0.996, accuracy: 0.793\n",
      "epoch 13 iter 140, loss: 1.050, accuracy: 0.783\n",
      "epoch 13 iter 210, loss: 1.199, accuracy: 0.771\n",
      "epoch 13 iter 280, loss: 0.946, accuracy: 0.798\n",
      "epoch 14 iter 0, loss: 0.938, accuracy: 0.805\n",
      "epoch 14 iter 70, loss: 0.989, accuracy: 0.797\n",
      "epoch 14 iter 140, loss: 1.056, accuracy: 0.794\n",
      "epoch 14 iter 210, loss: 1.266, accuracy: 0.778\n",
      "epoch 14 iter 280, loss: 0.985, accuracy: 0.802\n",
      "epoch 15 iter 0, loss: 1.055, accuracy: 0.798\n",
      "epoch 15 iter 70, loss: 1.048, accuracy: 0.781\n",
      "epoch 15 iter 140, loss: 1.078, accuracy: 0.792\n",
      "epoch 15 iter 210, loss: 1.302, accuracy: 0.767\n",
      "epoch 15 iter 280, loss: 1.080, accuracy: 0.802\n",
      "epoch 16 iter 0, loss: 1.078, accuracy: 0.796\n",
      "epoch 16 iter 70, loss: 1.108, accuracy: 0.769\n",
      "epoch 16 iter 140, loss: 1.144, accuracy: 0.795\n",
      "epoch 16 iter 210, loss: 1.202, accuracy: 0.789\n",
      "epoch 16 iter 280, loss: 1.226, accuracy: 0.797\n",
      "epoch 17 iter 0, loss: 1.142, accuracy: 0.796\n",
      "epoch 17 iter 70, loss: 1.091, accuracy: 0.788\n",
      "epoch 17 iter 140, loss: 1.330, accuracy: 0.776\n",
      "epoch 17 iter 210, loss: 1.278, accuracy: 0.770\n",
      "epoch 17 iter 280, loss: 1.160, accuracy: 0.798\n",
      "epoch 18 iter 0, loss: 1.163, accuracy: 0.803\n",
      "epoch 18 iter 70, loss: 1.107, accuracy: 0.794\n",
      "epoch 18 iter 140, loss: 1.402, accuracy: 0.769\n",
      "epoch 18 iter 210, loss: 1.356, accuracy: 0.764\n",
      "epoch 18 iter 280, loss: 1.203, accuracy: 0.811\n",
      "epoch 19 iter 0, loss: 1.283, accuracy: 0.800\n",
      "epoch 19 iter 70, loss: 1.161, accuracy: 0.786\n",
      "epoch 19 iter 140, loss: 1.407, accuracy: 0.770\n",
      "epoch 19 iter 210, loss: 1.299, accuracy: 0.791\n",
      "epoch 19 iter 280, loss: 1.194, accuracy: 0.813\n",
      "epoch 20 iter 0, loss: 1.415, accuracy: 0.797\n",
      "epoch 20 iter 70, loss: 1.205, accuracy: 0.784\n",
      "epoch 20 iter 140, loss: 1.432, accuracy: 0.778\n",
      "epoch 20 iter 210, loss: 1.314, accuracy: 0.793\n",
      "epoch 20 iter 280, loss: 1.244, accuracy: 0.813\n",
      "epoch 21 iter 0, loss: 1.357, accuracy: 0.808\n",
      "epoch 21 iter 70, loss: 1.217, accuracy: 0.796\n",
      "epoch 21 iter 140, loss: 1.533, accuracy: 0.763\n",
      "epoch 21 iter 210, loss: 1.464, accuracy: 0.786\n",
      "epoch 21 iter 280, loss: 1.320, accuracy: 0.808\n",
      "epoch 22 iter 0, loss: 1.414, accuracy: 0.807\n",
      "epoch 22 iter 70, loss: 1.314, accuracy: 0.790\n",
      "epoch 22 iter 140, loss: 1.361, accuracy: 0.796\n",
      "epoch 22 iter 210, loss: 1.452, accuracy: 0.791\n",
      "epoch 22 iter 280, loss: 1.290, accuracy: 0.810\n",
      "epoch 23 iter 0, loss: 1.302, accuracy: 0.805\n",
      "epoch 23 iter 70, loss: 1.433, accuracy: 0.803\n",
      "epoch 23 iter 140, loss: 1.441, accuracy: 0.800\n",
      "epoch 23 iter 210, loss: 1.475, accuracy: 0.793\n",
      "epoch 23 iter 280, loss: 1.382, accuracy: 0.805\n",
      "epoch 24 iter 0, loss: 1.310, accuracy: 0.810\n",
      "epoch 24 iter 70, loss: 1.394, accuracy: 0.801\n",
      "epoch 24 iter 140, loss: 1.305, accuracy: 0.799\n",
      "epoch 24 iter 210, loss: 1.431, accuracy: 0.797\n",
      "epoch 24 iter 280, loss: 1.349, accuracy: 0.809\n",
      "epoch 25 iter 0, loss: 1.548, accuracy: 0.811\n",
      "epoch 25 iter 70, loss: 1.559, accuracy: 0.793\n",
      "epoch 25 iter 140, loss: 1.361, accuracy: 0.790\n",
      "epoch 25 iter 210, loss: 1.574, accuracy: 0.785\n",
      "epoch 25 iter 280, loss: 1.365, accuracy: 0.811\n",
      "epoch 26 iter 0, loss: 1.479, accuracy: 0.812\n",
      "epoch 26 iter 70, loss: 1.634, accuracy: 0.797\n",
      "epoch 26 iter 140, loss: 1.397, accuracy: 0.803\n",
      "epoch 26 iter 210, loss: 1.617, accuracy: 0.792\n",
      "epoch 26 iter 280, loss: 1.445, accuracy: 0.807\n",
      "epoch 27 iter 0, loss: 1.575, accuracy: 0.809\n",
      "epoch 27 iter 70, loss: 1.694, accuracy: 0.794\n",
      "epoch 27 iter 140, loss: 1.462, accuracy: 0.806\n",
      "epoch 27 iter 210, loss: 1.594, accuracy: 0.798\n",
      "epoch 27 iter 280, loss: 1.501, accuracy: 0.806\n",
      "epoch 28 iter 0, loss: 1.840, accuracy: 0.803\n",
      "epoch 28 iter 70, loss: 1.913, accuracy: 0.794\n",
      "epoch 28 iter 140, loss: 1.731, accuracy: 0.805\n",
      "epoch 28 iter 210, loss: 1.726, accuracy: 0.804\n",
      "epoch 28 iter 280, loss: 1.624, accuracy: 0.792\n",
      "epoch 29 iter 0, loss: 1.833, accuracy: 0.807\n",
      "epoch 29 iter 70, loss: 1.811, accuracy: 0.794\n",
      "epoch 29 iter 140, loss: 1.683, accuracy: 0.808\n",
      "epoch 29 iter 210, loss: 1.721, accuracy: 0.795\n",
      "epoch 29 iter 280, loss: 1.753, accuracy: 0.795\n",
      "epoch 30 iter 0, loss: 1.995, accuracy: 0.802\n",
      "epoch 30 iter 70, loss: 1.751, accuracy: 0.790\n",
      "epoch 30 iter 140, loss: 1.836, accuracy: 0.803\n",
      "epoch 30 iter 210, loss: 1.878, accuracy: 0.800\n",
      "epoch 30 iter 280, loss: 1.667, accuracy: 0.795\n",
      "epoch 31 iter 0, loss: 2.017, accuracy: 0.803\n",
      "epoch 31 iter 70, loss: 2.109, accuracy: 0.785\n",
      "epoch 31 iter 140, loss: 1.954, accuracy: 0.803\n",
      "epoch 31 iter 210, loss: 2.039, accuracy: 0.801\n",
      "epoch 31 iter 280, loss: 1.884, accuracy: 0.782\n",
      "epoch 32 iter 0, loss: 1.865, accuracy: 0.806\n",
      "epoch 32 iter 70, loss: 1.966, accuracy: 0.781\n",
      "epoch 32 iter 140, loss: 2.040, accuracy: 0.794\n",
      "epoch 32 iter 210, loss: 1.988, accuracy: 0.810\n",
      "epoch 32 iter 280, loss: 2.380, accuracy: 0.786\n",
      "epoch 33 iter 0, loss: 1.619, accuracy: 0.786\n",
      "epoch 33 iter 70, loss: 1.966, accuracy: 0.789\n",
      "epoch 33 iter 140, loss: 1.991, accuracy: 0.809\n",
      "epoch 33 iter 210, loss: 2.066, accuracy: 0.808\n",
      "epoch 33 iter 280, loss: 2.378, accuracy: 0.792\n",
      "epoch 34 iter 0, loss: 1.863, accuracy: 0.808\n",
      "epoch 34 iter 70, loss: 1.940, accuracy: 0.778\n",
      "epoch 34 iter 140, loss: 2.120, accuracy: 0.802\n",
      "epoch 34 iter 210, loss: 2.098, accuracy: 0.809\n",
      "epoch 34 iter 280, loss: 2.183, accuracy: 0.801\n",
      "epoch 35 iter 0, loss: 2.051, accuracy: 0.806\n",
      "epoch 35 iter 70, loss: 2.167, accuracy: 0.778\n",
      "epoch 35 iter 140, loss: 2.100, accuracy: 0.803\n",
      "epoch 35 iter 210, loss: 2.121, accuracy: 0.808\n",
      "epoch 35 iter 280, loss: 2.252, accuracy: 0.795\n",
      "epoch 36 iter 0, loss: 2.120, accuracy: 0.810\n",
      "epoch 36 iter 70, loss: 2.108, accuracy: 0.780\n",
      "epoch 36 iter 140, loss: 2.179, accuracy: 0.801\n",
      "epoch 36 iter 210, loss: 2.119, accuracy: 0.804\n",
      "epoch 36 iter 280, loss: 2.200, accuracy: 0.793\n",
      "epoch 37 iter 0, loss: 2.430, accuracy: 0.810\n",
      "epoch 37 iter 70, loss: 2.296, accuracy: 0.792\n",
      "epoch 37 iter 140, loss: 2.311, accuracy: 0.808\n",
      "epoch 37 iter 210, loss: 2.178, accuracy: 0.808\n",
      "epoch 37 iter 280, loss: 2.176, accuracy: 0.778\n",
      "epoch 38 iter 0, loss: 2.657, accuracy: 0.802\n",
      "epoch 38 iter 70, loss: 2.315, accuracy: 0.789\n",
      "epoch 38 iter 140, loss: 2.279, accuracy: 0.810\n",
      "epoch 38 iter 210, loss: 2.418, accuracy: 0.800\n",
      "epoch 38 iter 280, loss: 2.376, accuracy: 0.781\n",
      "epoch 39 iter 0, loss: 2.539, accuracy: 0.791\n",
      "epoch 39 iter 70, loss: 2.557, accuracy: 0.807\n",
      "epoch 39 iter 140, loss: 2.569, accuracy: 0.803\n",
      "epoch 39 iter 210, loss: 2.583, accuracy: 0.804\n",
      "epoch 39 iter 280, loss: 2.650, accuracy: 0.797\n",
      "epoch 40 iter 0, loss: 2.471, accuracy: 0.782\n",
      "epoch 40 iter 70, loss: 2.435, accuracy: 0.810\n",
      "epoch 40 iter 140, loss: 2.808, accuracy: 0.803\n",
      "epoch 40 iter 210, loss: 2.522, accuracy: 0.794\n",
      "epoch 40 iter 280, loss: 2.592, accuracy: 0.801\n",
      "epoch 41 iter 0, loss: 2.351, accuracy: 0.795\n",
      "epoch 41 iter 70, loss: 2.693, accuracy: 0.807\n",
      "epoch 41 iter 140, loss: 2.460, accuracy: 0.809\n",
      "epoch 41 iter 210, loss: 2.564, accuracy: 0.801\n",
      "epoch 41 iter 280, loss: 2.961, accuracy: 0.798\n",
      "epoch 42 iter 0, loss: 2.388, accuracy: 0.798\n",
      "epoch 42 iter 70, loss: 2.596, accuracy: 0.810\n",
      "epoch 42 iter 140, loss: 2.856, accuracy: 0.806\n",
      "epoch 42 iter 210, loss: 2.778, accuracy: 0.810\n",
      "epoch 42 iter 280, loss: 2.988, accuracy: 0.795\n",
      "epoch 43 iter 0, loss: 2.472, accuracy: 0.800\n",
      "epoch 43 iter 70, loss: 2.252, accuracy: 0.796\n",
      "epoch 43 iter 140, loss: 2.620, accuracy: 0.804\n",
      "epoch 43 iter 210, loss: 2.800, accuracy: 0.802\n",
      "epoch 43 iter 280, loss: 3.199, accuracy: 0.789\n",
      "epoch 44 iter 0, loss: 2.816, accuracy: 0.786\n",
      "epoch 44 iter 70, loss: 2.476, accuracy: 0.770\n",
      "epoch 44 iter 140, loss: 2.714, accuracy: 0.814\n",
      "epoch 44 iter 210, loss: 2.983, accuracy: 0.805\n",
      "epoch 44 iter 280, loss: 3.457, accuracy: 0.788\n",
      "epoch 45 iter 0, loss: 2.769, accuracy: 0.805\n",
      "epoch 45 iter 70, loss: 2.401, accuracy: 0.786\n",
      "epoch 45 iter 140, loss: 2.485, accuracy: 0.816\n",
      "epoch 45 iter 210, loss: 2.903, accuracy: 0.807\n",
      "epoch 45 iter 280, loss: 3.413, accuracy: 0.788\n",
      "epoch 46 iter 0, loss: 2.575, accuracy: 0.804\n",
      "epoch 46 iter 70, loss: 2.530, accuracy: 0.793\n",
      "epoch 46 iter 140, loss: 2.880, accuracy: 0.815\n",
      "epoch 46 iter 210, loss: 3.384, accuracy: 0.801\n",
      "epoch 46 iter 280, loss: 4.125, accuracy: 0.785\n",
      "epoch 47 iter 0, loss: 2.743, accuracy: 0.799\n",
      "epoch 47 iter 70, loss: 2.595, accuracy: 0.782\n",
      "epoch 47 iter 140, loss: 2.816, accuracy: 0.817\n",
      "epoch 47 iter 210, loss: 3.111, accuracy: 0.806\n",
      "epoch 47 iter 280, loss: 3.393, accuracy: 0.788\n",
      "epoch 48 iter 0, loss: 2.831, accuracy: 0.785\n",
      "epoch 48 iter 70, loss: 2.636, accuracy: 0.786\n",
      "epoch 48 iter 140, loss: 2.966, accuracy: 0.816\n",
      "epoch 48 iter 210, loss: 3.474, accuracy: 0.812\n",
      "epoch 48 iter 280, loss: 3.981, accuracy: 0.792\n",
      "epoch 49 iter 0, loss: 2.998, accuracy: 0.796\n",
      "epoch 49 iter 70, loss: 2.522, accuracy: 0.777\n",
      "epoch 49 iter 140, loss: 2.968, accuracy: 0.814\n",
      "epoch 49 iter 210, loss: 3.559, accuracy: 0.808\n",
      "epoch 49 iter 280, loss: 3.602, accuracy: 0.799\n",
      "epoch 50 iter 0, loss: 3.160, accuracy: 0.796\n",
      "epoch 50 iter 70, loss: 2.616, accuracy: 0.786\n",
      "epoch 50 iter 140, loss: 2.930, accuracy: 0.812\n",
      "epoch 50 iter 210, loss: 2.986, accuracy: 0.809\n",
      "epoch 50 iter 280, loss: 3.419, accuracy: 0.805\n",
      "epoch 51 iter 0, loss: 3.481, accuracy: 0.798\n",
      "epoch 51 iter 70, loss: 2.724, accuracy: 0.775\n",
      "epoch 51 iter 140, loss: 3.011, accuracy: 0.808\n",
      "epoch 51 iter 210, loss: 3.505, accuracy: 0.816\n",
      "epoch 51 iter 280, loss: 3.908, accuracy: 0.807\n",
      "epoch 52 iter 0, loss: 3.695, accuracy: 0.807\n",
      "epoch 52 iter 70, loss: 3.017, accuracy: 0.799\n",
      "epoch 52 iter 140, loss: 3.370, accuracy: 0.813\n",
      "epoch 52 iter 210, loss: 3.321, accuracy: 0.821\n",
      "epoch 52 iter 280, loss: 3.772, accuracy: 0.810\n",
      "epoch 53 iter 0, loss: 3.975, accuracy: 0.808\n",
      "epoch 53 iter 70, loss: 2.845, accuracy: 0.792\n",
      "epoch 53 iter 140, loss: 2.968, accuracy: 0.813\n",
      "epoch 53 iter 210, loss: 3.416, accuracy: 0.818\n",
      "epoch 53 iter 280, loss: 4.204, accuracy: 0.809\n",
      "epoch 54 iter 0, loss: 4.088, accuracy: 0.811\n",
      "epoch 54 iter 70, loss: 3.352, accuracy: 0.803\n",
      "epoch 54 iter 140, loss: 3.161, accuracy: 0.807\n",
      "epoch 54 iter 210, loss: 3.841, accuracy: 0.816\n",
      "epoch 54 iter 280, loss: 4.340, accuracy: 0.804\n",
      "epoch 55 iter 0, loss: 4.456, accuracy: 0.803\n",
      "epoch 55 iter 70, loss: 3.304, accuracy: 0.812\n",
      "epoch 55 iter 140, loss: 3.428, accuracy: 0.808\n",
      "epoch 55 iter 210, loss: 3.555, accuracy: 0.814\n",
      "epoch 55 iter 280, loss: 4.128, accuracy: 0.799\n",
      "epoch 56 iter 0, loss: 4.970, accuracy: 0.796\n",
      "epoch 56 iter 70, loss: 3.591, accuracy: 0.812\n",
      "epoch 56 iter 140, loss: 3.803, accuracy: 0.810\n",
      "epoch 56 iter 210, loss: 3.684, accuracy: 0.819\n",
      "epoch 56 iter 280, loss: 4.801, accuracy: 0.804\n",
      "epoch 57 iter 0, loss: 4.592, accuracy: 0.805\n",
      "epoch 57 iter 70, loss: 3.390, accuracy: 0.817\n",
      "epoch 57 iter 140, loss: 4.012, accuracy: 0.804\n",
      "epoch 57 iter 210, loss: 3.895, accuracy: 0.815\n",
      "epoch 57 iter 280, loss: 4.265, accuracy: 0.816\n",
      "epoch 58 iter 0, loss: 4.555, accuracy: 0.803\n",
      "epoch 58 iter 70, loss: 3.427, accuracy: 0.812\n",
      "epoch 58 iter 140, loss: 3.674, accuracy: 0.815\n",
      "epoch 58 iter 210, loss: 3.824, accuracy: 0.813\n",
      "epoch 58 iter 280, loss: 5.247, accuracy: 0.793\n",
      "epoch 59 iter 0, loss: 4.505, accuracy: 0.803\n",
      "epoch 59 iter 70, loss: 3.625, accuracy: 0.810\n",
      "epoch 59 iter 140, loss: 3.709, accuracy: 0.800\n",
      "epoch 59 iter 210, loss: 3.519, accuracy: 0.819\n",
      "epoch 59 iter 280, loss: 4.472, accuracy: 0.807\n",
      "epoch 60 iter 0, loss: 4.726, accuracy: 0.797\n",
      "epoch 60 iter 70, loss: 3.625, accuracy: 0.818\n",
      "epoch 60 iter 140, loss: 3.388, accuracy: 0.812\n",
      "epoch 60 iter 210, loss: 3.700, accuracy: 0.815\n",
      "epoch 60 iter 280, loss: 3.967, accuracy: 0.808\n",
      "epoch 61 iter 0, loss: 5.440, accuracy: 0.800\n",
      "epoch 61 iter 70, loss: 3.892, accuracy: 0.819\n",
      "epoch 61 iter 140, loss: 3.833, accuracy: 0.810\n",
      "epoch 61 iter 210, loss: 3.501, accuracy: 0.822\n",
      "epoch 61 iter 280, loss: 4.185, accuracy: 0.809\n",
      "epoch 62 iter 0, loss: 4.833, accuracy: 0.808\n",
      "epoch 62 iter 70, loss: 3.840, accuracy: 0.820\n",
      "epoch 62 iter 140, loss: 4.205, accuracy: 0.810\n",
      "epoch 62 iter 210, loss: 3.798, accuracy: 0.817\n",
      "epoch 62 iter 280, loss: 4.177, accuracy: 0.802\n",
      "epoch 63 iter 0, loss: 5.120, accuracy: 0.810\n",
      "epoch 63 iter 70, loss: 4.132, accuracy: 0.822\n",
      "epoch 63 iter 140, loss: 4.226, accuracy: 0.808\n",
      "epoch 63 iter 210, loss: 4.045, accuracy: 0.816\n",
      "epoch 63 iter 280, loss: 4.724, accuracy: 0.812\n",
      "epoch 64 iter 0, loss: 5.785, accuracy: 0.805\n",
      "epoch 64 iter 70, loss: 4.222, accuracy: 0.815\n",
      "epoch 64 iter 140, loss: 4.578, accuracy: 0.810\n",
      "epoch 64 iter 210, loss: 4.193, accuracy: 0.819\n",
      "epoch 64 iter 280, loss: 4.362, accuracy: 0.805\n",
      "epoch 65 iter 0, loss: 5.410, accuracy: 0.801\n",
      "epoch 65 iter 70, loss: 4.690, accuracy: 0.813\n",
      "epoch 65 iter 140, loss: 4.857, accuracy: 0.791\n",
      "epoch 65 iter 210, loss: 3.904, accuracy: 0.818\n",
      "epoch 65 iter 280, loss: 4.613, accuracy: 0.806\n",
      "epoch 66 iter 0, loss: 6.543, accuracy: 0.796\n",
      "epoch 66 iter 70, loss: 4.616, accuracy: 0.810\n",
      "epoch 66 iter 140, loss: 4.403, accuracy: 0.816\n",
      "epoch 66 iter 210, loss: 4.196, accuracy: 0.813\n",
      "epoch 66 iter 280, loss: 4.633, accuracy: 0.800\n",
      "epoch 67 iter 0, loss: 5.864, accuracy: 0.801\n",
      "epoch 67 iter 70, loss: 4.611, accuracy: 0.815\n",
      "epoch 67 iter 140, loss: 4.629, accuracy: 0.802\n",
      "epoch 67 iter 210, loss: 4.399, accuracy: 0.813\n",
      "epoch 67 iter 280, loss: 5.298, accuracy: 0.791\n",
      "epoch 68 iter 0, loss: 5.261, accuracy: 0.802\n",
      "epoch 68 iter 70, loss: 4.504, accuracy: 0.814\n",
      "epoch 68 iter 140, loss: 4.670, accuracy: 0.815\n",
      "epoch 68 iter 210, loss: 4.298, accuracy: 0.818\n",
      "epoch 68 iter 280, loss: 4.984, accuracy: 0.805\n",
      "epoch 69 iter 0, loss: 5.718, accuracy: 0.799\n",
      "epoch 69 iter 70, loss: 4.350, accuracy: 0.815\n",
      "epoch 69 iter 140, loss: 4.564, accuracy: 0.817\n",
      "epoch 69 iter 210, loss: 4.135, accuracy: 0.808\n",
      "epoch 69 iter 280, loss: 5.100, accuracy: 0.800\n",
      "epoch 70 iter 0, loss: 6.435, accuracy: 0.792\n",
      "epoch 70 iter 70, loss: 4.880, accuracy: 0.824\n",
      "epoch 70 iter 140, loss: 4.842, accuracy: 0.812\n",
      "epoch 70 iter 210, loss: 4.567, accuracy: 0.809\n",
      "epoch 70 iter 280, loss: 5.609, accuracy: 0.800\n",
      "epoch 71 iter 0, loss: 5.954, accuracy: 0.804\n",
      "epoch 71 iter 70, loss: 5.415, accuracy: 0.822\n",
      "epoch 71 iter 140, loss: 5.303, accuracy: 0.812\n",
      "epoch 71 iter 210, loss: 4.530, accuracy: 0.805\n",
      "epoch 71 iter 280, loss: 4.880, accuracy: 0.807\n",
      "epoch 72 iter 0, loss: 5.543, accuracy: 0.802\n",
      "epoch 72 iter 70, loss: 5.193, accuracy: 0.814\n",
      "epoch 72 iter 140, loss: 5.404, accuracy: 0.810\n",
      "epoch 72 iter 210, loss: 4.637, accuracy: 0.814\n",
      "epoch 72 iter 280, loss: 5.887, accuracy: 0.811\n",
      "epoch 73 iter 0, loss: 5.577, accuracy: 0.812\n",
      "epoch 73 iter 70, loss: 4.901, accuracy: 0.818\n",
      "epoch 73 iter 140, loss: 5.315, accuracy: 0.816\n",
      "epoch 73 iter 210, loss: 4.929, accuracy: 0.817\n",
      "epoch 73 iter 280, loss: 5.466, accuracy: 0.808\n",
      "epoch 74 iter 0, loss: 5.484, accuracy: 0.817\n",
      "epoch 74 iter 70, loss: 4.900, accuracy: 0.817\n",
      "epoch 74 iter 140, loss: 5.466, accuracy: 0.812\n",
      "epoch 74 iter 210, loss: 4.618, accuracy: 0.814\n",
      "epoch 74 iter 280, loss: 5.161, accuracy: 0.798\n",
      "epoch 75 iter 0, loss: 5.504, accuracy: 0.812\n",
      "epoch 75 iter 70, loss: 5.087, accuracy: 0.819\n",
      "epoch 75 iter 140, loss: 5.723, accuracy: 0.818\n",
      "epoch 75 iter 210, loss: 5.005, accuracy: 0.815\n",
      "epoch 75 iter 280, loss: 5.198, accuracy: 0.803\n",
      "epoch 76 iter 0, loss: 6.227, accuracy: 0.808\n",
      "epoch 76 iter 70, loss: 5.421, accuracy: 0.820\n",
      "epoch 76 iter 140, loss: 5.585, accuracy: 0.822\n",
      "epoch 76 iter 210, loss: 4.537, accuracy: 0.812\n",
      "epoch 76 iter 280, loss: 6.041, accuracy: 0.797\n",
      "epoch 77 iter 0, loss: 6.452, accuracy: 0.810\n",
      "epoch 77 iter 70, loss: 5.596, accuracy: 0.818\n",
      "epoch 77 iter 140, loss: 5.411, accuracy: 0.806\n",
      "epoch 77 iter 210, loss: 5.253, accuracy: 0.815\n",
      "epoch 77 iter 280, loss: 6.238, accuracy: 0.787\n",
      "epoch 78 iter 0, loss: 6.306, accuracy: 0.804\n",
      "epoch 78 iter 70, loss: 5.372, accuracy: 0.818\n",
      "epoch 78 iter 140, loss: 6.034, accuracy: 0.819\n",
      "epoch 78 iter 210, loss: 4.933, accuracy: 0.821\n",
      "epoch 78 iter 280, loss: 5.973, accuracy: 0.815\n",
      "epoch 79 iter 0, loss: 6.533, accuracy: 0.816\n",
      "epoch 79 iter 70, loss: 5.734, accuracy: 0.817\n",
      "epoch 79 iter 140, loss: 6.207, accuracy: 0.818\n",
      "epoch 79 iter 210, loss: 5.388, accuracy: 0.815\n",
      "epoch 79 iter 280, loss: 5.300, accuracy: 0.805\n",
      "epoch 80 iter 0, loss: 6.350, accuracy: 0.809\n",
      "epoch 80 iter 70, loss: 5.757, accuracy: 0.824\n",
      "epoch 80 iter 140, loss: 6.738, accuracy: 0.813\n",
      "epoch 80 iter 210, loss: 5.718, accuracy: 0.808\n",
      "epoch 80 iter 280, loss: 5.854, accuracy: 0.803\n",
      "epoch 81 iter 0, loss: 7.402, accuracy: 0.804\n",
      "epoch 81 iter 70, loss: 5.921, accuracy: 0.821\n",
      "epoch 81 iter 140, loss: 5.851, accuracy: 0.819\n",
      "epoch 81 iter 210, loss: 5.568, accuracy: 0.814\n",
      "epoch 81 iter 280, loss: 5.801, accuracy: 0.802\n",
      "epoch 82 iter 0, loss: 6.041, accuracy: 0.813\n",
      "epoch 82 iter 70, loss: 6.333, accuracy: 0.827\n",
      "epoch 82 iter 140, loss: 6.162, accuracy: 0.822\n",
      "epoch 82 iter 210, loss: 5.580, accuracy: 0.813\n",
      "epoch 82 iter 280, loss: 6.675, accuracy: 0.806\n",
      "epoch 83 iter 0, loss: 6.755, accuracy: 0.807\n",
      "epoch 83 iter 70, loss: 6.267, accuracy: 0.824\n",
      "epoch 83 iter 140, loss: 7.069, accuracy: 0.816\n",
      "epoch 83 iter 210, loss: 5.996, accuracy: 0.816\n",
      "epoch 83 iter 280, loss: 6.363, accuracy: 0.801\n",
      "epoch 84 iter 0, loss: 7.862, accuracy: 0.798\n",
      "epoch 84 iter 70, loss: 6.450, accuracy: 0.823\n",
      "epoch 84 iter 140, loss: 6.760, accuracy: 0.819\n",
      "epoch 84 iter 210, loss: 6.100, accuracy: 0.820\n",
      "epoch 84 iter 280, loss: 5.568, accuracy: 0.794\n",
      "epoch 85 iter 0, loss: 7.052, accuracy: 0.812\n",
      "epoch 85 iter 70, loss: 6.783, accuracy: 0.819\n",
      "epoch 85 iter 140, loss: 6.670, accuracy: 0.817\n",
      "epoch 85 iter 210, loss: 6.208, accuracy: 0.808\n",
      "epoch 85 iter 280, loss: 7.156, accuracy: 0.809\n",
      "epoch 86 iter 0, loss: 6.157, accuracy: 0.807\n",
      "epoch 86 iter 70, loss: 6.445, accuracy: 0.823\n",
      "epoch 86 iter 140, loss: 6.635, accuracy: 0.821\n",
      "epoch 86 iter 210, loss: 5.827, accuracy: 0.814\n",
      "epoch 86 iter 280, loss: 6.287, accuracy: 0.804\n",
      "epoch 87 iter 0, loss: 7.041, accuracy: 0.804\n",
      "epoch 87 iter 70, loss: 6.410, accuracy: 0.819\n",
      "epoch 87 iter 140, loss: 6.618, accuracy: 0.816\n",
      "epoch 87 iter 210, loss: 6.074, accuracy: 0.819\n",
      "epoch 87 iter 280, loss: 6.860, accuracy: 0.804\n",
      "epoch 88 iter 0, loss: 7.501, accuracy: 0.805\n",
      "epoch 88 iter 70, loss: 6.552, accuracy: 0.826\n",
      "epoch 88 iter 140, loss: 6.787, accuracy: 0.822\n",
      "epoch 88 iter 210, loss: 6.729, accuracy: 0.820\n",
      "epoch 88 iter 280, loss: 6.852, accuracy: 0.809\n",
      "epoch 89 iter 0, loss: 7.031, accuracy: 0.802\n",
      "epoch 89 iter 70, loss: 7.045, accuracy: 0.824\n",
      "epoch 89 iter 140, loss: 6.573, accuracy: 0.821\n",
      "epoch 89 iter 210, loss: 6.796, accuracy: 0.830\n",
      "epoch 89 iter 280, loss: 7.486, accuracy: 0.799\n",
      "epoch 90 iter 0, loss: 8.251, accuracy: 0.807\n",
      "epoch 90 iter 70, loss: 6.506, accuracy: 0.819\n",
      "epoch 90 iter 140, loss: 7.050, accuracy: 0.814\n",
      "epoch 90 iter 210, loss: 6.422, accuracy: 0.815\n",
      "epoch 90 iter 280, loss: 7.219, accuracy: 0.800\n",
      "epoch 91 iter 0, loss: 7.685, accuracy: 0.805\n",
      "epoch 91 iter 70, loss: 6.258, accuracy: 0.820\n",
      "epoch 91 iter 140, loss: 6.835, accuracy: 0.816\n",
      "epoch 91 iter 210, loss: 6.777, accuracy: 0.818\n",
      "epoch 91 iter 280, loss: 7.067, accuracy: 0.809\n",
      "epoch 92 iter 0, loss: 6.526, accuracy: 0.802\n",
      "epoch 92 iter 70, loss: 6.635, accuracy: 0.824\n",
      "epoch 92 iter 140, loss: 7.088, accuracy: 0.826\n",
      "epoch 92 iter 210, loss: 6.788, accuracy: 0.824\n",
      "epoch 92 iter 280, loss: 6.138, accuracy: 0.777\n",
      "epoch 93 iter 0, loss: 7.346, accuracy: 0.803\n",
      "epoch 93 iter 70, loss: 7.139, accuracy: 0.825\n",
      "epoch 93 iter 140, loss: 7.086, accuracy: 0.824\n",
      "epoch 93 iter 210, loss: 6.755, accuracy: 0.825\n",
      "epoch 93 iter 280, loss: 7.009, accuracy: 0.809\n",
      "epoch 94 iter 0, loss: 6.823, accuracy: 0.798\n",
      "epoch 94 iter 70, loss: 7.051, accuracy: 0.822\n",
      "epoch 94 iter 140, loss: 7.645, accuracy: 0.826\n",
      "epoch 94 iter 210, loss: 7.306, accuracy: 0.824\n",
      "epoch 94 iter 280, loss: 6.623, accuracy: 0.766\n",
      "epoch 95 iter 0, loss: 7.377, accuracy: 0.798\n",
      "epoch 95 iter 70, loss: 6.582, accuracy: 0.823\n",
      "epoch 95 iter 140, loss: 7.034, accuracy: 0.823\n",
      "epoch 95 iter 210, loss: 6.996, accuracy: 0.814\n",
      "epoch 95 iter 280, loss: 6.620, accuracy: 0.810\n",
      "epoch 96 iter 0, loss: 6.340, accuracy: 0.803\n",
      "epoch 96 iter 70, loss: 6.649, accuracy: 0.815\n",
      "epoch 96 iter 140, loss: 7.443, accuracy: 0.823\n",
      "epoch 96 iter 210, loss: 7.842, accuracy: 0.821\n",
      "epoch 96 iter 280, loss: 7.208, accuracy: 0.812\n",
      "epoch 97 iter 0, loss: 7.151, accuracy: 0.804\n",
      "epoch 97 iter 70, loss: 6.889, accuracy: 0.822\n",
      "epoch 97 iter 140, loss: 7.461, accuracy: 0.815\n",
      "epoch 97 iter 210, loss: 7.970, accuracy: 0.817\n",
      "epoch 97 iter 280, loss: 7.259, accuracy: 0.808\n",
      "epoch 98 iter 0, loss: 6.955, accuracy: 0.786\n",
      "epoch 98 iter 70, loss: 6.143, accuracy: 0.810\n",
      "epoch 98 iter 140, loss: 7.825, accuracy: 0.830\n",
      "epoch 98 iter 210, loss: 7.515, accuracy: 0.816\n",
      "epoch 98 iter 280, loss: 8.411, accuracy: 0.811\n",
      "epoch 99 iter 0, loss: 6.866, accuracy: 0.780\n",
      "epoch 99 iter 70, loss: 6.361, accuracy: 0.808\n",
      "epoch 99 iter 140, loss: 6.853, accuracy: 0.825\n",
      "epoch 99 iter 210, loss: 7.832, accuracy: 0.828\n",
      "epoch 99 iter 280, loss: 7.605, accuracy: 0.803\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=1,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[7, 7],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[7, 7],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 23.178, accuracy: 0.076\n",
      "epoch 0 iter 70, loss: 2.093, accuracy: 0.281\n",
      "epoch 0 iter 140, loss: 1.610, accuracy: 0.465\n",
      "epoch 0 iter 210, loss: 1.280, accuracy: 0.598\n",
      "epoch 0 iter 280, loss: 1.092, accuracy: 0.660\n",
      "epoch 1 iter 0, loss: 1.098, accuracy: 0.667\n",
      "epoch 1 iter 70, loss: 1.011, accuracy: 0.696\n",
      "epoch 1 iter 140, loss: 0.911, accuracy: 0.731\n",
      "epoch 1 iter 210, loss: 0.953, accuracy: 0.717\n",
      "epoch 1 iter 280, loss: 0.881, accuracy: 0.737\n",
      "epoch 2 iter 0, loss: 0.893, accuracy: 0.737\n",
      "epoch 2 iter 70, loss: 0.870, accuracy: 0.749\n",
      "epoch 2 iter 140, loss: 0.808, accuracy: 0.765\n",
      "epoch 2 iter 210, loss: 0.810, accuracy: 0.765\n",
      "epoch 2 iter 280, loss: 0.807, accuracy: 0.765\n",
      "epoch 3 iter 0, loss: 0.795, accuracy: 0.768\n",
      "epoch 3 iter 70, loss: 0.787, accuracy: 0.773\n",
      "epoch 3 iter 140, loss: 0.772, accuracy: 0.780\n",
      "epoch 3 iter 210, loss: 0.768, accuracy: 0.779\n",
      "epoch 3 iter 280, loss: 0.758, accuracy: 0.783\n",
      "epoch 4 iter 0, loss: 0.741, accuracy: 0.785\n",
      "epoch 4 iter 70, loss: 0.746, accuracy: 0.784\n",
      "epoch 4 iter 140, loss: 0.722, accuracy: 0.797\n",
      "epoch 4 iter 210, loss: 0.778, accuracy: 0.778\n",
      "epoch 4 iter 280, loss: 0.760, accuracy: 0.784\n",
      "epoch 5 iter 0, loss: 0.712, accuracy: 0.796\n",
      "epoch 5 iter 70, loss: 0.714, accuracy: 0.797\n",
      "epoch 5 iter 140, loss: 0.716, accuracy: 0.798\n",
      "epoch 5 iter 210, loss: 0.710, accuracy: 0.799\n",
      "epoch 5 iter 280, loss: 0.756, accuracy: 0.786\n",
      "epoch 6 iter 0, loss: 0.735, accuracy: 0.789\n",
      "epoch 6 iter 70, loss: 0.709, accuracy: 0.799\n",
      "epoch 6 iter 140, loss: 0.696, accuracy: 0.805\n",
      "epoch 6 iter 210, loss: 0.671, accuracy: 0.813\n",
      "epoch 6 iter 280, loss: 0.690, accuracy: 0.809\n",
      "epoch 7 iter 0, loss: 0.691, accuracy: 0.807\n",
      "epoch 7 iter 70, loss: 0.695, accuracy: 0.811\n",
      "epoch 7 iter 140, loss: 0.700, accuracy: 0.806\n",
      "epoch 7 iter 210, loss: 0.665, accuracy: 0.815\n",
      "epoch 7 iter 280, loss: 0.706, accuracy: 0.804\n",
      "epoch 8 iter 0, loss: 0.746, accuracy: 0.793\n",
      "epoch 8 iter 70, loss: 0.726, accuracy: 0.802\n",
      "epoch 8 iter 140, loss: 0.658, accuracy: 0.821\n",
      "epoch 8 iter 210, loss: 0.681, accuracy: 0.813\n",
      "epoch 8 iter 280, loss: 0.716, accuracy: 0.805\n",
      "epoch 9 iter 0, loss: 0.738, accuracy: 0.795\n",
      "epoch 9 iter 70, loss: 0.705, accuracy: 0.806\n",
      "epoch 9 iter 140, loss: 0.636, accuracy: 0.829\n",
      "epoch 9 iter 210, loss: 0.698, accuracy: 0.807\n",
      "epoch 9 iter 280, loss: 0.672, accuracy: 0.820\n",
      "epoch 10 iter 0, loss: 0.740, accuracy: 0.801\n",
      "epoch 10 iter 70, loss: 0.689, accuracy: 0.810\n",
      "epoch 10 iter 140, loss: 0.651, accuracy: 0.827\n",
      "epoch 10 iter 210, loss: 0.764, accuracy: 0.792\n",
      "epoch 10 iter 280, loss: 0.725, accuracy: 0.805\n",
      "epoch 11 iter 0, loss: 0.697, accuracy: 0.814\n",
      "epoch 11 iter 70, loss: 0.665, accuracy: 0.820\n",
      "epoch 11 iter 140, loss: 0.664, accuracy: 0.822\n",
      "epoch 11 iter 210, loss: 0.715, accuracy: 0.811\n",
      "epoch 11 iter 280, loss: 0.712, accuracy: 0.811\n",
      "epoch 12 iter 0, loss: 0.745, accuracy: 0.807\n",
      "epoch 12 iter 70, loss: 0.702, accuracy: 0.812\n",
      "epoch 12 iter 140, loss: 0.682, accuracy: 0.821\n",
      "epoch 12 iter 210, loss: 0.734, accuracy: 0.812\n",
      "epoch 12 iter 280, loss: 0.738, accuracy: 0.806\n",
      "epoch 13 iter 0, loss: 0.683, accuracy: 0.822\n",
      "epoch 13 iter 70, loss: 0.714, accuracy: 0.813\n",
      "epoch 13 iter 140, loss: 0.724, accuracy: 0.817\n",
      "epoch 13 iter 210, loss: 0.719, accuracy: 0.818\n",
      "epoch 13 iter 280, loss: 0.757, accuracy: 0.809\n",
      "epoch 14 iter 0, loss: 0.711, accuracy: 0.823\n",
      "epoch 14 iter 70, loss: 0.730, accuracy: 0.809\n",
      "epoch 14 iter 140, loss: 0.697, accuracy: 0.817\n",
      "epoch 14 iter 210, loss: 0.764, accuracy: 0.804\n",
      "epoch 14 iter 280, loss: 0.706, accuracy: 0.825\n",
      "epoch 15 iter 0, loss: 0.723, accuracy: 0.826\n",
      "epoch 15 iter 70, loss: 0.705, accuracy: 0.824\n",
      "epoch 15 iter 140, loss: 0.696, accuracy: 0.826\n",
      "epoch 15 iter 210, loss: 0.774, accuracy: 0.807\n",
      "epoch 15 iter 280, loss: 0.737, accuracy: 0.819\n",
      "epoch 16 iter 0, loss: 0.746, accuracy: 0.819\n",
      "epoch 16 iter 70, loss: 0.760, accuracy: 0.810\n",
      "epoch 16 iter 140, loss: 0.722, accuracy: 0.825\n",
      "epoch 16 iter 210, loss: 0.765, accuracy: 0.812\n",
      "epoch 16 iter 280, loss: 0.742, accuracy: 0.826\n",
      "epoch 17 iter 0, loss: 0.775, accuracy: 0.814\n",
      "epoch 17 iter 70, loss: 0.770, accuracy: 0.814\n",
      "epoch 17 iter 140, loss: 0.744, accuracy: 0.816\n",
      "epoch 17 iter 210, loss: 0.760, accuracy: 0.816\n",
      "epoch 17 iter 280, loss: 0.791, accuracy: 0.813\n",
      "epoch 18 iter 0, loss: 0.772, accuracy: 0.823\n",
      "epoch 18 iter 70, loss: 0.791, accuracy: 0.817\n",
      "epoch 18 iter 140, loss: 0.739, accuracy: 0.821\n",
      "epoch 18 iter 210, loss: 0.822, accuracy: 0.810\n",
      "epoch 18 iter 280, loss: 0.783, accuracy: 0.821\n",
      "epoch 19 iter 0, loss: 0.765, accuracy: 0.826\n",
      "epoch 19 iter 70, loss: 0.759, accuracy: 0.828\n",
      "epoch 19 iter 140, loss: 0.743, accuracy: 0.823\n",
      "epoch 19 iter 210, loss: 0.760, accuracy: 0.822\n",
      "epoch 19 iter 280, loss: 0.805, accuracy: 0.820\n",
      "epoch 20 iter 0, loss: 0.808, accuracy: 0.822\n",
      "epoch 20 iter 70, loss: 0.829, accuracy: 0.812\n",
      "epoch 20 iter 140, loss: 0.776, accuracy: 0.824\n",
      "epoch 20 iter 210, loss: 0.824, accuracy: 0.815\n",
      "epoch 20 iter 280, loss: 0.820, accuracy: 0.815\n",
      "epoch 21 iter 0, loss: 0.774, accuracy: 0.832\n",
      "epoch 21 iter 70, loss: 0.838, accuracy: 0.816\n",
      "epoch 21 iter 140, loss: 0.851, accuracy: 0.815\n",
      "epoch 21 iter 210, loss: 0.851, accuracy: 0.813\n",
      "epoch 21 iter 280, loss: 0.845, accuracy: 0.819\n",
      "epoch 22 iter 0, loss: 0.813, accuracy: 0.829\n",
      "epoch 22 iter 70, loss: 0.816, accuracy: 0.828\n",
      "epoch 22 iter 140, loss: 0.856, accuracy: 0.817\n",
      "epoch 22 iter 210, loss: 0.794, accuracy: 0.827\n",
      "epoch 22 iter 280, loss: 0.848, accuracy: 0.822\n",
      "epoch 23 iter 0, loss: 0.873, accuracy: 0.822\n",
      "epoch 23 iter 70, loss: 0.827, accuracy: 0.825\n",
      "epoch 23 iter 140, loss: 0.856, accuracy: 0.813\n",
      "epoch 23 iter 210, loss: 0.823, accuracy: 0.825\n",
      "epoch 23 iter 280, loss: 0.924, accuracy: 0.807\n",
      "epoch 24 iter 0, loss: 0.913, accuracy: 0.818\n",
      "epoch 24 iter 70, loss: 0.860, accuracy: 0.823\n",
      "epoch 24 iter 140, loss: 0.901, accuracy: 0.820\n",
      "epoch 24 iter 210, loss: 0.870, accuracy: 0.825\n",
      "epoch 24 iter 280, loss: 0.891, accuracy: 0.815\n",
      "epoch 25 iter 0, loss: 0.908, accuracy: 0.820\n",
      "epoch 25 iter 70, loss: 0.897, accuracy: 0.816\n",
      "epoch 25 iter 140, loss: 0.939, accuracy: 0.809\n",
      "epoch 25 iter 210, loss: 0.905, accuracy: 0.811\n",
      "epoch 25 iter 280, loss: 0.915, accuracy: 0.809\n",
      "epoch 26 iter 0, loss: 0.900, accuracy: 0.821\n",
      "epoch 26 iter 70, loss: 0.888, accuracy: 0.824\n",
      "epoch 26 iter 140, loss: 0.932, accuracy: 0.818\n",
      "epoch 26 iter 210, loss: 0.951, accuracy: 0.813\n",
      "epoch 26 iter 280, loss: 0.957, accuracy: 0.807\n",
      "epoch 27 iter 0, loss: 0.887, accuracy: 0.824\n",
      "epoch 27 iter 70, loss: 0.900, accuracy: 0.821\n",
      "epoch 27 iter 140, loss: 0.905, accuracy: 0.820\n",
      "epoch 27 iter 210, loss: 0.954, accuracy: 0.810\n",
      "epoch 27 iter 280, loss: 0.900, accuracy: 0.821\n",
      "epoch 28 iter 0, loss: 0.871, accuracy: 0.826\n",
      "epoch 28 iter 70, loss: 0.937, accuracy: 0.824\n",
      "epoch 28 iter 140, loss: 0.903, accuracy: 0.820\n",
      "epoch 28 iter 210, loss: 0.973, accuracy: 0.806\n",
      "epoch 28 iter 280, loss: 0.947, accuracy: 0.820\n",
      "epoch 29 iter 0, loss: 0.902, accuracy: 0.823\n",
      "epoch 29 iter 70, loss: 0.946, accuracy: 0.821\n",
      "epoch 29 iter 140, loss: 0.899, accuracy: 0.826\n",
      "epoch 29 iter 210, loss: 0.971, accuracy: 0.822\n",
      "epoch 29 iter 280, loss: 0.930, accuracy: 0.827\n",
      "epoch 30 iter 0, loss: 0.977, accuracy: 0.819\n",
      "epoch 30 iter 70, loss: 0.962, accuracy: 0.823\n",
      "epoch 30 iter 140, loss: 1.027, accuracy: 0.809\n",
      "epoch 30 iter 210, loss: 0.942, accuracy: 0.824\n",
      "epoch 30 iter 280, loss: 0.980, accuracy: 0.814\n",
      "epoch 31 iter 0, loss: 0.945, accuracy: 0.825\n",
      "epoch 31 iter 70, loss: 0.973, accuracy: 0.823\n",
      "epoch 31 iter 140, loss: 1.066, accuracy: 0.807\n",
      "epoch 31 iter 210, loss: 1.035, accuracy: 0.814\n",
      "epoch 31 iter 280, loss: 1.012, accuracy: 0.817\n",
      "epoch 32 iter 0, loss: 1.019, accuracy: 0.815\n",
      "epoch 32 iter 70, loss: 1.017, accuracy: 0.816\n",
      "epoch 32 iter 140, loss: 1.125, accuracy: 0.793\n",
      "epoch 32 iter 210, loss: 1.153, accuracy: 0.798\n",
      "epoch 32 iter 280, loss: 0.999, accuracy: 0.822\n",
      "epoch 33 iter 0, loss: 1.042, accuracy: 0.811\n",
      "epoch 33 iter 70, loss: 0.988, accuracy: 0.826\n",
      "epoch 33 iter 140, loss: 1.104, accuracy: 0.798\n",
      "epoch 33 iter 210, loss: 1.082, accuracy: 0.821\n",
      "epoch 33 iter 280, loss: 1.023, accuracy: 0.824\n",
      "epoch 34 iter 0, loss: 1.062, accuracy: 0.815\n",
      "epoch 34 iter 70, loss: 1.044, accuracy: 0.820\n",
      "epoch 34 iter 140, loss: 1.051, accuracy: 0.810\n",
      "epoch 34 iter 210, loss: 1.076, accuracy: 0.819\n",
      "epoch 34 iter 280, loss: 1.069, accuracy: 0.826\n",
      "epoch 35 iter 0, loss: 1.056, accuracy: 0.822\n",
      "epoch 35 iter 70, loss: 1.048, accuracy: 0.823\n",
      "epoch 35 iter 140, loss: 1.123, accuracy: 0.807\n",
      "epoch 35 iter 210, loss: 1.088, accuracy: 0.820\n",
      "epoch 35 iter 280, loss: 1.079, accuracy: 0.829\n",
      "epoch 36 iter 0, loss: 1.105, accuracy: 0.819\n",
      "epoch 36 iter 70, loss: 1.104, accuracy: 0.820\n",
      "epoch 36 iter 140, loss: 1.111, accuracy: 0.812\n",
      "epoch 36 iter 210, loss: 1.127, accuracy: 0.814\n",
      "epoch 36 iter 280, loss: 1.130, accuracy: 0.825\n",
      "epoch 37 iter 0, loss: 1.149, accuracy: 0.808\n",
      "epoch 37 iter 70, loss: 1.074, accuracy: 0.825\n",
      "epoch 37 iter 140, loss: 1.124, accuracy: 0.815\n",
      "epoch 37 iter 210, loss: 1.101, accuracy: 0.821\n",
      "epoch 37 iter 280, loss: 1.164, accuracy: 0.820\n",
      "epoch 38 iter 0, loss: 1.208, accuracy: 0.811\n",
      "epoch 38 iter 70, loss: 1.100, accuracy: 0.824\n",
      "epoch 38 iter 140, loss: 1.245, accuracy: 0.805\n",
      "epoch 38 iter 210, loss: 1.195, accuracy: 0.821\n",
      "epoch 38 iter 280, loss: 1.175, accuracy: 0.816\n",
      "epoch 39 iter 0, loss: 1.243, accuracy: 0.807\n",
      "epoch 39 iter 70, loss: 1.121, accuracy: 0.821\n",
      "epoch 39 iter 140, loss: 1.242, accuracy: 0.807\n",
      "epoch 39 iter 210, loss: 1.225, accuracy: 0.814\n",
      "epoch 39 iter 280, loss: 1.187, accuracy: 0.817\n",
      "epoch 40 iter 0, loss: 1.316, accuracy: 0.799\n",
      "epoch 40 iter 70, loss: 1.178, accuracy: 0.820\n",
      "epoch 40 iter 140, loss: 1.267, accuracy: 0.815\n",
      "epoch 40 iter 210, loss: 1.232, accuracy: 0.813\n",
      "epoch 40 iter 280, loss: 1.227, accuracy: 0.817\n",
      "epoch 41 iter 0, loss: 1.272, accuracy: 0.799\n",
      "epoch 41 iter 70, loss: 1.184, accuracy: 0.822\n",
      "epoch 41 iter 140, loss: 1.159, accuracy: 0.820\n",
      "epoch 41 iter 210, loss: 1.239, accuracy: 0.811\n",
      "epoch 41 iter 280, loss: 1.196, accuracy: 0.824\n",
      "epoch 42 iter 0, loss: 1.254, accuracy: 0.807\n",
      "epoch 42 iter 70, loss: 1.154, accuracy: 0.824\n",
      "epoch 42 iter 140, loss: 1.254, accuracy: 0.810\n",
      "epoch 42 iter 210, loss: 1.258, accuracy: 0.817\n",
      "epoch 42 iter 280, loss: 1.331, accuracy: 0.820\n",
      "epoch 43 iter 0, loss: 1.257, accuracy: 0.818\n",
      "epoch 43 iter 70, loss: 1.229, accuracy: 0.824\n",
      "epoch 43 iter 140, loss: 1.336, accuracy: 0.809\n",
      "epoch 43 iter 210, loss: 1.276, accuracy: 0.823\n",
      "epoch 43 iter 280, loss: 1.300, accuracy: 0.829\n",
      "epoch 44 iter 0, loss: 1.287, accuracy: 0.824\n",
      "epoch 44 iter 70, loss: 1.244, accuracy: 0.817\n",
      "epoch 44 iter 140, loss: 1.290, accuracy: 0.814\n",
      "epoch 44 iter 210, loss: 1.322, accuracy: 0.820\n",
      "epoch 44 iter 280, loss: 1.311, accuracy: 0.823\n",
      "epoch 45 iter 0, loss: 1.238, accuracy: 0.825\n",
      "epoch 45 iter 70, loss: 1.380, accuracy: 0.803\n",
      "epoch 45 iter 140, loss: 1.295, accuracy: 0.822\n",
      "epoch 45 iter 210, loss: 1.367, accuracy: 0.819\n",
      "epoch 45 iter 280, loss: 1.363, accuracy: 0.826\n",
      "epoch 46 iter 0, loss: 1.341, accuracy: 0.817\n",
      "epoch 46 iter 70, loss: 1.352, accuracy: 0.812\n",
      "epoch 46 iter 140, loss: 1.343, accuracy: 0.817\n",
      "epoch 46 iter 210, loss: 1.357, accuracy: 0.823\n",
      "epoch 46 iter 280, loss: 1.385, accuracy: 0.830\n",
      "epoch 47 iter 0, loss: 1.396, accuracy: 0.817\n",
      "epoch 47 iter 70, loss: 1.434, accuracy: 0.805\n",
      "epoch 47 iter 140, loss: 1.431, accuracy: 0.816\n",
      "epoch 47 iter 210, loss: 1.499, accuracy: 0.807\n",
      "epoch 47 iter 280, loss: 1.393, accuracy: 0.825\n",
      "epoch 48 iter 0, loss: 1.380, accuracy: 0.819\n",
      "epoch 48 iter 70, loss: 1.422, accuracy: 0.803\n",
      "epoch 48 iter 140, loss: 1.416, accuracy: 0.815\n",
      "epoch 48 iter 210, loss: 1.463, accuracy: 0.825\n",
      "epoch 48 iter 280, loss: 1.420, accuracy: 0.826\n",
      "epoch 49 iter 0, loss: 1.451, accuracy: 0.818\n",
      "epoch 49 iter 70, loss: 1.542, accuracy: 0.807\n",
      "epoch 49 iter 140, loss: 1.536, accuracy: 0.798\n",
      "epoch 49 iter 210, loss: 1.360, accuracy: 0.823\n",
      "epoch 49 iter 280, loss: 1.478, accuracy: 0.817\n",
      "epoch 50 iter 0, loss: 1.493, accuracy: 0.812\n",
      "epoch 50 iter 70, loss: 1.417, accuracy: 0.814\n",
      "epoch 50 iter 140, loss: 1.486, accuracy: 0.808\n",
      "epoch 50 iter 210, loss: 1.461, accuracy: 0.824\n",
      "epoch 50 iter 280, loss: 1.506, accuracy: 0.824\n",
      "epoch 51 iter 0, loss: 1.489, accuracy: 0.817\n",
      "epoch 51 iter 70, loss: 1.478, accuracy: 0.817\n",
      "epoch 51 iter 140, loss: 1.507, accuracy: 0.814\n",
      "epoch 51 iter 210, loss: 1.571, accuracy: 0.808\n",
      "epoch 51 iter 280, loss: 1.497, accuracy: 0.823\n",
      "epoch 52 iter 0, loss: 1.517, accuracy: 0.821\n",
      "epoch 52 iter 70, loss: 1.549, accuracy: 0.816\n",
      "epoch 52 iter 140, loss: 1.536, accuracy: 0.813\n",
      "epoch 52 iter 210, loss: 1.579, accuracy: 0.822\n",
      "epoch 52 iter 280, loss: 1.631, accuracy: 0.826\n",
      "epoch 53 iter 0, loss: 1.532, accuracy: 0.824\n",
      "epoch 53 iter 70, loss: 1.442, accuracy: 0.823\n",
      "epoch 53 iter 140, loss: 1.566, accuracy: 0.812\n",
      "epoch 53 iter 210, loss: 1.609, accuracy: 0.814\n",
      "epoch 53 iter 280, loss: 1.619, accuracy: 0.827\n",
      "epoch 54 iter 0, loss: 1.562, accuracy: 0.826\n",
      "epoch 54 iter 70, loss: 1.578, accuracy: 0.819\n",
      "epoch 54 iter 140, loss: 1.507, accuracy: 0.810\n",
      "epoch 54 iter 210, loss: 1.592, accuracy: 0.817\n",
      "epoch 54 iter 280, loss: 1.563, accuracy: 0.823\n",
      "epoch 55 iter 0, loss: 1.617, accuracy: 0.819\n",
      "epoch 55 iter 70, loss: 1.521, accuracy: 0.820\n",
      "epoch 55 iter 140, loss: 1.586, accuracy: 0.810\n",
      "epoch 55 iter 210, loss: 1.646, accuracy: 0.812\n",
      "epoch 55 iter 280, loss: 1.706, accuracy: 0.820\n",
      "epoch 56 iter 0, loss: 1.715, accuracy: 0.820\n",
      "epoch 56 iter 70, loss: 1.601, accuracy: 0.821\n",
      "epoch 56 iter 140, loss: 1.730, accuracy: 0.810\n",
      "epoch 56 iter 210, loss: 1.571, accuracy: 0.816\n",
      "epoch 56 iter 280, loss: 1.609, accuracy: 0.826\n",
      "epoch 57 iter 0, loss: 1.548, accuracy: 0.825\n",
      "epoch 57 iter 70, loss: 1.596, accuracy: 0.817\n",
      "epoch 57 iter 140, loss: 1.648, accuracy: 0.813\n",
      "epoch 57 iter 210, loss: 1.661, accuracy: 0.815\n",
      "epoch 57 iter 280, loss: 1.664, accuracy: 0.828\n",
      "epoch 58 iter 0, loss: 1.687, accuracy: 0.830\n",
      "epoch 58 iter 70, loss: 1.602, accuracy: 0.821\n",
      "epoch 58 iter 140, loss: 1.644, accuracy: 0.823\n",
      "epoch 58 iter 210, loss: 1.697, accuracy: 0.816\n",
      "epoch 58 iter 280, loss: 1.682, accuracy: 0.824\n",
      "epoch 59 iter 0, loss: 1.604, accuracy: 0.831\n",
      "epoch 59 iter 70, loss: 1.657, accuracy: 0.815\n",
      "epoch 59 iter 140, loss: 1.717, accuracy: 0.822\n",
      "epoch 59 iter 210, loss: 1.734, accuracy: 0.819\n",
      "epoch 59 iter 280, loss: 1.776, accuracy: 0.821\n",
      "epoch 60 iter 0, loss: 1.801, accuracy: 0.821\n",
      "epoch 60 iter 70, loss: 1.652, accuracy: 0.820\n",
      "epoch 60 iter 140, loss: 1.770, accuracy: 0.822\n",
      "epoch 60 iter 210, loss: 1.836, accuracy: 0.809\n",
      "epoch 60 iter 280, loss: 1.784, accuracy: 0.826\n",
      "epoch 61 iter 0, loss: 1.869, accuracy: 0.819\n",
      "epoch 61 iter 70, loss: 1.797, accuracy: 0.823\n",
      "epoch 61 iter 140, loss: 1.788, accuracy: 0.819\n",
      "epoch 61 iter 210, loss: 1.975, accuracy: 0.814\n",
      "epoch 61 iter 280, loss: 1.824, accuracy: 0.819\n",
      "epoch 62 iter 0, loss: 1.805, accuracy: 0.828\n",
      "epoch 62 iter 70, loss: 1.923, accuracy: 0.813\n",
      "epoch 62 iter 140, loss: 1.892, accuracy: 0.802\n",
      "epoch 62 iter 210, loss: 1.963, accuracy: 0.809\n",
      "epoch 62 iter 280, loss: 1.853, accuracy: 0.821\n",
      "epoch 63 iter 0, loss: 1.842, accuracy: 0.820\n",
      "epoch 63 iter 70, loss: 1.807, accuracy: 0.816\n",
      "epoch 63 iter 140, loss: 1.855, accuracy: 0.812\n",
      "epoch 63 iter 210, loss: 1.985, accuracy: 0.809\n",
      "epoch 63 iter 280, loss: 1.962, accuracy: 0.813\n",
      "epoch 64 iter 0, loss: 1.911, accuracy: 0.821\n",
      "epoch 64 iter 70, loss: 1.801, accuracy: 0.812\n",
      "epoch 64 iter 140, loss: 1.914, accuracy: 0.817\n",
      "epoch 64 iter 210, loss: 2.132, accuracy: 0.812\n",
      "epoch 64 iter 280, loss: 1.940, accuracy: 0.810\n",
      "epoch 65 iter 0, loss: 1.859, accuracy: 0.826\n",
      "epoch 65 iter 70, loss: 1.767, accuracy: 0.825\n",
      "epoch 65 iter 140, loss: 1.850, accuracy: 0.815\n",
      "epoch 65 iter 210, loss: 2.035, accuracy: 0.809\n",
      "epoch 65 iter 280, loss: 2.000, accuracy: 0.813\n",
      "epoch 66 iter 0, loss: 1.887, accuracy: 0.825\n",
      "epoch 66 iter 70, loss: 1.923, accuracy: 0.816\n",
      "epoch 66 iter 140, loss: 1.824, accuracy: 0.824\n",
      "epoch 66 iter 210, loss: 2.142, accuracy: 0.812\n",
      "epoch 66 iter 280, loss: 2.031, accuracy: 0.809\n",
      "epoch 67 iter 0, loss: 2.002, accuracy: 0.817\n",
      "epoch 67 iter 70, loss: 1.873, accuracy: 0.821\n",
      "epoch 67 iter 140, loss: 1.848, accuracy: 0.821\n",
      "epoch 67 iter 210, loss: 2.049, accuracy: 0.812\n",
      "epoch 67 iter 280, loss: 1.909, accuracy: 0.823\n",
      "epoch 68 iter 0, loss: 1.905, accuracy: 0.828\n",
      "epoch 68 iter 70, loss: 1.865, accuracy: 0.820\n",
      "epoch 68 iter 140, loss: 1.886, accuracy: 0.816\n",
      "epoch 68 iter 210, loss: 2.016, accuracy: 0.819\n",
      "epoch 68 iter 280, loss: 1.990, accuracy: 0.817\n",
      "epoch 69 iter 0, loss: 1.896, accuracy: 0.827\n",
      "epoch 69 iter 70, loss: 1.942, accuracy: 0.816\n",
      "epoch 69 iter 140, loss: 1.912, accuracy: 0.818\n",
      "epoch 69 iter 210, loss: 2.081, accuracy: 0.813\n",
      "epoch 69 iter 280, loss: 2.084, accuracy: 0.812\n",
      "epoch 70 iter 0, loss: 2.048, accuracy: 0.827\n",
      "epoch 70 iter 70, loss: 2.148, accuracy: 0.809\n",
      "epoch 70 iter 140, loss: 2.010, accuracy: 0.810\n",
      "epoch 70 iter 210, loss: 2.178, accuracy: 0.811\n",
      "epoch 70 iter 280, loss: 2.016, accuracy: 0.823\n",
      "epoch 71 iter 0, loss: 1.985, accuracy: 0.823\n",
      "epoch 71 iter 70, loss: 2.069, accuracy: 0.820\n",
      "epoch 71 iter 140, loss: 1.919, accuracy: 0.814\n",
      "epoch 71 iter 210, loss: 2.352, accuracy: 0.802\n",
      "epoch 71 iter 280, loss: 2.030, accuracy: 0.824\n",
      "epoch 72 iter 0, loss: 1.999, accuracy: 0.833\n",
      "epoch 72 iter 70, loss: 1.999, accuracy: 0.824\n",
      "epoch 72 iter 140, loss: 1.953, accuracy: 0.821\n",
      "epoch 72 iter 210, loss: 2.371, accuracy: 0.807\n",
      "epoch 72 iter 280, loss: 2.170, accuracy: 0.811\n",
      "epoch 73 iter 0, loss: 2.223, accuracy: 0.811\n",
      "epoch 73 iter 70, loss: 2.190, accuracy: 0.818\n",
      "epoch 73 iter 140, loss: 1.985, accuracy: 0.818\n",
      "epoch 73 iter 210, loss: 2.192, accuracy: 0.812\n",
      "epoch 73 iter 280, loss: 2.232, accuracy: 0.817\n",
      "epoch 74 iter 0, loss: 2.080, accuracy: 0.824\n",
      "epoch 74 iter 70, loss: 2.135, accuracy: 0.813\n",
      "epoch 74 iter 140, loss: 2.138, accuracy: 0.811\n",
      "epoch 74 iter 210, loss: 2.299, accuracy: 0.811\n",
      "epoch 74 iter 280, loss: 2.140, accuracy: 0.817\n",
      "epoch 75 iter 0, loss: 2.115, accuracy: 0.822\n",
      "epoch 75 iter 70, loss: 2.126, accuracy: 0.823\n",
      "epoch 75 iter 140, loss: 2.082, accuracy: 0.820\n",
      "epoch 75 iter 210, loss: 2.249, accuracy: 0.807\n",
      "epoch 75 iter 280, loss: 2.224, accuracy: 0.818\n",
      "epoch 76 iter 0, loss: 2.122, accuracy: 0.820\n",
      "epoch 76 iter 70, loss: 2.182, accuracy: 0.817\n",
      "epoch 76 iter 140, loss: 2.094, accuracy: 0.813\n",
      "epoch 76 iter 210, loss: 2.384, accuracy: 0.802\n",
      "epoch 76 iter 280, loss: 2.376, accuracy: 0.808\n",
      "epoch 77 iter 0, loss: 2.273, accuracy: 0.815\n",
      "epoch 77 iter 70, loss: 2.271, accuracy: 0.814\n",
      "epoch 77 iter 140, loss: 2.320, accuracy: 0.810\n",
      "epoch 77 iter 210, loss: 2.276, accuracy: 0.809\n",
      "epoch 77 iter 280, loss: 2.225, accuracy: 0.818\n",
      "epoch 78 iter 0, loss: 2.173, accuracy: 0.816\n",
      "epoch 78 iter 70, loss: 2.216, accuracy: 0.822\n",
      "epoch 78 iter 140, loss: 2.237, accuracy: 0.810\n",
      "epoch 78 iter 210, loss: 2.312, accuracy: 0.807\n",
      "epoch 78 iter 280, loss: 2.271, accuracy: 0.820\n",
      "epoch 79 iter 0, loss: 2.200, accuracy: 0.818\n",
      "epoch 79 iter 70, loss: 2.263, accuracy: 0.818\n",
      "epoch 79 iter 140, loss: 2.223, accuracy: 0.815\n",
      "epoch 79 iter 210, loss: 2.373, accuracy: 0.807\n",
      "epoch 79 iter 280, loss: 2.259, accuracy: 0.816\n",
      "epoch 80 iter 0, loss: 2.255, accuracy: 0.818\n",
      "epoch 80 iter 70, loss: 2.214, accuracy: 0.817\n",
      "epoch 80 iter 140, loss: 2.485, accuracy: 0.816\n",
      "epoch 80 iter 210, loss: 2.281, accuracy: 0.816\n",
      "epoch 80 iter 280, loss: 2.370, accuracy: 0.820\n",
      "epoch 81 iter 0, loss: 2.254, accuracy: 0.818\n",
      "epoch 81 iter 70, loss: 2.309, accuracy: 0.815\n",
      "epoch 81 iter 140, loss: 2.366, accuracy: 0.823\n",
      "epoch 81 iter 210, loss: 2.445, accuracy: 0.815\n",
      "epoch 81 iter 280, loss: 2.454, accuracy: 0.819\n",
      "epoch 82 iter 0, loss: 2.388, accuracy: 0.822\n",
      "epoch 82 iter 70, loss: 2.339, accuracy: 0.811\n",
      "epoch 82 iter 140, loss: 2.395, accuracy: 0.815\n",
      "epoch 82 iter 210, loss: 2.297, accuracy: 0.824\n",
      "epoch 82 iter 280, loss: 2.253, accuracy: 0.816\n",
      "epoch 83 iter 0, loss: 2.229, accuracy: 0.823\n",
      "epoch 83 iter 70, loss: 2.346, accuracy: 0.814\n",
      "epoch 83 iter 140, loss: 2.418, accuracy: 0.814\n",
      "epoch 83 iter 210, loss: 2.351, accuracy: 0.817\n",
      "epoch 83 iter 280, loss: 2.385, accuracy: 0.820\n",
      "epoch 84 iter 0, loss: 2.329, accuracy: 0.823\n",
      "epoch 84 iter 70, loss: 2.327, accuracy: 0.819\n",
      "epoch 84 iter 140, loss: 2.279, accuracy: 0.818\n",
      "epoch 84 iter 210, loss: 2.485, accuracy: 0.818\n",
      "epoch 84 iter 280, loss: 2.321, accuracy: 0.817\n",
      "epoch 85 iter 0, loss: 2.463, accuracy: 0.817\n",
      "epoch 85 iter 70, loss: 2.517, accuracy: 0.816\n",
      "epoch 85 iter 140, loss: 2.371, accuracy: 0.818\n",
      "epoch 85 iter 210, loss: 2.507, accuracy: 0.813\n",
      "epoch 85 iter 280, loss: 2.417, accuracy: 0.819\n",
      "epoch 86 iter 0, loss: 2.443, accuracy: 0.818\n",
      "epoch 86 iter 70, loss: 2.379, accuracy: 0.806\n",
      "epoch 86 iter 140, loss: 2.397, accuracy: 0.816\n",
      "epoch 86 iter 210, loss: 2.648, accuracy: 0.814\n",
      "epoch 86 iter 280, loss: 2.517, accuracy: 0.819\n",
      "epoch 87 iter 0, loss: 2.510, accuracy: 0.813\n",
      "epoch 87 iter 70, loss: 2.444, accuracy: 0.806\n",
      "epoch 87 iter 140, loss: 2.472, accuracy: 0.816\n",
      "epoch 87 iter 210, loss: 2.583, accuracy: 0.813\n",
      "epoch 87 iter 280, loss: 2.530, accuracy: 0.818\n",
      "epoch 88 iter 0, loss: 2.502, accuracy: 0.821\n",
      "epoch 88 iter 70, loss: 2.449, accuracy: 0.816\n",
      "epoch 88 iter 140, loss: 2.632, accuracy: 0.816\n",
      "epoch 88 iter 210, loss: 2.594, accuracy: 0.810\n",
      "epoch 88 iter 280, loss: 2.573, accuracy: 0.805\n",
      "epoch 89 iter 0, loss: 2.460, accuracy: 0.818\n",
      "epoch 89 iter 70, loss: 2.554, accuracy: 0.815\n",
      "epoch 89 iter 140, loss: 2.495, accuracy: 0.813\n",
      "epoch 89 iter 210, loss: 2.468, accuracy: 0.824\n",
      "epoch 89 iter 280, loss: 2.566, accuracy: 0.811\n",
      "epoch 90 iter 0, loss: 2.485, accuracy: 0.823\n",
      "epoch 90 iter 70, loss: 2.523, accuracy: 0.814\n",
      "epoch 90 iter 140, loss: 2.460, accuracy: 0.819\n",
      "epoch 90 iter 210, loss: 2.692, accuracy: 0.818\n",
      "epoch 90 iter 280, loss: 2.538, accuracy: 0.811\n",
      "epoch 91 iter 0, loss: 2.424, accuracy: 0.817\n",
      "epoch 91 iter 70, loss: 2.582, accuracy: 0.814\n",
      "epoch 91 iter 140, loss: 2.650, accuracy: 0.823\n",
      "epoch 91 iter 210, loss: 2.476, accuracy: 0.819\n",
      "epoch 91 iter 280, loss: 2.539, accuracy: 0.819\n",
      "epoch 92 iter 0, loss: 2.512, accuracy: 0.825\n",
      "epoch 92 iter 70, loss: 2.627, accuracy: 0.812\n",
      "epoch 92 iter 140, loss: 2.585, accuracy: 0.817\n",
      "epoch 92 iter 210, loss: 2.604, accuracy: 0.821\n",
      "epoch 92 iter 280, loss: 2.624, accuracy: 0.813\n",
      "epoch 93 iter 0, loss: 2.478, accuracy: 0.823\n",
      "epoch 93 iter 70, loss: 2.668, accuracy: 0.818\n",
      "epoch 93 iter 140, loss: 2.830, accuracy: 0.809\n",
      "epoch 93 iter 210, loss: 2.606, accuracy: 0.823\n",
      "epoch 93 iter 280, loss: 2.557, accuracy: 0.812\n",
      "epoch 94 iter 0, loss: 2.598, accuracy: 0.815\n",
      "epoch 94 iter 70, loss: 2.553, accuracy: 0.824\n",
      "epoch 94 iter 140, loss: 2.534, accuracy: 0.817\n",
      "epoch 94 iter 210, loss: 2.523, accuracy: 0.816\n",
      "epoch 94 iter 280, loss: 2.691, accuracy: 0.817\n",
      "epoch 95 iter 0, loss: 2.629, accuracy: 0.816\n",
      "epoch 95 iter 70, loss: 2.599, accuracy: 0.817\n",
      "epoch 95 iter 140, loss: 2.751, accuracy: 0.816\n",
      "epoch 95 iter 210, loss: 2.576, accuracy: 0.822\n",
      "epoch 95 iter 280, loss: 2.535, accuracy: 0.816\n",
      "epoch 96 iter 0, loss: 2.614, accuracy: 0.822\n",
      "epoch 96 iter 70, loss: 2.704, accuracy: 0.813\n",
      "epoch 96 iter 140, loss: 2.687, accuracy: 0.809\n",
      "epoch 96 iter 210, loss: 2.618, accuracy: 0.819\n",
      "epoch 96 iter 280, loss: 2.779, accuracy: 0.820\n",
      "epoch 97 iter 0, loss: 2.620, accuracy: 0.824\n",
      "epoch 97 iter 70, loss: 2.795, accuracy: 0.814\n",
      "epoch 97 iter 140, loss: 3.010, accuracy: 0.821\n",
      "epoch 97 iter 210, loss: 2.695, accuracy: 0.829\n",
      "epoch 97 iter 280, loss: 2.760, accuracy: 0.812\n",
      "epoch 98 iter 0, loss: 2.635, accuracy: 0.816\n",
      "epoch 98 iter 70, loss: 2.854, accuracy: 0.810\n",
      "epoch 98 iter 140, loss: 2.700, accuracy: 0.818\n",
      "epoch 98 iter 210, loss: 2.826, accuracy: 0.816\n",
      "epoch 98 iter 280, loss: 2.861, accuracy: 0.816\n",
      "epoch 99 iter 0, loss: 2.905, accuracy: 0.807\n",
      "epoch 99 iter 70, loss: 2.852, accuracy: 0.817\n",
      "epoch 99 iter 140, loss: 2.868, accuracy: 0.819\n",
      "epoch 99 iter 210, loss: 2.993, accuracy: 0.815\n",
      "epoch 99 iter 280, loss: 2.780, accuracy: 0.817\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=2,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=2,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 5.854, accuracy: 0.078\n",
      "epoch 0 iter 70, loss: 2.155, accuracy: 0.233\n",
      "epoch 0 iter 140, loss: 1.807, accuracy: 0.384\n",
      "epoch 0 iter 210, loss: 1.414, accuracy: 0.532\n",
      "epoch 0 iter 280, loss: 1.183, accuracy: 0.625\n",
      "epoch 1 iter 0, loss: 1.168, accuracy: 0.635\n",
      "epoch 1 iter 70, loss: 1.074, accuracy: 0.661\n",
      "epoch 1 iter 140, loss: 0.978, accuracy: 0.707\n",
      "epoch 1 iter 210, loss: 0.928, accuracy: 0.723\n",
      "epoch 1 iter 280, loss: 1.030, accuracy: 0.688\n",
      "epoch 2 iter 0, loss: 0.925, accuracy: 0.724\n",
      "epoch 2 iter 70, loss: 0.895, accuracy: 0.736\n",
      "epoch 2 iter 140, loss: 0.870, accuracy: 0.746\n",
      "epoch 2 iter 210, loss: 0.826, accuracy: 0.759\n",
      "epoch 2 iter 280, loss: 0.916, accuracy: 0.726\n",
      "epoch 3 iter 0, loss: 0.831, accuracy: 0.759\n",
      "epoch 3 iter 70, loss: 0.839, accuracy: 0.758\n",
      "epoch 3 iter 140, loss: 0.851, accuracy: 0.753\n",
      "epoch 3 iter 210, loss: 0.780, accuracy: 0.773\n",
      "epoch 3 iter 280, loss: 0.851, accuracy: 0.750\n",
      "epoch 4 iter 0, loss: 0.775, accuracy: 0.775\n",
      "epoch 4 iter 70, loss: 0.799, accuracy: 0.768\n",
      "epoch 4 iter 140, loss: 0.831, accuracy: 0.757\n",
      "epoch 4 iter 210, loss: 0.764, accuracy: 0.777\n",
      "epoch 4 iter 280, loss: 0.844, accuracy: 0.749\n",
      "epoch 5 iter 0, loss: 0.790, accuracy: 0.770\n",
      "epoch 5 iter 70, loss: 0.740, accuracy: 0.785\n",
      "epoch 5 iter 140, loss: 0.798, accuracy: 0.766\n",
      "epoch 5 iter 210, loss: 0.717, accuracy: 0.794\n",
      "epoch 5 iter 280, loss: 0.776, accuracy: 0.772\n",
      "epoch 6 iter 0, loss: 0.736, accuracy: 0.787\n",
      "epoch 6 iter 70, loss: 0.727, accuracy: 0.790\n",
      "epoch 6 iter 140, loss: 0.761, accuracy: 0.781\n",
      "epoch 6 iter 210, loss: 0.715, accuracy: 0.793\n",
      "epoch 6 iter 280, loss: 0.739, accuracy: 0.787\n",
      "epoch 7 iter 0, loss: 0.722, accuracy: 0.791\n",
      "epoch 7 iter 70, loss: 0.706, accuracy: 0.797\n",
      "epoch 7 iter 140, loss: 0.765, accuracy: 0.779\n",
      "epoch 7 iter 210, loss: 0.703, accuracy: 0.797\n",
      "epoch 7 iter 280, loss: 0.706, accuracy: 0.799\n",
      "epoch 8 iter 0, loss: 0.698, accuracy: 0.801\n",
      "epoch 8 iter 70, loss: 0.690, accuracy: 0.806\n",
      "epoch 8 iter 140, loss: 0.721, accuracy: 0.791\n",
      "epoch 8 iter 210, loss: 0.714, accuracy: 0.793\n",
      "epoch 8 iter 280, loss: 0.696, accuracy: 0.801\n",
      "epoch 9 iter 0, loss: 0.718, accuracy: 0.793\n",
      "epoch 9 iter 70, loss: 0.693, accuracy: 0.804\n",
      "epoch 9 iter 140, loss: 0.730, accuracy: 0.792\n",
      "epoch 9 iter 210, loss: 0.707, accuracy: 0.797\n",
      "epoch 9 iter 280, loss: 0.704, accuracy: 0.800\n",
      "epoch 10 iter 0, loss: 0.696, accuracy: 0.800\n",
      "epoch 10 iter 70, loss: 0.691, accuracy: 0.805\n",
      "epoch 10 iter 140, loss: 0.710, accuracy: 0.798\n",
      "epoch 10 iter 210, loss: 0.693, accuracy: 0.806\n",
      "epoch 10 iter 280, loss: 0.691, accuracy: 0.803\n",
      "epoch 11 iter 0, loss: 0.692, accuracy: 0.804\n",
      "epoch 11 iter 70, loss: 0.683, accuracy: 0.808\n",
      "epoch 11 iter 140, loss: 0.751, accuracy: 0.786\n",
      "epoch 11 iter 210, loss: 0.663, accuracy: 0.814\n",
      "epoch 11 iter 280, loss: 0.676, accuracy: 0.809\n",
      "epoch 12 iter 0, loss: 0.693, accuracy: 0.803\n",
      "epoch 12 iter 70, loss: 0.675, accuracy: 0.811\n",
      "epoch 12 iter 140, loss: 0.716, accuracy: 0.797\n",
      "epoch 12 iter 210, loss: 0.685, accuracy: 0.804\n",
      "epoch 12 iter 280, loss: 0.677, accuracy: 0.810\n",
      "epoch 13 iter 0, loss: 0.684, accuracy: 0.809\n",
      "epoch 13 iter 70, loss: 0.668, accuracy: 0.813\n",
      "epoch 13 iter 140, loss: 0.718, accuracy: 0.798\n",
      "epoch 13 iter 210, loss: 0.681, accuracy: 0.807\n",
      "epoch 13 iter 280, loss: 0.687, accuracy: 0.808\n",
      "epoch 14 iter 0, loss: 0.701, accuracy: 0.803\n",
      "epoch 14 iter 70, loss: 0.700, accuracy: 0.803\n",
      "epoch 14 iter 140, loss: 0.713, accuracy: 0.799\n",
      "epoch 14 iter 210, loss: 0.670, accuracy: 0.814\n",
      "epoch 14 iter 280, loss: 0.666, accuracy: 0.814\n",
      "epoch 15 iter 0, loss: 0.683, accuracy: 0.813\n",
      "epoch 15 iter 70, loss: 0.713, accuracy: 0.799\n",
      "epoch 15 iter 140, loss: 0.719, accuracy: 0.803\n",
      "epoch 15 iter 210, loss: 0.670, accuracy: 0.813\n",
      "epoch 15 iter 280, loss: 0.688, accuracy: 0.811\n",
      "epoch 16 iter 0, loss: 0.693, accuracy: 0.810\n",
      "epoch 16 iter 70, loss: 0.712, accuracy: 0.801\n",
      "epoch 16 iter 140, loss: 0.705, accuracy: 0.806\n",
      "epoch 16 iter 210, loss: 0.668, accuracy: 0.816\n",
      "epoch 16 iter 280, loss: 0.675, accuracy: 0.818\n",
      "epoch 17 iter 0, loss: 0.698, accuracy: 0.812\n",
      "epoch 17 iter 70, loss: 0.697, accuracy: 0.810\n",
      "epoch 17 iter 140, loss: 0.731, accuracy: 0.799\n",
      "epoch 17 iter 210, loss: 0.678, accuracy: 0.815\n",
      "epoch 17 iter 280, loss: 0.688, accuracy: 0.815\n",
      "epoch 18 iter 0, loss: 0.691, accuracy: 0.812\n",
      "epoch 18 iter 70, loss: 0.692, accuracy: 0.813\n",
      "epoch 18 iter 140, loss: 0.740, accuracy: 0.795\n",
      "epoch 18 iter 210, loss: 0.675, accuracy: 0.816\n",
      "epoch 18 iter 280, loss: 0.739, accuracy: 0.799\n",
      "epoch 19 iter 0, loss: 0.707, accuracy: 0.808\n",
      "epoch 19 iter 70, loss: 0.716, accuracy: 0.808\n",
      "epoch 19 iter 140, loss: 0.740, accuracy: 0.798\n",
      "epoch 19 iter 210, loss: 0.667, accuracy: 0.820\n",
      "epoch 19 iter 280, loss: 0.773, accuracy: 0.792\n",
      "epoch 20 iter 0, loss: 0.720, accuracy: 0.803\n",
      "epoch 20 iter 70, loss: 0.715, accuracy: 0.807\n",
      "epoch 20 iter 140, loss: 0.772, accuracy: 0.796\n",
      "epoch 20 iter 210, loss: 0.706, accuracy: 0.811\n",
      "epoch 20 iter 280, loss: 0.820, accuracy: 0.780\n",
      "epoch 21 iter 0, loss: 0.734, accuracy: 0.806\n",
      "epoch 21 iter 70, loss: 0.756, accuracy: 0.796\n",
      "epoch 21 iter 140, loss: 0.763, accuracy: 0.801\n",
      "epoch 21 iter 210, loss: 0.703, accuracy: 0.814\n",
      "epoch 21 iter 280, loss: 0.822, accuracy: 0.782\n",
      "epoch 22 iter 0, loss: 0.751, accuracy: 0.802\n",
      "epoch 22 iter 70, loss: 0.765, accuracy: 0.797\n",
      "epoch 22 iter 140, loss: 0.763, accuracy: 0.799\n",
      "epoch 22 iter 210, loss: 0.710, accuracy: 0.811\n",
      "epoch 22 iter 280, loss: 0.798, accuracy: 0.791\n",
      "epoch 23 iter 0, loss: 0.749, accuracy: 0.805\n",
      "epoch 23 iter 70, loss: 0.784, accuracy: 0.789\n",
      "epoch 23 iter 140, loss: 0.765, accuracy: 0.802\n",
      "epoch 23 iter 210, loss: 0.710, accuracy: 0.809\n",
      "epoch 23 iter 280, loss: 0.775, accuracy: 0.798\n",
      "epoch 24 iter 0, loss: 0.795, accuracy: 0.798\n",
      "epoch 24 iter 70, loss: 0.780, accuracy: 0.798\n",
      "epoch 24 iter 140, loss: 0.778, accuracy: 0.799\n",
      "epoch 24 iter 210, loss: 0.718, accuracy: 0.807\n",
      "epoch 24 iter 280, loss: 0.766, accuracy: 0.802\n",
      "epoch 25 iter 0, loss: 0.818, accuracy: 0.799\n",
      "epoch 25 iter 70, loss: 0.799, accuracy: 0.796\n",
      "epoch 25 iter 140, loss: 0.784, accuracy: 0.799\n",
      "epoch 25 iter 210, loss: 0.748, accuracy: 0.802\n",
      "epoch 25 iter 280, loss: 0.784, accuracy: 0.800\n",
      "epoch 26 iter 0, loss: 0.783, accuracy: 0.799\n",
      "epoch 26 iter 70, loss: 0.818, accuracy: 0.792\n",
      "epoch 26 iter 140, loss: 0.770, accuracy: 0.804\n",
      "epoch 26 iter 210, loss: 0.754, accuracy: 0.806\n",
      "epoch 26 iter 280, loss: 0.802, accuracy: 0.793\n",
      "epoch 27 iter 0, loss: 0.752, accuracy: 0.807\n",
      "epoch 27 iter 70, loss: 0.815, accuracy: 0.793\n",
      "epoch 27 iter 140, loss: 0.773, accuracy: 0.807\n",
      "epoch 27 iter 210, loss: 0.775, accuracy: 0.803\n",
      "epoch 27 iter 280, loss: 0.827, accuracy: 0.791\n",
      "epoch 28 iter 0, loss: 0.816, accuracy: 0.799\n",
      "epoch 28 iter 70, loss: 0.810, accuracy: 0.798\n",
      "epoch 28 iter 140, loss: 0.821, accuracy: 0.791\n",
      "epoch 28 iter 210, loss: 0.772, accuracy: 0.805\n",
      "epoch 28 iter 280, loss: 0.785, accuracy: 0.805\n",
      "epoch 29 iter 0, loss: 0.796, accuracy: 0.806\n",
      "epoch 29 iter 70, loss: 0.822, accuracy: 0.798\n",
      "epoch 29 iter 140, loss: 0.832, accuracy: 0.794\n",
      "epoch 29 iter 210, loss: 0.789, accuracy: 0.806\n",
      "epoch 29 iter 280, loss: 0.797, accuracy: 0.803\n",
      "epoch 30 iter 0, loss: 0.853, accuracy: 0.795\n",
      "epoch 30 iter 70, loss: 0.828, accuracy: 0.798\n",
      "epoch 30 iter 140, loss: 0.820, accuracy: 0.797\n",
      "epoch 30 iter 210, loss: 0.770, accuracy: 0.808\n",
      "epoch 30 iter 280, loss: 0.816, accuracy: 0.805\n",
      "epoch 31 iter 0, loss: 0.788, accuracy: 0.807\n",
      "epoch 31 iter 70, loss: 0.826, accuracy: 0.801\n",
      "epoch 31 iter 140, loss: 0.835, accuracy: 0.796\n",
      "epoch 31 iter 210, loss: 0.791, accuracy: 0.808\n",
      "epoch 31 iter 280, loss: 0.827, accuracy: 0.802\n",
      "epoch 32 iter 0, loss: 0.832, accuracy: 0.803\n",
      "epoch 32 iter 70, loss: 0.860, accuracy: 0.800\n",
      "epoch 32 iter 140, loss: 0.858, accuracy: 0.797\n",
      "epoch 32 iter 210, loss: 0.811, accuracy: 0.802\n",
      "epoch 32 iter 280, loss: 0.853, accuracy: 0.805\n",
      "epoch 33 iter 0, loss: 0.848, accuracy: 0.803\n",
      "epoch 33 iter 70, loss: 0.857, accuracy: 0.800\n",
      "epoch 33 iter 140, loss: 0.859, accuracy: 0.800\n",
      "epoch 33 iter 210, loss: 0.823, accuracy: 0.804\n",
      "epoch 33 iter 280, loss: 0.895, accuracy: 0.799\n",
      "epoch 34 iter 0, loss: 0.859, accuracy: 0.804\n",
      "epoch 34 iter 70, loss: 0.867, accuracy: 0.804\n",
      "epoch 34 iter 140, loss: 0.861, accuracy: 0.794\n",
      "epoch 34 iter 210, loss: 0.866, accuracy: 0.795\n",
      "epoch 34 iter 280, loss: 0.862, accuracy: 0.804\n",
      "epoch 35 iter 0, loss: 0.998, accuracy: 0.781\n",
      "epoch 35 iter 70, loss: 0.869, accuracy: 0.805\n",
      "epoch 35 iter 140, loss: 0.860, accuracy: 0.799\n",
      "epoch 35 iter 210, loss: 0.877, accuracy: 0.794\n",
      "epoch 35 iter 280, loss: 0.842, accuracy: 0.811\n",
      "epoch 36 iter 0, loss: 0.958, accuracy: 0.794\n",
      "epoch 36 iter 70, loss: 0.888, accuracy: 0.802\n",
      "epoch 36 iter 140, loss: 0.868, accuracy: 0.802\n",
      "epoch 36 iter 210, loss: 0.876, accuracy: 0.799\n",
      "epoch 36 iter 280, loss: 0.850, accuracy: 0.809\n",
      "epoch 37 iter 0, loss: 0.998, accuracy: 0.787\n",
      "epoch 37 iter 70, loss: 0.898, accuracy: 0.805\n",
      "epoch 37 iter 140, loss: 0.902, accuracy: 0.797\n",
      "epoch 37 iter 210, loss: 0.906, accuracy: 0.792\n",
      "epoch 37 iter 280, loss: 0.867, accuracy: 0.809\n",
      "epoch 38 iter 0, loss: 0.973, accuracy: 0.797\n",
      "epoch 38 iter 70, loss: 0.920, accuracy: 0.804\n",
      "epoch 38 iter 140, loss: 0.932, accuracy: 0.795\n",
      "epoch 38 iter 210, loss: 0.894, accuracy: 0.794\n",
      "epoch 38 iter 280, loss: 0.884, accuracy: 0.809\n",
      "epoch 39 iter 0, loss: 0.959, accuracy: 0.799\n",
      "epoch 39 iter 70, loss: 0.928, accuracy: 0.801\n",
      "epoch 39 iter 140, loss: 0.905, accuracy: 0.795\n",
      "epoch 39 iter 210, loss: 0.901, accuracy: 0.800\n",
      "epoch 39 iter 280, loss: 0.895, accuracy: 0.811\n",
      "epoch 40 iter 0, loss: 0.978, accuracy: 0.800\n",
      "epoch 40 iter 70, loss: 0.977, accuracy: 0.787\n",
      "epoch 40 iter 140, loss: 0.868, accuracy: 0.803\n",
      "epoch 40 iter 210, loss: 0.906, accuracy: 0.800\n",
      "epoch 40 iter 280, loss: 0.899, accuracy: 0.802\n",
      "epoch 41 iter 0, loss: 0.937, accuracy: 0.793\n",
      "epoch 41 iter 70, loss: 0.970, accuracy: 0.798\n",
      "epoch 41 iter 140, loss: 0.912, accuracy: 0.799\n",
      "epoch 41 iter 210, loss: 0.946, accuracy: 0.794\n",
      "epoch 41 iter 280, loss: 0.927, accuracy: 0.800\n",
      "epoch 42 iter 0, loss: 0.933, accuracy: 0.796\n",
      "epoch 42 iter 70, loss: 0.986, accuracy: 0.791\n",
      "epoch 42 iter 140, loss: 0.903, accuracy: 0.804\n",
      "epoch 42 iter 210, loss: 0.927, accuracy: 0.798\n",
      "epoch 42 iter 280, loss: 0.922, accuracy: 0.807\n",
      "epoch 43 iter 0, loss: 0.925, accuracy: 0.805\n",
      "epoch 43 iter 70, loss: 0.990, accuracy: 0.793\n",
      "epoch 43 iter 140, loss: 0.918, accuracy: 0.802\n",
      "epoch 43 iter 210, loss: 0.937, accuracy: 0.799\n",
      "epoch 43 iter 280, loss: 0.886, accuracy: 0.815\n",
      "epoch 44 iter 0, loss: 0.940, accuracy: 0.803\n",
      "epoch 44 iter 70, loss: 0.998, accuracy: 0.790\n",
      "epoch 44 iter 140, loss: 0.973, accuracy: 0.795\n",
      "epoch 44 iter 210, loss: 0.931, accuracy: 0.803\n",
      "epoch 44 iter 280, loss: 0.953, accuracy: 0.802\n",
      "epoch 45 iter 0, loss: 0.986, accuracy: 0.798\n",
      "epoch 45 iter 70, loss: 1.048, accuracy: 0.788\n",
      "epoch 45 iter 140, loss: 0.941, accuracy: 0.803\n",
      "epoch 45 iter 210, loss: 0.971, accuracy: 0.792\n",
      "epoch 45 iter 280, loss: 0.915, accuracy: 0.812\n",
      "epoch 46 iter 0, loss: 0.975, accuracy: 0.804\n",
      "epoch 46 iter 70, loss: 1.076, accuracy: 0.780\n",
      "epoch 46 iter 140, loss: 0.972, accuracy: 0.795\n",
      "epoch 46 iter 210, loss: 0.942, accuracy: 0.795\n",
      "epoch 46 iter 280, loss: 0.968, accuracy: 0.809\n",
      "epoch 47 iter 0, loss: 0.998, accuracy: 0.801\n",
      "epoch 47 iter 70, loss: 1.048, accuracy: 0.796\n",
      "epoch 47 iter 140, loss: 0.996, accuracy: 0.797\n",
      "epoch 47 iter 210, loss: 0.960, accuracy: 0.799\n",
      "epoch 47 iter 280, loss: 0.965, accuracy: 0.810\n",
      "epoch 48 iter 0, loss: 1.005, accuracy: 0.803\n",
      "epoch 48 iter 70, loss: 1.089, accuracy: 0.790\n",
      "epoch 48 iter 140, loss: 0.997, accuracy: 0.793\n",
      "epoch 48 iter 210, loss: 0.970, accuracy: 0.797\n",
      "epoch 48 iter 280, loss: 0.996, accuracy: 0.805\n",
      "epoch 49 iter 0, loss: 1.019, accuracy: 0.799\n",
      "epoch 49 iter 70, loss: 1.089, accuracy: 0.787\n",
      "epoch 49 iter 140, loss: 1.007, accuracy: 0.798\n",
      "epoch 49 iter 210, loss: 0.987, accuracy: 0.799\n",
      "epoch 49 iter 280, loss: 0.982, accuracy: 0.809\n",
      "epoch 50 iter 0, loss: 1.014, accuracy: 0.800\n",
      "epoch 50 iter 70, loss: 1.116, accuracy: 0.788\n",
      "epoch 50 iter 140, loss: 0.995, accuracy: 0.803\n",
      "epoch 50 iter 210, loss: 1.001, accuracy: 0.798\n",
      "epoch 50 iter 280, loss: 0.949, accuracy: 0.814\n",
      "epoch 51 iter 0, loss: 1.008, accuracy: 0.807\n",
      "epoch 51 iter 70, loss: 1.086, accuracy: 0.795\n",
      "epoch 51 iter 140, loss: 0.988, accuracy: 0.804\n",
      "epoch 51 iter 210, loss: 0.983, accuracy: 0.801\n",
      "epoch 51 iter 280, loss: 0.987, accuracy: 0.807\n",
      "epoch 52 iter 0, loss: 1.023, accuracy: 0.802\n",
      "epoch 52 iter 70, loss: 1.125, accuracy: 0.789\n",
      "epoch 52 iter 140, loss: 1.037, accuracy: 0.794\n",
      "epoch 52 iter 210, loss: 1.014, accuracy: 0.800\n",
      "epoch 52 iter 280, loss: 1.025, accuracy: 0.804\n",
      "epoch 53 iter 0, loss: 1.069, accuracy: 0.795\n",
      "epoch 53 iter 70, loss: 1.091, accuracy: 0.798\n",
      "epoch 53 iter 140, loss: 1.043, accuracy: 0.796\n",
      "epoch 53 iter 210, loss: 1.036, accuracy: 0.801\n",
      "epoch 53 iter 280, loss: 1.057, accuracy: 0.799\n",
      "epoch 54 iter 0, loss: 1.068, accuracy: 0.793\n",
      "epoch 54 iter 70, loss: 1.129, accuracy: 0.783\n",
      "epoch 54 iter 140, loss: 1.058, accuracy: 0.792\n",
      "epoch 54 iter 210, loss: 1.039, accuracy: 0.801\n",
      "epoch 54 iter 280, loss: 1.076, accuracy: 0.801\n",
      "epoch 55 iter 0, loss: 1.058, accuracy: 0.803\n",
      "epoch 55 iter 70, loss: 1.135, accuracy: 0.788\n",
      "epoch 55 iter 140, loss: 1.048, accuracy: 0.795\n",
      "epoch 55 iter 210, loss: 1.076, accuracy: 0.796\n",
      "epoch 55 iter 280, loss: 1.040, accuracy: 0.807\n",
      "epoch 56 iter 0, loss: 1.067, accuracy: 0.805\n",
      "epoch 56 iter 70, loss: 1.150, accuracy: 0.792\n",
      "epoch 56 iter 140, loss: 1.092, accuracy: 0.798\n",
      "epoch 56 iter 210, loss: 1.086, accuracy: 0.792\n",
      "epoch 56 iter 280, loss: 1.055, accuracy: 0.803\n",
      "epoch 57 iter 0, loss: 1.080, accuracy: 0.805\n",
      "epoch 57 iter 70, loss: 1.195, accuracy: 0.787\n",
      "epoch 57 iter 140, loss: 1.074, accuracy: 0.801\n",
      "epoch 57 iter 210, loss: 1.104, accuracy: 0.793\n",
      "epoch 57 iter 280, loss: 1.112, accuracy: 0.802\n",
      "epoch 58 iter 0, loss: 1.046, accuracy: 0.805\n",
      "epoch 58 iter 70, loss: 1.154, accuracy: 0.792\n",
      "epoch 58 iter 140, loss: 1.092, accuracy: 0.800\n",
      "epoch 58 iter 210, loss: 1.098, accuracy: 0.795\n",
      "epoch 58 iter 280, loss: 1.086, accuracy: 0.808\n",
      "epoch 59 iter 0, loss: 1.063, accuracy: 0.808\n",
      "epoch 59 iter 70, loss: 1.183, accuracy: 0.794\n",
      "epoch 59 iter 140, loss: 1.088, accuracy: 0.804\n",
      "epoch 59 iter 210, loss: 1.134, accuracy: 0.796\n",
      "epoch 59 iter 280, loss: 1.112, accuracy: 0.802\n",
      "epoch 60 iter 0, loss: 1.106, accuracy: 0.804\n",
      "epoch 60 iter 70, loss: 1.190, accuracy: 0.801\n",
      "epoch 60 iter 140, loss: 1.126, accuracy: 0.804\n",
      "epoch 60 iter 210, loss: 1.164, accuracy: 0.788\n",
      "epoch 60 iter 280, loss: 1.127, accuracy: 0.804\n",
      "epoch 61 iter 0, loss: 1.102, accuracy: 0.802\n",
      "epoch 61 iter 70, loss: 1.203, accuracy: 0.798\n",
      "epoch 61 iter 140, loss: 1.084, accuracy: 0.809\n",
      "epoch 61 iter 210, loss: 1.164, accuracy: 0.788\n",
      "epoch 61 iter 280, loss: 1.133, accuracy: 0.801\n",
      "epoch 62 iter 0, loss: 1.094, accuracy: 0.805\n",
      "epoch 62 iter 70, loss: 1.219, accuracy: 0.794\n",
      "epoch 62 iter 140, loss: 1.150, accuracy: 0.801\n",
      "epoch 62 iter 210, loss: 1.123, accuracy: 0.798\n",
      "epoch 62 iter 280, loss: 1.181, accuracy: 0.801\n",
      "epoch 63 iter 0, loss: 1.117, accuracy: 0.806\n",
      "epoch 63 iter 70, loss: 1.242, accuracy: 0.793\n",
      "epoch 63 iter 140, loss: 1.174, accuracy: 0.796\n",
      "epoch 63 iter 210, loss: 1.170, accuracy: 0.793\n",
      "epoch 63 iter 280, loss: 1.248, accuracy: 0.790\n",
      "epoch 64 iter 0, loss: 1.150, accuracy: 0.805\n",
      "epoch 64 iter 70, loss: 1.289, accuracy: 0.786\n",
      "epoch 64 iter 140, loss: 1.130, accuracy: 0.807\n",
      "epoch 64 iter 210, loss: 1.124, accuracy: 0.794\n",
      "epoch 64 iter 280, loss: 1.180, accuracy: 0.797\n",
      "epoch 65 iter 0, loss: 1.143, accuracy: 0.803\n",
      "epoch 65 iter 70, loss: 1.398, accuracy: 0.768\n",
      "epoch 65 iter 140, loss: 1.156, accuracy: 0.801\n",
      "epoch 65 iter 210, loss: 1.142, accuracy: 0.795\n",
      "epoch 65 iter 280, loss: 1.234, accuracy: 0.789\n",
      "epoch 66 iter 0, loss: 1.181, accuracy: 0.802\n",
      "epoch 66 iter 70, loss: 1.294, accuracy: 0.783\n",
      "epoch 66 iter 140, loss: 1.145, accuracy: 0.804\n",
      "epoch 66 iter 210, loss: 1.150, accuracy: 0.802\n",
      "epoch 66 iter 280, loss: 1.252, accuracy: 0.795\n",
      "epoch 67 iter 0, loss: 1.147, accuracy: 0.802\n",
      "epoch 67 iter 70, loss: 1.303, accuracy: 0.783\n",
      "epoch 67 iter 140, loss: 1.176, accuracy: 0.800\n",
      "epoch 67 iter 210, loss: 1.178, accuracy: 0.802\n",
      "epoch 67 iter 280, loss: 1.211, accuracy: 0.798\n",
      "epoch 68 iter 0, loss: 1.150, accuracy: 0.802\n",
      "epoch 68 iter 70, loss: 1.328, accuracy: 0.781\n",
      "epoch 68 iter 140, loss: 1.202, accuracy: 0.800\n",
      "epoch 68 iter 210, loss: 1.146, accuracy: 0.802\n",
      "epoch 68 iter 280, loss: 1.201, accuracy: 0.795\n",
      "epoch 69 iter 0, loss: 1.144, accuracy: 0.804\n",
      "epoch 69 iter 70, loss: 1.353, accuracy: 0.780\n",
      "epoch 69 iter 140, loss: 1.200, accuracy: 0.800\n",
      "epoch 69 iter 210, loss: 1.244, accuracy: 0.795\n",
      "epoch 69 iter 280, loss: 1.276, accuracy: 0.793\n",
      "epoch 70 iter 0, loss: 1.195, accuracy: 0.802\n",
      "epoch 70 iter 70, loss: 1.406, accuracy: 0.781\n",
      "epoch 70 iter 140, loss: 1.252, accuracy: 0.801\n",
      "epoch 70 iter 210, loss: 1.246, accuracy: 0.788\n",
      "epoch 70 iter 280, loss: 1.303, accuracy: 0.790\n",
      "epoch 71 iter 0, loss: 1.266, accuracy: 0.789\n",
      "epoch 71 iter 70, loss: 1.408, accuracy: 0.784\n",
      "epoch 71 iter 140, loss: 1.282, accuracy: 0.792\n",
      "epoch 71 iter 210, loss: 1.208, accuracy: 0.801\n",
      "epoch 71 iter 280, loss: 1.282, accuracy: 0.792\n",
      "epoch 72 iter 0, loss: 1.218, accuracy: 0.803\n",
      "epoch 72 iter 70, loss: 1.408, accuracy: 0.781\n",
      "epoch 72 iter 140, loss: 1.268, accuracy: 0.799\n",
      "epoch 72 iter 210, loss: 1.293, accuracy: 0.787\n",
      "epoch 72 iter 280, loss: 1.289, accuracy: 0.796\n",
      "epoch 73 iter 0, loss: 1.220, accuracy: 0.803\n",
      "epoch 73 iter 70, loss: 1.390, accuracy: 0.789\n",
      "epoch 73 iter 140, loss: 1.253, accuracy: 0.798\n",
      "epoch 73 iter 210, loss: 1.255, accuracy: 0.793\n",
      "epoch 73 iter 280, loss: 1.257, accuracy: 0.795\n",
      "epoch 74 iter 0, loss: 1.222, accuracy: 0.805\n",
      "epoch 74 iter 70, loss: 1.422, accuracy: 0.788\n",
      "epoch 74 iter 140, loss: 1.341, accuracy: 0.794\n",
      "epoch 74 iter 210, loss: 1.262, accuracy: 0.789\n",
      "epoch 74 iter 280, loss: 1.289, accuracy: 0.790\n",
      "epoch 75 iter 0, loss: 1.222, accuracy: 0.802\n",
      "epoch 75 iter 70, loss: 1.451, accuracy: 0.787\n",
      "epoch 75 iter 140, loss: 1.343, accuracy: 0.792\n",
      "epoch 75 iter 210, loss: 1.287, accuracy: 0.790\n",
      "epoch 75 iter 280, loss: 1.324, accuracy: 0.795\n",
      "epoch 76 iter 0, loss: 1.292, accuracy: 0.793\n",
      "epoch 76 iter 70, loss: 1.450, accuracy: 0.781\n",
      "epoch 76 iter 140, loss: 1.332, accuracy: 0.793\n",
      "epoch 76 iter 210, loss: 1.236, accuracy: 0.794\n",
      "epoch 76 iter 280, loss: 1.308, accuracy: 0.794\n",
      "epoch 77 iter 0, loss: 1.231, accuracy: 0.802\n",
      "epoch 77 iter 70, loss: 1.486, accuracy: 0.776\n",
      "epoch 77 iter 140, loss: 1.437, accuracy: 0.783\n",
      "epoch 77 iter 210, loss: 1.234, accuracy: 0.797\n",
      "epoch 77 iter 280, loss: 1.300, accuracy: 0.794\n",
      "epoch 78 iter 0, loss: 1.216, accuracy: 0.804\n",
      "epoch 78 iter 70, loss: 1.356, accuracy: 0.789\n",
      "epoch 78 iter 140, loss: 1.397, accuracy: 0.785\n",
      "epoch 78 iter 210, loss: 1.251, accuracy: 0.799\n",
      "epoch 78 iter 280, loss: 1.316, accuracy: 0.791\n",
      "epoch 79 iter 0, loss: 1.258, accuracy: 0.795\n",
      "epoch 79 iter 70, loss: 1.340, accuracy: 0.795\n",
      "epoch 79 iter 140, loss: 1.382, accuracy: 0.781\n",
      "epoch 79 iter 210, loss: 1.238, accuracy: 0.799\n",
      "epoch 79 iter 280, loss: 1.280, accuracy: 0.798\n",
      "epoch 80 iter 0, loss: 1.314, accuracy: 0.793\n",
      "epoch 80 iter 70, loss: 1.337, accuracy: 0.798\n",
      "epoch 80 iter 140, loss: 1.359, accuracy: 0.787\n",
      "epoch 80 iter 210, loss: 1.233, accuracy: 0.798\n",
      "epoch 80 iter 280, loss: 1.316, accuracy: 0.798\n",
      "epoch 81 iter 0, loss: 1.345, accuracy: 0.786\n",
      "epoch 81 iter 70, loss: 1.378, accuracy: 0.793\n",
      "epoch 81 iter 140, loss: 1.435, accuracy: 0.778\n",
      "epoch 81 iter 210, loss: 1.242, accuracy: 0.798\n",
      "epoch 81 iter 280, loss: 1.368, accuracy: 0.792\n",
      "epoch 82 iter 0, loss: 1.336, accuracy: 0.793\n",
      "epoch 82 iter 70, loss: 1.408, accuracy: 0.790\n",
      "epoch 82 iter 140, loss: 1.405, accuracy: 0.792\n",
      "epoch 82 iter 210, loss: 1.263, accuracy: 0.802\n",
      "epoch 82 iter 280, loss: 1.361, accuracy: 0.796\n",
      "epoch 83 iter 0, loss: 1.318, accuracy: 0.800\n",
      "epoch 83 iter 70, loss: 1.457, accuracy: 0.787\n",
      "epoch 83 iter 140, loss: 1.415, accuracy: 0.794\n",
      "epoch 83 iter 210, loss: 1.290, accuracy: 0.800\n",
      "epoch 83 iter 280, loss: 1.377, accuracy: 0.794\n",
      "epoch 84 iter 0, loss: 1.308, accuracy: 0.804\n",
      "epoch 84 iter 70, loss: 1.487, accuracy: 0.787\n",
      "epoch 84 iter 140, loss: 1.431, accuracy: 0.789\n",
      "epoch 84 iter 210, loss: 1.355, accuracy: 0.798\n",
      "epoch 84 iter 280, loss: 1.408, accuracy: 0.793\n",
      "epoch 85 iter 0, loss: 1.408, accuracy: 0.787\n",
      "epoch 85 iter 70, loss: 1.448, accuracy: 0.792\n",
      "epoch 85 iter 140, loss: 1.489, accuracy: 0.786\n",
      "epoch 85 iter 210, loss: 1.420, accuracy: 0.796\n",
      "epoch 85 iter 280, loss: 1.454, accuracy: 0.793\n",
      "epoch 86 iter 0, loss: 1.387, accuracy: 0.794\n",
      "epoch 86 iter 70, loss: 1.478, accuracy: 0.787\n",
      "epoch 86 iter 140, loss: 1.461, accuracy: 0.792\n",
      "epoch 86 iter 210, loss: 1.331, accuracy: 0.799\n",
      "epoch 86 iter 280, loss: 1.499, accuracy: 0.791\n",
      "epoch 87 iter 0, loss: 1.411, accuracy: 0.794\n",
      "epoch 87 iter 70, loss: 1.499, accuracy: 0.793\n",
      "epoch 87 iter 140, loss: 1.471, accuracy: 0.790\n",
      "epoch 87 iter 210, loss: 1.318, accuracy: 0.798\n",
      "epoch 87 iter 280, loss: 1.477, accuracy: 0.788\n",
      "epoch 88 iter 0, loss: 1.489, accuracy: 0.786\n",
      "epoch 88 iter 70, loss: 1.552, accuracy: 0.782\n",
      "epoch 88 iter 140, loss: 1.478, accuracy: 0.790\n",
      "epoch 88 iter 210, loss: 1.379, accuracy: 0.799\n",
      "epoch 88 iter 280, loss: 1.463, accuracy: 0.789\n",
      "epoch 89 iter 0, loss: 1.447, accuracy: 0.798\n",
      "epoch 89 iter 70, loss: 1.487, accuracy: 0.792\n",
      "epoch 89 iter 140, loss: 1.558, accuracy: 0.780\n",
      "epoch 89 iter 210, loss: 1.467, accuracy: 0.781\n",
      "epoch 89 iter 280, loss: 1.431, accuracy: 0.790\n",
      "epoch 90 iter 0, loss: 1.476, accuracy: 0.791\n",
      "epoch 90 iter 70, loss: 1.514, accuracy: 0.790\n",
      "epoch 90 iter 140, loss: 1.524, accuracy: 0.785\n",
      "epoch 90 iter 210, loss: 1.438, accuracy: 0.784\n",
      "epoch 90 iter 280, loss: 1.479, accuracy: 0.785\n",
      "epoch 91 iter 0, loss: 1.590, accuracy: 0.765\n",
      "epoch 91 iter 70, loss: 1.499, accuracy: 0.794\n",
      "epoch 91 iter 140, loss: 1.590, accuracy: 0.787\n",
      "epoch 91 iter 210, loss: 1.418, accuracy: 0.791\n",
      "epoch 91 iter 280, loss: 1.583, accuracy: 0.774\n",
      "epoch 92 iter 0, loss: 1.482, accuracy: 0.783\n",
      "epoch 92 iter 70, loss: 1.490, accuracy: 0.794\n",
      "epoch 92 iter 140, loss: 1.629, accuracy: 0.790\n",
      "epoch 92 iter 210, loss: 1.407, accuracy: 0.794\n",
      "epoch 92 iter 280, loss: 1.542, accuracy: 0.783\n",
      "epoch 93 iter 0, loss: 1.563, accuracy: 0.769\n",
      "epoch 93 iter 70, loss: 1.470, accuracy: 0.792\n",
      "epoch 93 iter 140, loss: 1.549, accuracy: 0.794\n",
      "epoch 93 iter 210, loss: 1.430, accuracy: 0.797\n",
      "epoch 93 iter 280, loss: 1.531, accuracy: 0.786\n",
      "epoch 94 iter 0, loss: 1.482, accuracy: 0.778\n",
      "epoch 94 iter 70, loss: 1.488, accuracy: 0.793\n",
      "epoch 94 iter 140, loss: 1.549, accuracy: 0.788\n",
      "epoch 94 iter 210, loss: 1.423, accuracy: 0.793\n",
      "epoch 94 iter 280, loss: 1.573, accuracy: 0.778\n",
      "epoch 95 iter 0, loss: 1.578, accuracy: 0.768\n",
      "epoch 95 iter 70, loss: 1.474, accuracy: 0.796\n",
      "epoch 95 iter 140, loss: 1.513, accuracy: 0.788\n",
      "epoch 95 iter 210, loss: 1.413, accuracy: 0.790\n",
      "epoch 95 iter 280, loss: 1.418, accuracy: 0.797\n",
      "epoch 96 iter 0, loss: 1.499, accuracy: 0.779\n",
      "epoch 96 iter 70, loss: 1.485, accuracy: 0.796\n",
      "epoch 96 iter 140, loss: 1.445, accuracy: 0.798\n",
      "epoch 96 iter 210, loss: 1.423, accuracy: 0.786\n",
      "epoch 96 iter 280, loss: 1.442, accuracy: 0.800\n",
      "epoch 97 iter 0, loss: 1.462, accuracy: 0.786\n",
      "epoch 97 iter 70, loss: 1.477, accuracy: 0.797\n",
      "epoch 97 iter 140, loss: 1.460, accuracy: 0.795\n",
      "epoch 97 iter 210, loss: 1.489, accuracy: 0.784\n",
      "epoch 97 iter 280, loss: 1.492, accuracy: 0.795\n",
      "epoch 98 iter 0, loss: 1.530, accuracy: 0.786\n",
      "epoch 98 iter 70, loss: 1.496, accuracy: 0.792\n",
      "epoch 98 iter 140, loss: 1.561, accuracy: 0.791\n",
      "epoch 98 iter 210, loss: 1.471, accuracy: 0.792\n",
      "epoch 98 iter 280, loss: 1.484, accuracy: 0.795\n",
      "epoch 99 iter 0, loss: 1.512, accuracy: 0.791\n",
      "epoch 99 iter 70, loss: 1.522, accuracy: 0.793\n",
      "epoch 99 iter 140, loss: 1.527, accuracy: 0.791\n",
      "epoch 99 iter 210, loss: 1.479, accuracy: 0.793\n",
      "epoch 99 iter 280, loss: 1.528, accuracy: 0.792\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=3,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=3,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 63.278, accuracy: 0.094\n",
      "epoch 0 iter 70, loss: 2.236, accuracy: 0.188\n",
      "epoch 0 iter 140, loss: 2.148, accuracy: 0.251\n",
      "epoch 0 iter 210, loss: 2.089, accuracy: 0.270\n",
      "epoch 0 iter 280, loss: 2.055, accuracy: 0.270\n",
      "epoch 1 iter 0, loss: 2.041, accuracy: 0.273\n",
      "epoch 1 iter 70, loss: 2.006, accuracy: 0.293\n",
      "epoch 1 iter 140, loss: 1.682, accuracy: 0.444\n",
      "epoch 1 iter 210, loss: 1.329, accuracy: 0.584\n",
      "epoch 1 iter 280, loss: 1.145, accuracy: 0.650\n",
      "epoch 2 iter 0, loss: 1.119, accuracy: 0.660\n",
      "epoch 2 iter 70, loss: 1.138, accuracy: 0.656\n",
      "epoch 2 iter 140, loss: 1.068, accuracy: 0.680\n",
      "epoch 2 iter 210, loss: 0.990, accuracy: 0.702\n",
      "epoch 2 iter 280, loss: 0.864, accuracy: 0.745\n",
      "epoch 3 iter 0, loss: 0.925, accuracy: 0.727\n",
      "epoch 3 iter 70, loss: 0.856, accuracy: 0.750\n",
      "epoch 3 iter 140, loss: 0.804, accuracy: 0.766\n",
      "epoch 3 iter 210, loss: 0.839, accuracy: 0.753\n",
      "epoch 3 iter 280, loss: 0.758, accuracy: 0.782\n",
      "epoch 4 iter 0, loss: 0.794, accuracy: 0.767\n",
      "epoch 4 iter 70, loss: 0.763, accuracy: 0.780\n",
      "epoch 4 iter 140, loss: 0.733, accuracy: 0.791\n",
      "epoch 4 iter 210, loss: 0.805, accuracy: 0.762\n",
      "epoch 4 iter 280, loss: 0.720, accuracy: 0.791\n",
      "epoch 5 iter 0, loss: 0.757, accuracy: 0.778\n",
      "epoch 5 iter 70, loss: 0.715, accuracy: 0.794\n",
      "epoch 5 iter 140, loss: 0.688, accuracy: 0.801\n",
      "epoch 5 iter 210, loss: 0.658, accuracy: 0.816\n",
      "epoch 5 iter 280, loss: 0.666, accuracy: 0.810\n",
      "epoch 6 iter 0, loss: 0.648, accuracy: 0.817\n",
      "epoch 6 iter 70, loss: 0.652, accuracy: 0.819\n",
      "epoch 6 iter 140, loss: 0.642, accuracy: 0.819\n",
      "epoch 6 iter 210, loss: 0.628, accuracy: 0.823\n",
      "epoch 6 iter 280, loss: 0.630, accuracy: 0.828\n",
      "epoch 7 iter 0, loss: 0.615, accuracy: 0.830\n",
      "epoch 7 iter 70, loss: 0.642, accuracy: 0.830\n",
      "epoch 7 iter 140, loss: 0.634, accuracy: 0.824\n",
      "epoch 7 iter 210, loss: 0.626, accuracy: 0.834\n",
      "epoch 7 iter 280, loss: 0.634, accuracy: 0.825\n",
      "epoch 8 iter 0, loss: 0.609, accuracy: 0.832\n",
      "epoch 8 iter 70, loss: 0.671, accuracy: 0.817\n",
      "epoch 8 iter 140, loss: 0.639, accuracy: 0.830\n",
      "epoch 8 iter 210, loss: 0.638, accuracy: 0.829\n",
      "epoch 8 iter 280, loss: 0.624, accuracy: 0.832\n",
      "epoch 9 iter 0, loss: 0.595, accuracy: 0.841\n",
      "epoch 9 iter 70, loss: 0.602, accuracy: 0.837\n",
      "epoch 9 iter 140, loss: 0.634, accuracy: 0.836\n",
      "epoch 9 iter 210, loss: 0.611, accuracy: 0.842\n",
      "epoch 9 iter 280, loss: 0.613, accuracy: 0.837\n",
      "epoch 10 iter 0, loss: 0.598, accuracy: 0.840\n",
      "epoch 10 iter 70, loss: 0.628, accuracy: 0.837\n",
      "epoch 10 iter 140, loss: 0.633, accuracy: 0.839\n",
      "epoch 10 iter 210, loss: 0.652, accuracy: 0.829\n",
      "epoch 10 iter 280, loss: 0.592, accuracy: 0.847\n",
      "epoch 11 iter 0, loss: 0.605, accuracy: 0.846\n",
      "epoch 11 iter 70, loss: 0.655, accuracy: 0.833\n",
      "epoch 11 iter 140, loss: 0.643, accuracy: 0.840\n",
      "epoch 11 iter 210, loss: 0.685, accuracy: 0.822\n",
      "epoch 11 iter 280, loss: 0.599, accuracy: 0.850\n",
      "epoch 12 iter 0, loss: 0.602, accuracy: 0.850\n",
      "epoch 12 iter 70, loss: 0.669, accuracy: 0.824\n",
      "epoch 12 iter 140, loss: 0.606, accuracy: 0.849\n",
      "epoch 12 iter 210, loss: 0.640, accuracy: 0.845\n",
      "epoch 12 iter 280, loss: 0.613, accuracy: 0.850\n",
      "epoch 13 iter 0, loss: 0.637, accuracy: 0.850\n",
      "epoch 13 iter 70, loss: 0.693, accuracy: 0.830\n",
      "epoch 13 iter 140, loss: 0.625, accuracy: 0.850\n",
      "epoch 13 iter 210, loss: 0.659, accuracy: 0.843\n",
      "epoch 13 iter 280, loss: 0.647, accuracy: 0.849\n",
      "epoch 14 iter 0, loss: 0.627, accuracy: 0.854\n",
      "epoch 14 iter 70, loss: 0.701, accuracy: 0.828\n",
      "epoch 14 iter 140, loss: 0.651, accuracy: 0.849\n",
      "epoch 14 iter 210, loss: 0.692, accuracy: 0.837\n",
      "epoch 14 iter 280, loss: 0.634, accuracy: 0.853\n",
      "epoch 15 iter 0, loss: 0.655, accuracy: 0.848\n",
      "epoch 15 iter 70, loss: 0.676, accuracy: 0.843\n",
      "epoch 15 iter 140, loss: 0.644, accuracy: 0.850\n",
      "epoch 15 iter 210, loss: 0.710, accuracy: 0.842\n",
      "epoch 15 iter 280, loss: 0.629, accuracy: 0.855\n",
      "epoch 16 iter 0, loss: 0.649, accuracy: 0.849\n",
      "epoch 16 iter 70, loss: 0.671, accuracy: 0.848\n",
      "epoch 16 iter 140, loss: 0.674, accuracy: 0.851\n",
      "epoch 16 iter 210, loss: 0.729, accuracy: 0.845\n",
      "epoch 16 iter 280, loss: 0.708, accuracy: 0.848\n",
      "epoch 17 iter 0, loss: 0.693, accuracy: 0.852\n",
      "epoch 17 iter 70, loss: 0.790, accuracy: 0.823\n",
      "epoch 17 iter 140, loss: 0.711, accuracy: 0.848\n",
      "epoch 17 iter 210, loss: 0.723, accuracy: 0.847\n",
      "epoch 17 iter 280, loss: 0.703, accuracy: 0.854\n",
      "epoch 18 iter 0, loss: 0.719, accuracy: 0.848\n",
      "epoch 18 iter 70, loss: 0.738, accuracy: 0.847\n",
      "epoch 18 iter 140, loss: 0.742, accuracy: 0.851\n",
      "epoch 18 iter 210, loss: 0.804, accuracy: 0.831\n",
      "epoch 18 iter 280, loss: 0.687, accuracy: 0.863\n",
      "epoch 19 iter 0, loss: 0.723, accuracy: 0.851\n",
      "epoch 19 iter 70, loss: 0.737, accuracy: 0.847\n",
      "epoch 19 iter 140, loss: 0.763, accuracy: 0.849\n",
      "epoch 19 iter 210, loss: 0.846, accuracy: 0.830\n",
      "epoch 19 iter 280, loss: 0.783, accuracy: 0.848\n",
      "epoch 20 iter 0, loss: 0.741, accuracy: 0.853\n",
      "epoch 20 iter 70, loss: 0.772, accuracy: 0.845\n",
      "epoch 20 iter 140, loss: 0.795, accuracy: 0.850\n",
      "epoch 20 iter 210, loss: 0.861, accuracy: 0.837\n",
      "epoch 20 iter 280, loss: 0.802, accuracy: 0.851\n",
      "epoch 21 iter 0, loss: 0.798, accuracy: 0.860\n",
      "epoch 21 iter 70, loss: 0.843, accuracy: 0.851\n",
      "epoch 21 iter 140, loss: 0.807, accuracy: 0.849\n",
      "epoch 21 iter 210, loss: 0.880, accuracy: 0.850\n",
      "epoch 21 iter 280, loss: 0.846, accuracy: 0.851\n",
      "epoch 22 iter 0, loss: 0.826, accuracy: 0.852\n",
      "epoch 22 iter 70, loss: 0.872, accuracy: 0.845\n",
      "epoch 22 iter 140, loss: 0.835, accuracy: 0.853\n",
      "epoch 22 iter 210, loss: 0.836, accuracy: 0.854\n",
      "epoch 22 iter 280, loss: 0.826, accuracy: 0.851\n",
      "epoch 23 iter 0, loss: 0.836, accuracy: 0.854\n",
      "epoch 23 iter 70, loss: 0.965, accuracy: 0.834\n",
      "epoch 23 iter 140, loss: 0.880, accuracy: 0.853\n",
      "epoch 23 iter 210, loss: 0.881, accuracy: 0.854\n",
      "epoch 23 iter 280, loss: 0.859, accuracy: 0.848\n",
      "epoch 24 iter 0, loss: 0.944, accuracy: 0.846\n",
      "epoch 24 iter 70, loss: 0.914, accuracy: 0.847\n",
      "epoch 24 iter 140, loss: 0.936, accuracy: 0.846\n",
      "epoch 24 iter 210, loss: 0.950, accuracy: 0.842\n",
      "epoch 24 iter 280, loss: 0.849, accuracy: 0.857\n",
      "epoch 25 iter 0, loss: 0.868, accuracy: 0.860\n",
      "epoch 25 iter 70, loss: 0.969, accuracy: 0.843\n",
      "epoch 25 iter 140, loss: 0.929, accuracy: 0.854\n",
      "epoch 25 iter 210, loss: 0.940, accuracy: 0.847\n",
      "epoch 25 iter 280, loss: 0.897, accuracy: 0.859\n",
      "epoch 26 iter 0, loss: 0.904, accuracy: 0.860\n",
      "epoch 26 iter 70, loss: 0.988, accuracy: 0.845\n",
      "epoch 26 iter 140, loss: 0.975, accuracy: 0.848\n",
      "epoch 26 iter 210, loss: 0.955, accuracy: 0.851\n",
      "epoch 26 iter 280, loss: 0.924, accuracy: 0.859\n",
      "epoch 27 iter 0, loss: 0.902, accuracy: 0.862\n",
      "epoch 27 iter 70, loss: 1.012, accuracy: 0.853\n",
      "epoch 27 iter 140, loss: 0.974, accuracy: 0.854\n",
      "epoch 27 iter 210, loss: 1.029, accuracy: 0.846\n",
      "epoch 27 iter 280, loss: 0.919, accuracy: 0.860\n",
      "epoch 28 iter 0, loss: 0.916, accuracy: 0.862\n",
      "epoch 28 iter 70, loss: 1.090, accuracy: 0.846\n",
      "epoch 28 iter 140, loss: 1.027, accuracy: 0.852\n",
      "epoch 28 iter 210, loss: 1.045, accuracy: 0.857\n",
      "epoch 28 iter 280, loss: 1.072, accuracy: 0.852\n",
      "epoch 29 iter 0, loss: 1.015, accuracy: 0.859\n",
      "epoch 29 iter 70, loss: 1.094, accuracy: 0.852\n",
      "epoch 29 iter 140, loss: 1.063, accuracy: 0.854\n",
      "epoch 29 iter 210, loss: 1.104, accuracy: 0.851\n",
      "epoch 29 iter 280, loss: 1.081, accuracy: 0.852\n",
      "epoch 30 iter 0, loss: 1.067, accuracy: 0.853\n",
      "epoch 30 iter 70, loss: 1.093, accuracy: 0.855\n",
      "epoch 30 iter 140, loss: 1.129, accuracy: 0.852\n",
      "epoch 30 iter 210, loss: 1.079, accuracy: 0.862\n",
      "epoch 30 iter 280, loss: 1.122, accuracy: 0.849\n",
      "epoch 31 iter 0, loss: 1.100, accuracy: 0.849\n",
      "epoch 31 iter 70, loss: 1.158, accuracy: 0.853\n",
      "epoch 31 iter 140, loss: 1.205, accuracy: 0.843\n",
      "epoch 31 iter 210, loss: 1.199, accuracy: 0.848\n",
      "epoch 31 iter 280, loss: 1.258, accuracy: 0.840\n",
      "epoch 32 iter 0, loss: 1.102, accuracy: 0.848\n",
      "epoch 32 iter 70, loss: 1.212, accuracy: 0.848\n",
      "epoch 32 iter 140, loss: 1.293, accuracy: 0.840\n",
      "epoch 32 iter 210, loss: 1.259, accuracy: 0.843\n",
      "epoch 32 iter 280, loss: 1.219, accuracy: 0.842\n",
      "epoch 33 iter 0, loss: 1.177, accuracy: 0.854\n",
      "epoch 33 iter 70, loss: 1.231, accuracy: 0.852\n",
      "epoch 33 iter 140, loss: 1.206, accuracy: 0.852\n",
      "epoch 33 iter 210, loss: 1.269, accuracy: 0.850\n",
      "epoch 33 iter 280, loss: 1.295, accuracy: 0.848\n",
      "epoch 34 iter 0, loss: 1.231, accuracy: 0.854\n",
      "epoch 34 iter 70, loss: 1.278, accuracy: 0.853\n",
      "epoch 34 iter 140, loss: 1.248, accuracy: 0.850\n",
      "epoch 34 iter 210, loss: 1.265, accuracy: 0.858\n",
      "epoch 34 iter 280, loss: 1.331, accuracy: 0.844\n",
      "epoch 35 iter 0, loss: 1.238, accuracy: 0.860\n",
      "epoch 35 iter 70, loss: 1.304, accuracy: 0.855\n",
      "epoch 35 iter 140, loss: 1.261, accuracy: 0.847\n",
      "epoch 35 iter 210, loss: 1.310, accuracy: 0.860\n",
      "epoch 35 iter 280, loss: 1.383, accuracy: 0.835\n",
      "epoch 36 iter 0, loss: 1.246, accuracy: 0.851\n",
      "epoch 36 iter 70, loss: 1.383, accuracy: 0.846\n",
      "epoch 36 iter 140, loss: 1.388, accuracy: 0.847\n",
      "epoch 36 iter 210, loss: 1.422, accuracy: 0.849\n",
      "epoch 36 iter 280, loss: 1.356, accuracy: 0.848\n",
      "epoch 37 iter 0, loss: 1.323, accuracy: 0.848\n",
      "epoch 37 iter 70, loss: 1.394, accuracy: 0.853\n",
      "epoch 37 iter 140, loss: 1.377, accuracy: 0.852\n",
      "epoch 37 iter 210, loss: 1.558, accuracy: 0.844\n",
      "epoch 37 iter 280, loss: 1.354, accuracy: 0.851\n",
      "epoch 38 iter 0, loss: 1.360, accuracy: 0.852\n",
      "epoch 38 iter 70, loss: 1.323, accuracy: 0.854\n",
      "epoch 38 iter 140, loss: 1.445, accuracy: 0.833\n",
      "epoch 38 iter 210, loss: 1.429, accuracy: 0.853\n",
      "epoch 38 iter 280, loss: 1.447, accuracy: 0.850\n",
      "epoch 39 iter 0, loss: 1.393, accuracy: 0.846\n",
      "epoch 39 iter 70, loss: 1.376, accuracy: 0.851\n",
      "epoch 39 iter 140, loss: 1.462, accuracy: 0.847\n",
      "epoch 39 iter 210, loss: 1.479, accuracy: 0.848\n",
      "epoch 39 iter 280, loss: 1.534, accuracy: 0.846\n",
      "epoch 40 iter 0, loss: 1.441, accuracy: 0.844\n",
      "epoch 40 iter 70, loss: 1.394, accuracy: 0.855\n",
      "epoch 40 iter 140, loss: 1.412, accuracy: 0.847\n",
      "epoch 40 iter 210, loss: 1.496, accuracy: 0.852\n",
      "epoch 40 iter 280, loss: 1.524, accuracy: 0.847\n",
      "epoch 41 iter 0, loss: 1.457, accuracy: 0.837\n",
      "epoch 41 iter 70, loss: 1.397, accuracy: 0.853\n",
      "epoch 41 iter 140, loss: 1.590, accuracy: 0.823\n",
      "epoch 41 iter 210, loss: 1.472, accuracy: 0.853\n",
      "epoch 41 iter 280, loss: 1.518, accuracy: 0.851\n",
      "epoch 42 iter 0, loss: 1.554, accuracy: 0.844\n",
      "epoch 42 iter 70, loss: 1.473, accuracy: 0.850\n",
      "epoch 42 iter 140, loss: 1.565, accuracy: 0.836\n",
      "epoch 42 iter 210, loss: 1.496, accuracy: 0.857\n",
      "epoch 42 iter 280, loss: 1.516, accuracy: 0.850\n",
      "epoch 43 iter 0, loss: 1.547, accuracy: 0.845\n",
      "epoch 43 iter 70, loss: 1.491, accuracy: 0.854\n",
      "epoch 43 iter 140, loss: 1.502, accuracy: 0.844\n",
      "epoch 43 iter 210, loss: 1.448, accuracy: 0.859\n",
      "epoch 43 iter 280, loss: 1.543, accuracy: 0.851\n",
      "epoch 44 iter 0, loss: 1.629, accuracy: 0.841\n",
      "epoch 44 iter 70, loss: 1.509, accuracy: 0.857\n",
      "epoch 44 iter 140, loss: 1.466, accuracy: 0.849\n",
      "epoch 44 iter 210, loss: 1.515, accuracy: 0.859\n",
      "epoch 44 iter 280, loss: 1.592, accuracy: 0.852\n",
      "epoch 45 iter 0, loss: 1.593, accuracy: 0.857\n",
      "epoch 45 iter 70, loss: 1.571, accuracy: 0.852\n",
      "epoch 45 iter 140, loss: 1.589, accuracy: 0.848\n",
      "epoch 45 iter 210, loss: 1.563, accuracy: 0.860\n",
      "epoch 45 iter 280, loss: 1.626, accuracy: 0.853\n",
      "epoch 46 iter 0, loss: 1.646, accuracy: 0.851\n",
      "epoch 46 iter 70, loss: 1.605, accuracy: 0.860\n",
      "epoch 46 iter 140, loss: 1.622, accuracy: 0.851\n",
      "epoch 46 iter 210, loss: 1.688, accuracy: 0.859\n",
      "epoch 46 iter 280, loss: 1.697, accuracy: 0.852\n",
      "epoch 47 iter 0, loss: 1.706, accuracy: 0.848\n",
      "epoch 47 iter 70, loss: 1.689, accuracy: 0.851\n",
      "epoch 47 iter 140, loss: 1.701, accuracy: 0.855\n",
      "epoch 47 iter 210, loss: 1.694, accuracy: 0.855\n",
      "epoch 47 iter 280, loss: 1.793, accuracy: 0.850\n",
      "epoch 48 iter 0, loss: 1.804, accuracy: 0.848\n",
      "epoch 48 iter 70, loss: 1.702, accuracy: 0.847\n",
      "epoch 48 iter 140, loss: 1.715, accuracy: 0.850\n",
      "epoch 48 iter 210, loss: 1.792, accuracy: 0.857\n",
      "epoch 48 iter 280, loss: 1.741, accuracy: 0.854\n",
      "epoch 49 iter 0, loss: 1.801, accuracy: 0.848\n",
      "epoch 49 iter 70, loss: 1.747, accuracy: 0.848\n",
      "epoch 49 iter 140, loss: 1.700, accuracy: 0.859\n",
      "epoch 49 iter 210, loss: 1.873, accuracy: 0.853\n",
      "epoch 49 iter 280, loss: 1.852, accuracy: 0.854\n",
      "epoch 50 iter 0, loss: 1.879, accuracy: 0.852\n",
      "epoch 50 iter 70, loss: 1.797, accuracy: 0.849\n",
      "epoch 50 iter 140, loss: 1.882, accuracy: 0.859\n",
      "epoch 50 iter 210, loss: 2.073, accuracy: 0.841\n",
      "epoch 50 iter 280, loss: 1.980, accuracy: 0.849\n",
      "epoch 51 iter 0, loss: 1.915, accuracy: 0.853\n",
      "epoch 51 iter 70, loss: 1.908, accuracy: 0.839\n",
      "epoch 51 iter 140, loss: 1.895, accuracy: 0.854\n",
      "epoch 51 iter 210, loss: 1.964, accuracy: 0.850\n",
      "epoch 51 iter 280, loss: 1.874, accuracy: 0.852\n",
      "epoch 52 iter 0, loss: 1.843, accuracy: 0.857\n",
      "epoch 52 iter 70, loss: 1.914, accuracy: 0.851\n",
      "epoch 52 iter 140, loss: 1.841, accuracy: 0.856\n",
      "epoch 52 iter 210, loss: 1.922, accuracy: 0.847\n",
      "epoch 52 iter 280, loss: 1.922, accuracy: 0.855\n",
      "epoch 53 iter 0, loss: 1.884, accuracy: 0.858\n",
      "epoch 53 iter 70, loss: 1.859, accuracy: 0.854\n",
      "epoch 53 iter 140, loss: 1.842, accuracy: 0.859\n",
      "epoch 53 iter 210, loss: 1.973, accuracy: 0.852\n",
      "epoch 53 iter 280, loss: 2.044, accuracy: 0.847\n",
      "epoch 54 iter 0, loss: 1.985, accuracy: 0.852\n",
      "epoch 54 iter 70, loss: 2.026, accuracy: 0.849\n",
      "epoch 54 iter 140, loss: 2.028, accuracy: 0.860\n",
      "epoch 54 iter 210, loss: 1.935, accuracy: 0.862\n",
      "epoch 54 iter 280, loss: 2.007, accuracy: 0.855\n",
      "epoch 55 iter 0, loss: 1.966, accuracy: 0.859\n",
      "epoch 55 iter 70, loss: 2.054, accuracy: 0.852\n",
      "epoch 55 iter 140, loss: 2.064, accuracy: 0.851\n",
      "epoch 55 iter 210, loss: 2.013, accuracy: 0.860\n",
      "epoch 55 iter 280, loss: 2.062, accuracy: 0.859\n",
      "epoch 56 iter 0, loss: 2.093, accuracy: 0.859\n",
      "epoch 56 iter 70, loss: 2.117, accuracy: 0.850\n",
      "epoch 56 iter 140, loss: 1.985, accuracy: 0.858\n",
      "epoch 56 iter 210, loss: 2.114, accuracy: 0.851\n",
      "epoch 56 iter 280, loss: 2.091, accuracy: 0.853\n",
      "epoch 57 iter 0, loss: 2.163, accuracy: 0.852\n",
      "epoch 57 iter 70, loss: 2.036, accuracy: 0.857\n",
      "epoch 57 iter 140, loss: 2.089, accuracy: 0.861\n",
      "epoch 57 iter 210, loss: 2.134, accuracy: 0.853\n",
      "epoch 57 iter 280, loss: 2.192, accuracy: 0.858\n",
      "epoch 58 iter 0, loss: 2.184, accuracy: 0.860\n",
      "epoch 58 iter 70, loss: 2.212, accuracy: 0.857\n",
      "epoch 58 iter 140, loss: 2.067, accuracy: 0.857\n",
      "epoch 58 iter 210, loss: 2.149, accuracy: 0.852\n",
      "epoch 58 iter 280, loss: 2.222, accuracy: 0.855\n",
      "epoch 59 iter 0, loss: 2.324, accuracy: 0.854\n",
      "epoch 59 iter 70, loss: 2.142, accuracy: 0.854\n",
      "epoch 59 iter 140, loss: 2.297, accuracy: 0.848\n",
      "epoch 59 iter 210, loss: 2.169, accuracy: 0.857\n",
      "epoch 59 iter 280, loss: 2.287, accuracy: 0.853\n",
      "epoch 60 iter 0, loss: 2.312, accuracy: 0.852\n",
      "epoch 60 iter 70, loss: 2.193, accuracy: 0.855\n",
      "epoch 60 iter 140, loss: 2.193, accuracy: 0.858\n",
      "epoch 60 iter 210, loss: 2.267, accuracy: 0.849\n",
      "epoch 60 iter 280, loss: 2.365, accuracy: 0.847\n",
      "epoch 61 iter 0, loss: 2.304, accuracy: 0.856\n",
      "epoch 61 iter 70, loss: 2.329, accuracy: 0.847\n",
      "epoch 61 iter 140, loss: 2.189, accuracy: 0.854\n",
      "epoch 61 iter 210, loss: 2.198, accuracy: 0.857\n",
      "epoch 61 iter 280, loss: 2.186, accuracy: 0.859\n",
      "epoch 62 iter 0, loss: 2.268, accuracy: 0.854\n",
      "epoch 62 iter 70, loss: 2.289, accuracy: 0.855\n",
      "epoch 62 iter 140, loss: 2.260, accuracy: 0.858\n",
      "epoch 62 iter 210, loss: 2.371, accuracy: 0.853\n",
      "epoch 62 iter 280, loss: 2.432, accuracy: 0.846\n",
      "epoch 63 iter 0, loss: 2.419, accuracy: 0.852\n",
      "epoch 63 iter 70, loss: 2.414, accuracy: 0.854\n",
      "epoch 63 iter 140, loss: 2.300, accuracy: 0.856\n",
      "epoch 63 iter 210, loss: 2.390, accuracy: 0.861\n",
      "epoch 63 iter 280, loss: 2.408, accuracy: 0.849\n",
      "epoch 64 iter 0, loss: 2.489, accuracy: 0.849\n",
      "epoch 64 iter 70, loss: 2.604, accuracy: 0.849\n",
      "epoch 64 iter 140, loss: 2.289, accuracy: 0.854\n",
      "epoch 64 iter 210, loss: 2.347, accuracy: 0.856\n",
      "epoch 64 iter 280, loss: 2.386, accuracy: 0.859\n",
      "epoch 65 iter 0, loss: 2.459, accuracy: 0.856\n",
      "epoch 65 iter 70, loss: 2.384, accuracy: 0.861\n",
      "epoch 65 iter 140, loss: 2.453, accuracy: 0.852\n",
      "epoch 65 iter 210, loss: 2.483, accuracy: 0.851\n",
      "epoch 65 iter 280, loss: 2.462, accuracy: 0.859\n",
      "epoch 66 iter 0, loss: 2.635, accuracy: 0.844\n",
      "epoch 66 iter 70, loss: 2.539, accuracy: 0.852\n",
      "epoch 66 iter 140, loss: 2.434, accuracy: 0.849\n",
      "epoch 66 iter 210, loss: 2.537, accuracy: 0.851\n",
      "epoch 66 iter 280, loss: 2.470, accuracy: 0.854\n",
      "epoch 67 iter 0, loss: 2.551, accuracy: 0.851\n",
      "epoch 67 iter 70, loss: 2.634, accuracy: 0.851\n",
      "epoch 67 iter 140, loss: 2.409, accuracy: 0.857\n",
      "epoch 67 iter 210, loss: 2.656, accuracy: 0.849\n",
      "epoch 67 iter 280, loss: 2.603, accuracy: 0.852\n",
      "epoch 68 iter 0, loss: 2.608, accuracy: 0.850\n",
      "epoch 68 iter 70, loss: 2.562, accuracy: 0.851\n",
      "epoch 68 iter 140, loss: 2.533, accuracy: 0.852\n",
      "epoch 68 iter 210, loss: 2.633, accuracy: 0.841\n",
      "epoch 68 iter 280, loss: 2.469, accuracy: 0.854\n",
      "epoch 69 iter 0, loss: 2.605, accuracy: 0.855\n",
      "epoch 69 iter 70, loss: 2.673, accuracy: 0.856\n",
      "epoch 69 iter 140, loss: 2.620, accuracy: 0.848\n",
      "epoch 69 iter 210, loss: 2.497, accuracy: 0.853\n",
      "epoch 69 iter 280, loss: 2.527, accuracy: 0.853\n",
      "epoch 70 iter 0, loss: 2.671, accuracy: 0.856\n",
      "epoch 70 iter 70, loss: 2.589, accuracy: 0.864\n",
      "epoch 70 iter 140, loss: 2.646, accuracy: 0.846\n",
      "epoch 70 iter 210, loss: 2.859, accuracy: 0.844\n",
      "epoch 70 iter 280, loss: 2.662, accuracy: 0.851\n",
      "epoch 71 iter 0, loss: 2.793, accuracy: 0.851\n",
      "epoch 71 iter 70, loss: 2.696, accuracy: 0.856\n",
      "epoch 71 iter 140, loss: 2.692, accuracy: 0.853\n",
      "epoch 71 iter 210, loss: 2.795, accuracy: 0.847\n",
      "epoch 71 iter 280, loss: 2.607, accuracy: 0.855\n",
      "epoch 72 iter 0, loss: 2.710, accuracy: 0.859\n",
      "epoch 72 iter 70, loss: 2.749, accuracy: 0.856\n",
      "epoch 72 iter 140, loss: 2.723, accuracy: 0.849\n",
      "epoch 72 iter 210, loss: 2.773, accuracy: 0.853\n",
      "epoch 72 iter 280, loss: 2.641, accuracy: 0.854\n",
      "epoch 73 iter 0, loss: 2.707, accuracy: 0.858\n",
      "epoch 73 iter 70, loss: 2.840, accuracy: 0.849\n",
      "epoch 73 iter 140, loss: 2.640, accuracy: 0.852\n",
      "epoch 73 iter 210, loss: 2.763, accuracy: 0.849\n",
      "epoch 73 iter 280, loss: 2.530, accuracy: 0.854\n",
      "epoch 74 iter 0, loss: 2.619, accuracy: 0.853\n",
      "epoch 74 iter 70, loss: 2.678, accuracy: 0.852\n",
      "epoch 74 iter 140, loss: 2.750, accuracy: 0.848\n",
      "epoch 74 iter 210, loss: 2.785, accuracy: 0.854\n",
      "epoch 74 iter 280, loss: 2.684, accuracy: 0.855\n",
      "epoch 75 iter 0, loss: 2.820, accuracy: 0.856\n",
      "epoch 75 iter 70, loss: 2.963, accuracy: 0.850\n",
      "epoch 75 iter 140, loss: 2.802, accuracy: 0.856\n",
      "epoch 75 iter 210, loss: 2.764, accuracy: 0.855\n",
      "epoch 75 iter 280, loss: 2.705, accuracy: 0.855\n",
      "epoch 76 iter 0, loss: 2.773, accuracy: 0.860\n",
      "epoch 76 iter 70, loss: 2.894, accuracy: 0.855\n",
      "epoch 76 iter 140, loss: 2.885, accuracy: 0.847\n",
      "epoch 76 iter 210, loss: 2.850, accuracy: 0.858\n",
      "epoch 76 iter 280, loss: 2.859, accuracy: 0.852\n",
      "epoch 77 iter 0, loss: 2.829, accuracy: 0.855\n",
      "epoch 77 iter 70, loss: 2.889, accuracy: 0.852\n",
      "epoch 77 iter 140, loss: 3.017, accuracy: 0.849\n",
      "epoch 77 iter 210, loss: 2.976, accuracy: 0.853\n",
      "epoch 77 iter 280, loss: 2.949, accuracy: 0.856\n",
      "epoch 78 iter 0, loss: 2.996, accuracy: 0.859\n",
      "epoch 78 iter 70, loss: 2.922, accuracy: 0.854\n",
      "epoch 78 iter 140, loss: 2.942, accuracy: 0.851\n",
      "epoch 78 iter 210, loss: 2.724, accuracy: 0.854\n",
      "epoch 78 iter 280, loss: 2.845, accuracy: 0.859\n",
      "epoch 79 iter 0, loss: 3.031, accuracy: 0.857\n",
      "epoch 79 iter 70, loss: 3.123, accuracy: 0.850\n",
      "epoch 79 iter 140, loss: 3.088, accuracy: 0.854\n",
      "epoch 79 iter 210, loss: 2.898, accuracy: 0.857\n",
      "epoch 79 iter 280, loss: 2.895, accuracy: 0.852\n",
      "epoch 80 iter 0, loss: 2.936, accuracy: 0.855\n",
      "epoch 80 iter 70, loss: 3.146, accuracy: 0.857\n",
      "epoch 80 iter 140, loss: 3.081, accuracy: 0.852\n",
      "epoch 80 iter 210, loss: 3.274, accuracy: 0.853\n",
      "epoch 80 iter 280, loss: 3.226, accuracy: 0.853\n",
      "epoch 81 iter 0, loss: 3.099, accuracy: 0.856\n",
      "epoch 81 iter 70, loss: 3.054, accuracy: 0.858\n",
      "epoch 81 iter 140, loss: 3.038, accuracy: 0.853\n",
      "epoch 81 iter 210, loss: 3.033, accuracy: 0.857\n",
      "epoch 81 iter 280, loss: 2.985, accuracy: 0.857\n",
      "epoch 82 iter 0, loss: 3.136, accuracy: 0.860\n",
      "epoch 82 iter 70, loss: 3.174, accuracy: 0.851\n",
      "epoch 82 iter 140, loss: 3.245, accuracy: 0.855\n",
      "epoch 82 iter 210, loss: 3.225, accuracy: 0.854\n",
      "epoch 82 iter 280, loss: 2.964, accuracy: 0.856\n",
      "epoch 83 iter 0, loss: 3.113, accuracy: 0.858\n",
      "epoch 83 iter 70, loss: 3.174, accuracy: 0.856\n",
      "epoch 83 iter 140, loss: 3.166, accuracy: 0.852\n",
      "epoch 83 iter 210, loss: 3.098, accuracy: 0.863\n",
      "epoch 83 iter 280, loss: 3.125, accuracy: 0.857\n",
      "epoch 84 iter 0, loss: 3.212, accuracy: 0.854\n",
      "epoch 84 iter 70, loss: 3.354, accuracy: 0.850\n",
      "epoch 84 iter 140, loss: 3.267, accuracy: 0.858\n",
      "epoch 84 iter 210, loss: 3.149, accuracy: 0.853\n",
      "epoch 84 iter 280, loss: 3.253, accuracy: 0.851\n",
      "epoch 85 iter 0, loss: 3.378, accuracy: 0.853\n",
      "epoch 85 iter 70, loss: 3.501, accuracy: 0.853\n",
      "epoch 85 iter 140, loss: 3.259, accuracy: 0.856\n",
      "epoch 85 iter 210, loss: 3.302, accuracy: 0.855\n",
      "epoch 85 iter 280, loss: 3.214, accuracy: 0.851\n",
      "epoch 86 iter 0, loss: 3.207, accuracy: 0.858\n",
      "epoch 86 iter 70, loss: 3.365, accuracy: 0.856\n",
      "epoch 86 iter 140, loss: 3.475, accuracy: 0.855\n",
      "epoch 86 iter 210, loss: 3.251, accuracy: 0.861\n",
      "epoch 86 iter 280, loss: 3.353, accuracy: 0.860\n",
      "epoch 87 iter 0, loss: 3.316, accuracy: 0.859\n",
      "epoch 87 iter 70, loss: 3.462, accuracy: 0.857\n",
      "epoch 87 iter 140, loss: 3.350, accuracy: 0.858\n",
      "epoch 87 iter 210, loss: 3.370, accuracy: 0.852\n",
      "epoch 87 iter 280, loss: 3.432, accuracy: 0.860\n",
      "epoch 88 iter 0, loss: 3.387, accuracy: 0.857\n",
      "epoch 88 iter 70, loss: 3.212, accuracy: 0.862\n",
      "epoch 88 iter 140, loss: 3.419, accuracy: 0.861\n",
      "epoch 88 iter 210, loss: 3.241, accuracy: 0.856\n",
      "epoch 88 iter 280, loss: 3.339, accuracy: 0.858\n",
      "epoch 89 iter 0, loss: 3.364, accuracy: 0.857\n",
      "epoch 89 iter 70, loss: 3.480, accuracy: 0.860\n",
      "epoch 89 iter 140, loss: 3.583, accuracy: 0.858\n",
      "epoch 89 iter 210, loss: 3.505, accuracy: 0.855\n",
      "epoch 89 iter 280, loss: 3.644, accuracy: 0.855\n",
      "epoch 90 iter 0, loss: 3.619, accuracy: 0.857\n",
      "epoch 90 iter 70, loss: 3.539, accuracy: 0.857\n",
      "epoch 90 iter 140, loss: 3.449, accuracy: 0.860\n",
      "epoch 90 iter 210, loss: 3.327, accuracy: 0.859\n",
      "epoch 90 iter 280, loss: 3.530, accuracy: 0.856\n",
      "epoch 91 iter 0, loss: 3.643, accuracy: 0.859\n",
      "epoch 91 iter 70, loss: 3.785, accuracy: 0.859\n",
      "epoch 91 iter 140, loss: 3.635, accuracy: 0.856\n",
      "epoch 91 iter 210, loss: 3.498, accuracy: 0.862\n",
      "epoch 91 iter 280, loss: 3.624, accuracy: 0.852\n",
      "epoch 92 iter 0, loss: 3.666, accuracy: 0.857\n",
      "epoch 92 iter 70, loss: 3.943, accuracy: 0.851\n",
      "epoch 92 iter 140, loss: 3.652, accuracy: 0.855\n",
      "epoch 92 iter 210, loss: 3.516, accuracy: 0.858\n",
      "epoch 92 iter 280, loss: 3.567, accuracy: 0.861\n",
      "epoch 93 iter 0, loss: 3.472, accuracy: 0.861\n",
      "epoch 93 iter 70, loss: 3.532, accuracy: 0.857\n",
      "epoch 93 iter 140, loss: 3.786, accuracy: 0.849\n",
      "epoch 93 iter 210, loss: 3.624, accuracy: 0.860\n",
      "epoch 93 iter 280, loss: 3.635, accuracy: 0.853\n",
      "epoch 94 iter 0, loss: 3.542, accuracy: 0.854\n",
      "epoch 94 iter 70, loss: 3.611, accuracy: 0.857\n",
      "epoch 94 iter 140, loss: 3.564, accuracy: 0.855\n",
      "epoch 94 iter 210, loss: 3.480, accuracy: 0.858\n",
      "epoch 94 iter 280, loss: 3.616, accuracy: 0.849\n",
      "epoch 95 iter 0, loss: 3.625, accuracy: 0.857\n",
      "epoch 95 iter 70, loss: 3.705, accuracy: 0.861\n",
      "epoch 95 iter 140, loss: 3.759, accuracy: 0.856\n",
      "epoch 95 iter 210, loss: 3.660, accuracy: 0.857\n",
      "epoch 95 iter 280, loss: 3.606, accuracy: 0.851\n",
      "epoch 96 iter 0, loss: 3.584, accuracy: 0.858\n",
      "epoch 96 iter 70, loss: 3.994, accuracy: 0.856\n",
      "epoch 96 iter 140, loss: 4.097, accuracy: 0.849\n",
      "epoch 96 iter 210, loss: 3.845, accuracy: 0.856\n",
      "epoch 96 iter 280, loss: 3.900, accuracy: 0.853\n",
      "epoch 97 iter 0, loss: 3.943, accuracy: 0.858\n",
      "epoch 97 iter 70, loss: 3.858, accuracy: 0.860\n",
      "epoch 97 iter 140, loss: 3.814, accuracy: 0.853\n",
      "epoch 97 iter 210, loss: 3.676, accuracy: 0.858\n",
      "epoch 97 iter 280, loss: 3.663, accuracy: 0.863\n",
      "epoch 98 iter 0, loss: 3.598, accuracy: 0.856\n",
      "epoch 98 iter 70, loss: 3.880, accuracy: 0.858\n",
      "epoch 98 iter 140, loss: 3.865, accuracy: 0.856\n",
      "epoch 98 iter 210, loss: 3.616, accuracy: 0.855\n",
      "epoch 98 iter 280, loss: 3.949, accuracy: 0.860\n",
      "epoch 99 iter 0, loss: 3.876, accuracy: 0.861\n",
      "epoch 99 iter 70, loss: 3.853, accuracy: 0.856\n",
      "epoch 99 iter 140, loss: 3.982, accuracy: 0.854\n",
      "epoch 99 iter 210, loss: 3.586, accuracy: 0.860\n",
      "epoch 99 iter 280, loss: 3.901, accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=1,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=100, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 95.843, accuracy: 0.062\n",
      "epoch 0 iter 70, loss: 2.236, accuracy: 0.196\n",
      "epoch 0 iter 140, loss: 2.178, accuracy: 0.224\n",
      "epoch 0 iter 210, loss: 2.130, accuracy: 0.254\n",
      "epoch 0 iter 280, loss: 2.102, accuracy: 0.278\n",
      "epoch 1 iter 0, loss: 2.105, accuracy: 0.267\n",
      "epoch 1 iter 70, loss: 2.055, accuracy: 0.290\n",
      "epoch 1 iter 140, loss: 2.029, accuracy: 0.295\n",
      "epoch 1 iter 210, loss: 2.012, accuracy: 0.303\n",
      "epoch 1 iter 280, loss: 1.898, accuracy: 0.347\n",
      "epoch 2 iter 0, loss: 2.329, accuracy: 0.292\n",
      "epoch 2 iter 70, loss: 1.970, accuracy: 0.310\n",
      "epoch 2 iter 140, loss: 1.983, accuracy: 0.306\n",
      "epoch 2 iter 210, loss: 1.937, accuracy: 0.326\n",
      "epoch 2 iter 280, loss: 1.950, accuracy: 0.320\n",
      "epoch 3 iter 0, loss: 1.976, accuracy: 0.306\n",
      "epoch 3 iter 70, loss: 1.923, accuracy: 0.332\n",
      "epoch 3 iter 140, loss: 1.261, accuracy: 0.609\n",
      "epoch 3 iter 210, loss: 1.100, accuracy: 0.666\n",
      "epoch 3 iter 280, loss: 1.074, accuracy: 0.669\n",
      "epoch 4 iter 0, loss: 1.028, accuracy: 0.689\n",
      "epoch 4 iter 70, loss: 0.949, accuracy: 0.713\n",
      "epoch 4 iter 140, loss: 0.911, accuracy: 0.729\n",
      "epoch 4 iter 210, loss: 0.878, accuracy: 0.742\n",
      "epoch 4 iter 280, loss: 0.851, accuracy: 0.750\n",
      "epoch 5 iter 0, loss: 0.781, accuracy: 0.774\n",
      "epoch 5 iter 70, loss: 0.759, accuracy: 0.780\n",
      "epoch 5 iter 140, loss: 0.765, accuracy: 0.781\n",
      "epoch 5 iter 210, loss: 0.737, accuracy: 0.793\n",
      "epoch 5 iter 280, loss: 0.714, accuracy: 0.798\n",
      "epoch 6 iter 0, loss: 0.696, accuracy: 0.807\n",
      "epoch 6 iter 70, loss: 0.714, accuracy: 0.794\n",
      "epoch 6 iter 140, loss: 0.750, accuracy: 0.794\n",
      "epoch 6 iter 210, loss: 0.688, accuracy: 0.814\n",
      "epoch 6 iter 280, loss: 0.733, accuracy: 0.803\n",
      "epoch 7 iter 0, loss: 0.713, accuracy: 0.809\n",
      "epoch 7 iter 70, loss: 0.692, accuracy: 0.807\n",
      "epoch 7 iter 140, loss: 0.747, accuracy: 0.804\n",
      "epoch 7 iter 210, loss: 0.704, accuracy: 0.814\n",
      "epoch 7 iter 280, loss: 0.767, accuracy: 0.810\n",
      "epoch 8 iter 0, loss: 0.727, accuracy: 0.818\n",
      "epoch 8 iter 70, loss: 0.719, accuracy: 0.813\n",
      "epoch 8 iter 140, loss: 0.740, accuracy: 0.814\n",
      "epoch 8 iter 210, loss: 0.735, accuracy: 0.818\n",
      "epoch 8 iter 280, loss: 0.726, accuracy: 0.826\n",
      "epoch 9 iter 0, loss: 0.789, accuracy: 0.821\n",
      "epoch 9 iter 70, loss: 0.776, accuracy: 0.812\n",
      "epoch 9 iter 140, loss: 0.810, accuracy: 0.816\n",
      "epoch 9 iter 210, loss: 0.812, accuracy: 0.808\n",
      "epoch 9 iter 280, loss: 0.789, accuracy: 0.824\n",
      "epoch 10 iter 0, loss: 0.815, accuracy: 0.823\n",
      "epoch 10 iter 70, loss: 0.814, accuracy: 0.817\n",
      "epoch 10 iter 140, loss: 0.939, accuracy: 0.814\n",
      "epoch 10 iter 210, loss: 0.803, accuracy: 0.818\n",
      "epoch 10 iter 280, loss: 0.833, accuracy: 0.817\n",
      "epoch 11 iter 0, loss: 0.854, accuracy: 0.829\n",
      "epoch 11 iter 70, loss: 0.812, accuracy: 0.823\n",
      "epoch 11 iter 140, loss: 1.067, accuracy: 0.804\n",
      "epoch 11 iter 210, loss: 0.839, accuracy: 0.818\n",
      "epoch 11 iter 280, loss: 0.882, accuracy: 0.817\n",
      "epoch 12 iter 0, loss: 0.875, accuracy: 0.820\n",
      "epoch 12 iter 70, loss: 0.914, accuracy: 0.817\n",
      "epoch 12 iter 140, loss: 1.085, accuracy: 0.809\n",
      "epoch 12 iter 210, loss: 0.814, accuracy: 0.825\n",
      "epoch 12 iter 280, loss: 0.941, accuracy: 0.815\n",
      "epoch 13 iter 0, loss: 1.068, accuracy: 0.805\n",
      "epoch 13 iter 70, loss: 1.097, accuracy: 0.786\n",
      "epoch 13 iter 140, loss: 0.973, accuracy: 0.815\n",
      "epoch 13 iter 210, loss: 0.851, accuracy: 0.832\n",
      "epoch 13 iter 280, loss: 1.001, accuracy: 0.820\n",
      "epoch 14 iter 0, loss: 0.971, accuracy: 0.817\n",
      "epoch 14 iter 70, loss: 1.070, accuracy: 0.811\n",
      "epoch 14 iter 140, loss: 1.032, accuracy: 0.811\n",
      "epoch 14 iter 210, loss: 0.973, accuracy: 0.817\n",
      "epoch 14 iter 280, loss: 1.012, accuracy: 0.824\n",
      "epoch 15 iter 0, loss: 1.001, accuracy: 0.822\n",
      "epoch 15 iter 70, loss: 1.203, accuracy: 0.806\n",
      "epoch 15 iter 140, loss: 1.089, accuracy: 0.821\n",
      "epoch 15 iter 210, loss: 1.022, accuracy: 0.822\n",
      "epoch 15 iter 280, loss: 1.128, accuracy: 0.815\n",
      "epoch 16 iter 0, loss: 1.118, accuracy: 0.825\n",
      "epoch 16 iter 70, loss: 1.183, accuracy: 0.816\n",
      "epoch 16 iter 140, loss: 1.242, accuracy: 0.817\n",
      "epoch 16 iter 210, loss: 1.087, accuracy: 0.816\n",
      "epoch 16 iter 280, loss: 1.271, accuracy: 0.805\n",
      "epoch 17 iter 0, loss: 1.135, accuracy: 0.822\n",
      "epoch 17 iter 70, loss: 1.263, accuracy: 0.820\n",
      "epoch 17 iter 140, loss: 1.286, accuracy: 0.817\n",
      "epoch 17 iter 210, loss: 1.167, accuracy: 0.810\n",
      "epoch 17 iter 280, loss: 1.250, accuracy: 0.823\n",
      "epoch 18 iter 0, loss: 1.071, accuracy: 0.820\n",
      "epoch 18 iter 70, loss: 1.256, accuracy: 0.812\n",
      "epoch 18 iter 140, loss: 1.384, accuracy: 0.817\n",
      "epoch 18 iter 210, loss: 1.187, accuracy: 0.813\n",
      "epoch 18 iter 280, loss: 1.193, accuracy: 0.829\n",
      "epoch 19 iter 0, loss: 1.203, accuracy: 0.823\n",
      "epoch 19 iter 70, loss: 1.275, accuracy: 0.820\n",
      "epoch 19 iter 140, loss: 1.237, accuracy: 0.830\n",
      "epoch 19 iter 210, loss: 1.279, accuracy: 0.812\n",
      "epoch 19 iter 280, loss: 1.361, accuracy: 0.825\n",
      "epoch 20 iter 0, loss: 1.360, accuracy: 0.826\n",
      "epoch 20 iter 70, loss: 1.471, accuracy: 0.814\n",
      "epoch 20 iter 140, loss: 1.314, accuracy: 0.832\n",
      "epoch 20 iter 210, loss: 1.316, accuracy: 0.807\n",
      "epoch 20 iter 280, loss: 1.362, accuracy: 0.831\n",
      "epoch 21 iter 0, loss: 1.435, accuracy: 0.824\n",
      "epoch 21 iter 70, loss: 1.554, accuracy: 0.818\n",
      "epoch 21 iter 140, loss: 1.628, accuracy: 0.817\n",
      "epoch 21 iter 210, loss: 1.389, accuracy: 0.822\n",
      "epoch 21 iter 280, loss: 1.388, accuracy: 0.827\n",
      "epoch 22 iter 0, loss: 1.515, accuracy: 0.818\n",
      "epoch 22 iter 70, loss: 1.550, accuracy: 0.819\n",
      "epoch 22 iter 140, loss: 1.626, accuracy: 0.818\n",
      "epoch 22 iter 210, loss: 1.431, accuracy: 0.833\n",
      "epoch 22 iter 280, loss: 1.479, accuracy: 0.826\n",
      "epoch 23 iter 0, loss: 1.342, accuracy: 0.833\n",
      "epoch 23 iter 70, loss: 1.590, accuracy: 0.825\n",
      "epoch 23 iter 140, loss: 1.760, accuracy: 0.826\n",
      "epoch 23 iter 210, loss: 1.516, accuracy: 0.832\n",
      "epoch 23 iter 280, loss: 1.697, accuracy: 0.821\n",
      "epoch 24 iter 0, loss: 1.753, accuracy: 0.816\n",
      "epoch 24 iter 70, loss: 1.768, accuracy: 0.818\n",
      "epoch 24 iter 140, loss: 1.802, accuracy: 0.833\n",
      "epoch 24 iter 210, loss: 1.557, accuracy: 0.833\n",
      "epoch 24 iter 280, loss: 1.711, accuracy: 0.819\n",
      "epoch 25 iter 0, loss: 1.895, accuracy: 0.807\n",
      "epoch 25 iter 70, loss: 1.667, accuracy: 0.829\n",
      "epoch 25 iter 140, loss: 2.138, accuracy: 0.826\n",
      "epoch 25 iter 210, loss: 1.723, accuracy: 0.833\n",
      "epoch 25 iter 280, loss: 1.747, accuracy: 0.830\n",
      "epoch 26 iter 0, loss: 1.770, accuracy: 0.829\n",
      "epoch 26 iter 70, loss: 1.935, accuracy: 0.820\n",
      "epoch 26 iter 140, loss: 1.844, accuracy: 0.831\n",
      "epoch 26 iter 210, loss: 1.880, accuracy: 0.838\n",
      "epoch 26 iter 280, loss: 1.839, accuracy: 0.825\n",
      "epoch 27 iter 0, loss: 1.783, accuracy: 0.830\n",
      "epoch 27 iter 70, loss: 1.823, accuracy: 0.829\n",
      "epoch 27 iter 140, loss: 1.976, accuracy: 0.827\n",
      "epoch 27 iter 210, loss: 1.819, accuracy: 0.835\n",
      "epoch 27 iter 280, loss: 1.853, accuracy: 0.825\n",
      "epoch 28 iter 0, loss: 1.996, accuracy: 0.828\n",
      "epoch 28 iter 70, loss: 1.913, accuracy: 0.831\n",
      "epoch 28 iter 140, loss: 1.957, accuracy: 0.834\n",
      "epoch 28 iter 210, loss: 1.767, accuracy: 0.836\n",
      "epoch 28 iter 280, loss: 1.911, accuracy: 0.824\n",
      "epoch 29 iter 0, loss: 2.065, accuracy: 0.829\n",
      "epoch 29 iter 70, loss: 2.099, accuracy: 0.829\n",
      "epoch 29 iter 140, loss: 1.934, accuracy: 0.832\n",
      "epoch 29 iter 210, loss: 1.801, accuracy: 0.843\n",
      "epoch 29 iter 280, loss: 1.969, accuracy: 0.830\n",
      "epoch 30 iter 0, loss: 2.076, accuracy: 0.837\n",
      "epoch 30 iter 70, loss: 2.162, accuracy: 0.831\n",
      "epoch 30 iter 140, loss: 1.951, accuracy: 0.836\n",
      "epoch 30 iter 210, loss: 1.858, accuracy: 0.842\n",
      "epoch 30 iter 280, loss: 1.945, accuracy: 0.836\n",
      "epoch 31 iter 0, loss: 2.063, accuracy: 0.841\n",
      "epoch 31 iter 70, loss: 2.128, accuracy: 0.825\n",
      "epoch 31 iter 140, loss: 2.185, accuracy: 0.828\n",
      "epoch 31 iter 210, loss: 1.895, accuracy: 0.845\n",
      "epoch 31 iter 280, loss: 2.075, accuracy: 0.836\n",
      "epoch 32 iter 0, loss: 2.106, accuracy: 0.837\n",
      "epoch 32 iter 70, loss: 2.449, accuracy: 0.828\n",
      "epoch 32 iter 140, loss: 2.323, accuracy: 0.824\n",
      "epoch 32 iter 210, loss: 2.301, accuracy: 0.823\n",
      "epoch 32 iter 280, loss: 2.159, accuracy: 0.831\n",
      "epoch 33 iter 0, loss: 2.404, accuracy: 0.833\n",
      "epoch 33 iter 70, loss: 2.320, accuracy: 0.829\n",
      "epoch 33 iter 140, loss: 2.431, accuracy: 0.830\n",
      "epoch 33 iter 210, loss: 2.460, accuracy: 0.837\n",
      "epoch 33 iter 280, loss: 2.200, accuracy: 0.829\n",
      "epoch 34 iter 0, loss: 2.384, accuracy: 0.833\n",
      "epoch 34 iter 70, loss: 2.337, accuracy: 0.834\n",
      "epoch 34 iter 140, loss: 2.517, accuracy: 0.824\n",
      "epoch 34 iter 210, loss: 2.330, accuracy: 0.842\n",
      "epoch 34 iter 280, loss: 2.151, accuracy: 0.833\n",
      "epoch 35 iter 0, loss: 2.395, accuracy: 0.842\n",
      "epoch 35 iter 70, loss: 2.457, accuracy: 0.834\n",
      "epoch 35 iter 140, loss: 2.816, accuracy: 0.831\n",
      "epoch 35 iter 210, loss: 2.438, accuracy: 0.839\n",
      "epoch 35 iter 280, loss: 2.256, accuracy: 0.830\n",
      "epoch 36 iter 0, loss: 2.377, accuracy: 0.848\n",
      "epoch 36 iter 70, loss: 2.467, accuracy: 0.839\n",
      "epoch 36 iter 140, loss: 2.710, accuracy: 0.832\n",
      "epoch 36 iter 210, loss: 2.379, accuracy: 0.840\n",
      "epoch 36 iter 280, loss: 2.155, accuracy: 0.835\n",
      "epoch 37 iter 0, loss: 2.229, accuracy: 0.844\n",
      "epoch 37 iter 70, loss: 2.589, accuracy: 0.832\n",
      "epoch 37 iter 140, loss: 2.761, accuracy: 0.829\n",
      "epoch 37 iter 210, loss: 2.290, accuracy: 0.840\n",
      "epoch 37 iter 280, loss: 2.373, accuracy: 0.837\n",
      "epoch 38 iter 0, loss: 2.508, accuracy: 0.840\n",
      "epoch 38 iter 70, loss: 2.739, accuracy: 0.830\n",
      "epoch 38 iter 140, loss: 2.512, accuracy: 0.833\n",
      "epoch 38 iter 210, loss: 2.548, accuracy: 0.836\n",
      "epoch 38 iter 280, loss: 2.247, accuracy: 0.837\n",
      "epoch 39 iter 0, loss: 2.381, accuracy: 0.846\n",
      "epoch 39 iter 70, loss: 2.844, accuracy: 0.835\n",
      "epoch 39 iter 140, loss: 2.546, accuracy: 0.844\n",
      "epoch 39 iter 210, loss: 2.573, accuracy: 0.840\n",
      "epoch 39 iter 280, loss: 2.486, accuracy: 0.827\n",
      "epoch 40 iter 0, loss: 2.640, accuracy: 0.849\n",
      "epoch 40 iter 70, loss: 2.695, accuracy: 0.832\n",
      "epoch 40 iter 140, loss: 2.745, accuracy: 0.834\n",
      "epoch 40 iter 210, loss: 2.563, accuracy: 0.841\n",
      "epoch 40 iter 280, loss: 2.414, accuracy: 0.829\n",
      "epoch 41 iter 0, loss: 2.503, accuracy: 0.844\n",
      "epoch 41 iter 70, loss: 3.034, accuracy: 0.834\n",
      "epoch 41 iter 140, loss: 2.744, accuracy: 0.829\n",
      "epoch 41 iter 210, loss: 2.776, accuracy: 0.835\n",
      "epoch 41 iter 280, loss: 2.735, accuracy: 0.830\n",
      "epoch 42 iter 0, loss: 2.912, accuracy: 0.836\n",
      "epoch 42 iter 70, loss: 3.293, accuracy: 0.836\n",
      "epoch 42 iter 140, loss: 3.288, accuracy: 0.830\n",
      "epoch 42 iter 210, loss: 2.917, accuracy: 0.844\n",
      "epoch 42 iter 280, loss: 2.617, accuracy: 0.825\n",
      "epoch 43 iter 0, loss: 2.686, accuracy: 0.829\n",
      "epoch 43 iter 70, loss: 2.954, accuracy: 0.843\n",
      "epoch 43 iter 140, loss: 3.071, accuracy: 0.829\n",
      "epoch 43 iter 210, loss: 3.061, accuracy: 0.839\n",
      "epoch 43 iter 280, loss: 2.743, accuracy: 0.847\n",
      "epoch 44 iter 0, loss: 2.814, accuracy: 0.842\n",
      "epoch 44 iter 70, loss: 3.225, accuracy: 0.839\n",
      "epoch 44 iter 140, loss: 3.057, accuracy: 0.816\n",
      "epoch 44 iter 210, loss: 3.067, accuracy: 0.841\n",
      "epoch 44 iter 280, loss: 2.977, accuracy: 0.841\n",
      "epoch 45 iter 0, loss: 2.880, accuracy: 0.839\n",
      "epoch 45 iter 70, loss: 3.285, accuracy: 0.833\n",
      "epoch 45 iter 140, loss: 3.230, accuracy: 0.836\n",
      "epoch 45 iter 210, loss: 2.865, accuracy: 0.848\n",
      "epoch 45 iter 280, loss: 2.937, accuracy: 0.839\n",
      "epoch 46 iter 0, loss: 2.879, accuracy: 0.840\n",
      "epoch 46 iter 70, loss: 3.131, accuracy: 0.844\n",
      "epoch 46 iter 140, loss: 3.370, accuracy: 0.833\n",
      "epoch 46 iter 210, loss: 2.946, accuracy: 0.852\n",
      "epoch 46 iter 280, loss: 2.930, accuracy: 0.838\n",
      "epoch 47 iter 0, loss: 2.914, accuracy: 0.848\n",
      "epoch 47 iter 70, loss: 3.141, accuracy: 0.837\n",
      "epoch 47 iter 140, loss: 3.376, accuracy: 0.827\n",
      "epoch 47 iter 210, loss: 3.171, accuracy: 0.842\n",
      "epoch 47 iter 280, loss: 3.213, accuracy: 0.840\n",
      "epoch 48 iter 0, loss: 2.934, accuracy: 0.819\n",
      "epoch 48 iter 70, loss: 3.357, accuracy: 0.832\n",
      "epoch 48 iter 140, loss: 3.305, accuracy: 0.835\n",
      "epoch 48 iter 210, loss: 3.085, accuracy: 0.848\n",
      "epoch 48 iter 280, loss: 3.011, accuracy: 0.846\n",
      "epoch 49 iter 0, loss: 2.762, accuracy: 0.837\n",
      "epoch 49 iter 70, loss: 3.557, accuracy: 0.832\n",
      "epoch 49 iter 140, loss: 3.334, accuracy: 0.834\n",
      "epoch 49 iter 210, loss: 3.376, accuracy: 0.843\n",
      "epoch 49 iter 280, loss: 3.654, accuracy: 0.843\n",
      "epoch 50 iter 0, loss: 3.455, accuracy: 0.833\n",
      "epoch 50 iter 70, loss: 3.510, accuracy: 0.840\n",
      "epoch 50 iter 140, loss: 3.352, accuracy: 0.834\n",
      "epoch 50 iter 210, loss: 3.257, accuracy: 0.841\n",
      "epoch 50 iter 280, loss: 3.564, accuracy: 0.842\n",
      "epoch 51 iter 0, loss: 3.172, accuracy: 0.845\n",
      "epoch 51 iter 70, loss: 3.532, accuracy: 0.839\n",
      "epoch 51 iter 140, loss: 3.337, accuracy: 0.846\n",
      "epoch 51 iter 210, loss: 3.654, accuracy: 0.843\n",
      "epoch 51 iter 280, loss: 3.576, accuracy: 0.841\n",
      "epoch 52 iter 0, loss: 3.553, accuracy: 0.834\n",
      "epoch 52 iter 70, loss: 3.594, accuracy: 0.847\n",
      "epoch 52 iter 140, loss: 3.727, accuracy: 0.843\n",
      "epoch 52 iter 210, loss: 3.512, accuracy: 0.853\n",
      "epoch 52 iter 280, loss: 3.686, accuracy: 0.840\n",
      "epoch 53 iter 0, loss: 3.432, accuracy: 0.847\n",
      "epoch 53 iter 70, loss: 3.799, accuracy: 0.843\n",
      "epoch 53 iter 140, loss: 3.760, accuracy: 0.840\n",
      "epoch 53 iter 210, loss: 3.754, accuracy: 0.846\n",
      "epoch 53 iter 280, loss: 3.553, accuracy: 0.835\n",
      "epoch 54 iter 0, loss: 3.442, accuracy: 0.838\n",
      "epoch 54 iter 70, loss: 3.855, accuracy: 0.845\n",
      "epoch 54 iter 140, loss: 3.663, accuracy: 0.842\n",
      "epoch 54 iter 210, loss: 3.513, accuracy: 0.847\n",
      "epoch 54 iter 280, loss: 3.470, accuracy: 0.848\n",
      "epoch 55 iter 0, loss: 3.873, accuracy: 0.849\n",
      "epoch 55 iter 70, loss: 3.907, accuracy: 0.846\n",
      "epoch 55 iter 140, loss: 3.638, accuracy: 0.827\n",
      "epoch 55 iter 210, loss: 3.625, accuracy: 0.845\n",
      "epoch 55 iter 280, loss: 3.740, accuracy: 0.851\n",
      "epoch 56 iter 0, loss: 3.927, accuracy: 0.857\n",
      "epoch 56 iter 70, loss: 3.976, accuracy: 0.844\n",
      "epoch 56 iter 140, loss: 3.773, accuracy: 0.838\n",
      "epoch 56 iter 210, loss: 4.097, accuracy: 0.842\n",
      "epoch 56 iter 280, loss: 3.664, accuracy: 0.849\n",
      "epoch 57 iter 0, loss: 3.778, accuracy: 0.848\n",
      "epoch 57 iter 70, loss: 4.002, accuracy: 0.851\n",
      "epoch 57 iter 140, loss: 3.929, accuracy: 0.842\n",
      "epoch 57 iter 210, loss: 3.790, accuracy: 0.854\n",
      "epoch 57 iter 280, loss: 3.605, accuracy: 0.854\n",
      "epoch 58 iter 0, loss: 3.672, accuracy: 0.844\n",
      "epoch 58 iter 70, loss: 4.172, accuracy: 0.846\n",
      "epoch 58 iter 140, loss: 3.653, accuracy: 0.841\n",
      "epoch 58 iter 210, loss: 4.081, accuracy: 0.846\n",
      "epoch 58 iter 280, loss: 3.749, accuracy: 0.847\n",
      "epoch 59 iter 0, loss: 3.847, accuracy: 0.845\n",
      "epoch 59 iter 70, loss: 4.229, accuracy: 0.844\n",
      "epoch 59 iter 140, loss: 4.096, accuracy: 0.840\n",
      "epoch 59 iter 210, loss: 3.815, accuracy: 0.846\n",
      "epoch 59 iter 280, loss: 4.062, accuracy: 0.854\n",
      "epoch 60 iter 0, loss: 3.953, accuracy: 0.852\n",
      "epoch 60 iter 70, loss: 4.596, accuracy: 0.846\n",
      "epoch 60 iter 140, loss: 3.779, accuracy: 0.846\n",
      "epoch 60 iter 210, loss: 4.099, accuracy: 0.847\n",
      "epoch 60 iter 280, loss: 3.635, accuracy: 0.851\n",
      "epoch 61 iter 0, loss: 3.932, accuracy: 0.851\n",
      "epoch 61 iter 70, loss: 4.364, accuracy: 0.845\n",
      "epoch 61 iter 140, loss: 3.669, accuracy: 0.846\n",
      "epoch 61 iter 210, loss: 4.202, accuracy: 0.845\n",
      "epoch 61 iter 280, loss: 3.819, accuracy: 0.847\n",
      "epoch 62 iter 0, loss: 4.014, accuracy: 0.842\n",
      "epoch 62 iter 70, loss: 4.186, accuracy: 0.844\n",
      "epoch 62 iter 140, loss: 4.262, accuracy: 0.841\n",
      "epoch 62 iter 210, loss: 4.009, accuracy: 0.847\n",
      "epoch 62 iter 280, loss: 4.087, accuracy: 0.844\n",
      "epoch 63 iter 0, loss: 4.003, accuracy: 0.848\n",
      "epoch 63 iter 70, loss: 4.456, accuracy: 0.840\n",
      "epoch 63 iter 140, loss: 4.293, accuracy: 0.838\n",
      "epoch 63 iter 210, loss: 4.204, accuracy: 0.850\n",
      "epoch 63 iter 280, loss: 4.013, accuracy: 0.848\n",
      "epoch 64 iter 0, loss: 3.971, accuracy: 0.848\n",
      "epoch 64 iter 70, loss: 4.821, accuracy: 0.839\n",
      "epoch 64 iter 140, loss: 4.657, accuracy: 0.847\n",
      "epoch 64 iter 210, loss: 4.230, accuracy: 0.845\n",
      "epoch 64 iter 280, loss: 3.833, accuracy: 0.849\n",
      "epoch 65 iter 0, loss: 3.773, accuracy: 0.851\n",
      "epoch 65 iter 70, loss: 4.355, accuracy: 0.846\n",
      "epoch 65 iter 140, loss: 4.218, accuracy: 0.842\n",
      "epoch 65 iter 210, loss: 4.117, accuracy: 0.854\n",
      "epoch 65 iter 280, loss: 3.884, accuracy: 0.855\n",
      "epoch 66 iter 0, loss: 4.067, accuracy: 0.849\n",
      "epoch 66 iter 70, loss: 4.296, accuracy: 0.848\n",
      "epoch 66 iter 140, loss: 4.180, accuracy: 0.849\n",
      "epoch 66 iter 210, loss: 4.471, accuracy: 0.851\n",
      "epoch 66 iter 280, loss: 4.117, accuracy: 0.853\n",
      "epoch 67 iter 0, loss: 4.129, accuracy: 0.850\n",
      "epoch 67 iter 70, loss: 4.746, accuracy: 0.848\n",
      "epoch 67 iter 140, loss: 4.508, accuracy: 0.839\n",
      "epoch 67 iter 210, loss: 4.299, accuracy: 0.848\n",
      "epoch 67 iter 280, loss: 4.506, accuracy: 0.859\n",
      "epoch 68 iter 0, loss: 4.517, accuracy: 0.856\n",
      "epoch 68 iter 70, loss: 5.013, accuracy: 0.856\n",
      "epoch 68 iter 140, loss: 4.710, accuracy: 0.848\n",
      "epoch 68 iter 210, loss: 4.610, accuracy: 0.854\n",
      "epoch 68 iter 280, loss: 4.362, accuracy: 0.854\n",
      "epoch 69 iter 0, loss: 4.532, accuracy: 0.856\n",
      "epoch 69 iter 70, loss: 4.924, accuracy: 0.849\n",
      "epoch 69 iter 140, loss: 4.914, accuracy: 0.848\n",
      "epoch 69 iter 210, loss: 4.706, accuracy: 0.856\n",
      "epoch 69 iter 280, loss: 4.559, accuracy: 0.852\n",
      "epoch 70 iter 0, loss: 4.751, accuracy: 0.854\n",
      "epoch 70 iter 70, loss: 4.906, accuracy: 0.848\n",
      "epoch 70 iter 140, loss: 5.501, accuracy: 0.851\n",
      "epoch 70 iter 210, loss: 4.525, accuracy: 0.848\n",
      "epoch 70 iter 280, loss: 4.411, accuracy: 0.859\n",
      "epoch 71 iter 0, loss: 4.902, accuracy: 0.852\n",
      "epoch 71 iter 70, loss: 5.079, accuracy: 0.846\n",
      "epoch 71 iter 140, loss: 5.089, accuracy: 0.841\n",
      "epoch 71 iter 210, loss: 4.636, accuracy: 0.854\n",
      "epoch 71 iter 280, loss: 4.876, accuracy: 0.856\n",
      "epoch 72 iter 0, loss: 4.814, accuracy: 0.853\n",
      "epoch 72 iter 70, loss: 5.056, accuracy: 0.849\n",
      "epoch 72 iter 140, loss: 5.087, accuracy: 0.846\n",
      "epoch 72 iter 210, loss: 5.025, accuracy: 0.852\n",
      "epoch 72 iter 280, loss: 4.662, accuracy: 0.858\n",
      "epoch 73 iter 0, loss: 4.751, accuracy: 0.859\n",
      "epoch 73 iter 70, loss: 4.941, accuracy: 0.849\n",
      "epoch 73 iter 140, loss: 5.125, accuracy: 0.847\n",
      "epoch 73 iter 210, loss: 5.290, accuracy: 0.851\n",
      "epoch 73 iter 280, loss: 4.613, accuracy: 0.858\n",
      "epoch 74 iter 0, loss: 4.519, accuracy: 0.848\n",
      "epoch 74 iter 70, loss: 4.787, accuracy: 0.853\n",
      "epoch 74 iter 140, loss: 4.797, accuracy: 0.833\n",
      "epoch 74 iter 210, loss: 5.090, accuracy: 0.846\n",
      "epoch 74 iter 280, loss: 4.872, accuracy: 0.855\n",
      "epoch 75 iter 0, loss: 5.163, accuracy: 0.851\n",
      "epoch 75 iter 70, loss: 5.177, accuracy: 0.841\n",
      "epoch 75 iter 140, loss: 4.758, accuracy: 0.839\n",
      "epoch 75 iter 210, loss: 5.174, accuracy: 0.852\n",
      "epoch 75 iter 280, loss: 4.809, accuracy: 0.855\n",
      "epoch 76 iter 0, loss: 4.871, accuracy: 0.856\n",
      "epoch 76 iter 70, loss: 5.288, accuracy: 0.849\n",
      "epoch 76 iter 140, loss: 4.912, accuracy: 0.855\n",
      "epoch 76 iter 210, loss: 5.184, accuracy: 0.856\n",
      "epoch 76 iter 280, loss: 5.087, accuracy: 0.852\n",
      "epoch 77 iter 0, loss: 5.209, accuracy: 0.856\n",
      "epoch 77 iter 70, loss: 5.460, accuracy: 0.853\n",
      "epoch 77 iter 140, loss: 5.338, accuracy: 0.847\n",
      "epoch 77 iter 210, loss: 5.163, accuracy: 0.844\n",
      "epoch 77 iter 280, loss: 5.277, accuracy: 0.851\n",
      "epoch 78 iter 0, loss: 5.237, accuracy: 0.853\n",
      "epoch 78 iter 70, loss: 5.467, accuracy: 0.847\n",
      "epoch 78 iter 140, loss: 5.000, accuracy: 0.847\n",
      "epoch 78 iter 210, loss: 5.035, accuracy: 0.850\n",
      "epoch 78 iter 280, loss: 5.068, accuracy: 0.854\n",
      "epoch 79 iter 0, loss: 4.903, accuracy: 0.855\n",
      "epoch 79 iter 70, loss: 5.384, accuracy: 0.842\n",
      "epoch 79 iter 140, loss: 5.850, accuracy: 0.846\n",
      "epoch 79 iter 210, loss: 5.550, accuracy: 0.853\n",
      "epoch 79 iter 280, loss: 5.297, accuracy: 0.845\n",
      "epoch 80 iter 0, loss: 5.764, accuracy: 0.850\n",
      "epoch 80 iter 70, loss: 5.775, accuracy: 0.854\n",
      "epoch 80 iter 140, loss: 5.303, accuracy: 0.849\n",
      "epoch 80 iter 210, loss: 5.554, accuracy: 0.843\n",
      "epoch 80 iter 280, loss: 5.452, accuracy: 0.847\n",
      "epoch 81 iter 0, loss: 5.274, accuracy: 0.854\n",
      "epoch 81 iter 70, loss: 5.685, accuracy: 0.852\n",
      "epoch 81 iter 140, loss: 5.660, accuracy: 0.847\n",
      "epoch 81 iter 210, loss: 5.454, accuracy: 0.847\n",
      "epoch 81 iter 280, loss: 5.640, accuracy: 0.849\n",
      "epoch 82 iter 0, loss: 5.459, accuracy: 0.838\n",
      "epoch 82 iter 70, loss: 5.443, accuracy: 0.856\n",
      "epoch 82 iter 140, loss: 5.584, accuracy: 0.848\n",
      "epoch 82 iter 210, loss: 5.981, accuracy: 0.856\n",
      "epoch 82 iter 280, loss: 5.417, accuracy: 0.849\n",
      "epoch 83 iter 0, loss: 5.604, accuracy: 0.851\n",
      "epoch 83 iter 70, loss: 6.283, accuracy: 0.850\n",
      "epoch 83 iter 140, loss: 5.981, accuracy: 0.854\n",
      "epoch 83 iter 210, loss: 6.271, accuracy: 0.853\n",
      "epoch 83 iter 280, loss: 5.750, accuracy: 0.857\n",
      "epoch 84 iter 0, loss: 5.548, accuracy: 0.853\n",
      "epoch 84 iter 70, loss: 6.371, accuracy: 0.849\n",
      "epoch 84 iter 140, loss: 6.017, accuracy: 0.847\n",
      "epoch 84 iter 210, loss: 6.423, accuracy: 0.859\n",
      "epoch 84 iter 280, loss: 6.005, accuracy: 0.854\n",
      "epoch 85 iter 0, loss: 5.866, accuracy: 0.850\n",
      "epoch 85 iter 70, loss: 6.455, accuracy: 0.855\n",
      "epoch 85 iter 140, loss: 5.946, accuracy: 0.849\n",
      "epoch 85 iter 210, loss: 6.121, accuracy: 0.856\n",
      "epoch 85 iter 280, loss: 5.906, accuracy: 0.844\n",
      "epoch 86 iter 0, loss: 6.080, accuracy: 0.856\n",
      "epoch 86 iter 70, loss: 6.221, accuracy: 0.850\n",
      "epoch 86 iter 140, loss: 6.288, accuracy: 0.850\n",
      "epoch 86 iter 210, loss: 6.235, accuracy: 0.846\n",
      "epoch 86 iter 280, loss: 5.759, accuracy: 0.848\n",
      "epoch 87 iter 0, loss: 5.700, accuracy: 0.851\n",
      "epoch 87 iter 70, loss: 6.805, accuracy: 0.842\n",
      "epoch 87 iter 140, loss: 6.520, accuracy: 0.849\n",
      "epoch 87 iter 210, loss: 6.698, accuracy: 0.851\n",
      "epoch 87 iter 280, loss: 6.460, accuracy: 0.855\n",
      "epoch 88 iter 0, loss: 6.970, accuracy: 0.855\n",
      "epoch 88 iter 70, loss: 7.358, accuracy: 0.840\n",
      "epoch 88 iter 140, loss: 6.786, accuracy: 0.847\n",
      "epoch 88 iter 210, loss: 6.575, accuracy: 0.859\n",
      "epoch 88 iter 280, loss: 6.359, accuracy: 0.846\n",
      "epoch 89 iter 0, loss: 6.183, accuracy: 0.850\n",
      "epoch 89 iter 70, loss: 7.157, accuracy: 0.849\n",
      "epoch 89 iter 140, loss: 6.782, accuracy: 0.847\n",
      "epoch 89 iter 210, loss: 7.060, accuracy: 0.849\n",
      "epoch 89 iter 280, loss: 6.600, accuracy: 0.848\n",
      "epoch 90 iter 0, loss: 6.542, accuracy: 0.850\n",
      "epoch 90 iter 70, loss: 7.223, accuracy: 0.857\n",
      "epoch 90 iter 140, loss: 7.490, accuracy: 0.842\n",
      "epoch 90 iter 210, loss: 7.075, accuracy: 0.857\n",
      "epoch 90 iter 280, loss: 6.810, accuracy: 0.850\n",
      "epoch 91 iter 0, loss: 6.740, accuracy: 0.855\n",
      "epoch 91 iter 70, loss: 7.020, accuracy: 0.846\n",
      "epoch 91 iter 140, loss: 7.148, accuracy: 0.845\n",
      "epoch 91 iter 210, loss: 6.437, accuracy: 0.850\n",
      "epoch 91 iter 280, loss: 6.775, accuracy: 0.849\n",
      "epoch 92 iter 0, loss: 6.340, accuracy: 0.846\n",
      "epoch 92 iter 70, loss: 6.697, accuracy: 0.848\n",
      "epoch 92 iter 140, loss: 6.961, accuracy: 0.842\n",
      "epoch 92 iter 210, loss: 6.525, accuracy: 0.852\n",
      "epoch 92 iter 280, loss: 6.749, accuracy: 0.838\n",
      "epoch 93 iter 0, loss: 6.724, accuracy: 0.847\n",
      "epoch 93 iter 70, loss: 7.253, accuracy: 0.852\n",
      "epoch 93 iter 140, loss: 6.791, accuracy: 0.850\n",
      "epoch 93 iter 210, loss: 7.024, accuracy: 0.849\n",
      "epoch 93 iter 280, loss: 6.494, accuracy: 0.848\n",
      "epoch 94 iter 0, loss: 6.372, accuracy: 0.847\n",
      "epoch 94 iter 70, loss: 6.948, accuracy: 0.854\n",
      "epoch 94 iter 140, loss: 6.773, accuracy: 0.853\n",
      "epoch 94 iter 210, loss: 7.605, accuracy: 0.853\n",
      "epoch 94 iter 280, loss: 6.713, accuracy: 0.853\n",
      "epoch 95 iter 0, loss: 6.869, accuracy: 0.851\n",
      "epoch 95 iter 70, loss: 7.118, accuracy: 0.855\n",
      "epoch 95 iter 140, loss: 6.679, accuracy: 0.848\n",
      "epoch 95 iter 210, loss: 7.422, accuracy: 0.853\n",
      "epoch 95 iter 280, loss: 6.946, accuracy: 0.852\n",
      "epoch 96 iter 0, loss: 6.872, accuracy: 0.847\n",
      "epoch 96 iter 70, loss: 7.295, accuracy: 0.857\n",
      "epoch 96 iter 140, loss: 7.229, accuracy: 0.849\n",
      "epoch 96 iter 210, loss: 7.245, accuracy: 0.852\n",
      "epoch 96 iter 280, loss: 6.630, accuracy: 0.858\n",
      "epoch 97 iter 0, loss: 6.529, accuracy: 0.858\n",
      "epoch 97 iter 70, loss: 8.428, accuracy: 0.853\n",
      "epoch 97 iter 140, loss: 7.140, accuracy: 0.843\n",
      "epoch 97 iter 210, loss: 7.976, accuracy: 0.857\n",
      "epoch 97 iter 280, loss: 6.737, accuracy: 0.853\n",
      "epoch 98 iter 0, loss: 6.674, accuracy: 0.855\n",
      "epoch 98 iter 70, loss: 7.531, accuracy: 0.859\n",
      "epoch 98 iter 140, loss: 8.027, accuracy: 0.850\n",
      "epoch 98 iter 210, loss: 7.392, accuracy: 0.854\n",
      "epoch 98 iter 280, loss: 7.532, accuracy: 0.851\n",
      "epoch 99 iter 0, loss: 7.076, accuracy: 0.854\n",
      "epoch 99 iter 70, loss: 8.085, accuracy: 0.857\n",
      "epoch 99 iter 140, loss: 7.731, accuracy: 0.854\n",
      "epoch 99 iter 210, loss: 7.472, accuracy: 0.857\n",
      "epoch 99 iter 280, loss: 7.241, accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "def my_SVHN_net(x_):    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            strides=1,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            strides=1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=1000, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}    \n",
    "\n",
    "modified_model_dict = apply_classification_loss(my_SVHN_net)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=100, print_every=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Double click here to add your answer]**\n",
    "\n",
    "From 1.1 we can get that: strides = 1 kernel_size = [5,5] # of filter = 32 and units = 500 and finally the accuraccy = 0.822.\n",
    "\n",
    "By changing filter = 16, we can get accuraccy = 0.853.\n",
    "\n",
    "By changing filter = 64, we can get accuraccy = 0.853.\n",
    " \n",
    "By changing kernel—size = [3,3] we can get the accuraccy = 0.832.\n",
    "\n",
    "By changing kernel—size = [7,7] we can get the accuraccy = 0.806\n",
    "\n",
    "By changing the strides = 2 we can get accuraccy = 0.817.\n",
    "\n",
    "By changing the strides = 3 we can get accuraccy = 0.792.\n",
    "\n",
    "By changing the unites = 100 we can get accuraccy = 0.858.\n",
    "\n",
    "By changing the units = 1000 we can get accuraccy = 0.856."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Saving and Reloading Model Weights\n",
    "(25 points)\n",
    "\n",
    "In this section you learn to save the weights of a trained model, and to load the weights of a saved model. This is really useful when we would like to load an already trained model in order to continue training or to fine-tune it. Often times we save “snapshots” of the trained model as training progresses in case the training is interrupted, or in case we would like to fall back to an earlier model, this is called snapshot saving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 Defining another network\n",
    "(10 points)\n",
    "\n",
    "Define a network with a slightly different structure in `def cnn_expanded(x_)` below. `cnn_expanded` is an expanded version of `cnn_model`. \n",
    "It should have: \n",
    "- followed by one additional convolutional layer, and \n",
    "- followed by one additional pooling layer.\n",
    "\n",
    "The last fully-connected layer will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the new model \n",
    "def cnn_expanded(x_):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "            inputs=pool2,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)  \n",
    "    \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    pool_flat = tf.contrib.layers.flatten(pool3, scope='pool2flat')\n",
    "    \n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Saving and Loading Weights\n",
    "(15 points)\n",
    "\n",
    "`new_train_model()` below has two additional parameters `save_model=False, load_model=False` than `train_model` defined previously. Modify `new_train_model()` such that it would \n",
    "- save weights after the training is complete if `save_model` is `True`, and\n",
    "- load weights on start-up before training if `load_model` is `True`.\n",
    "\n",
    "*Hint:*  take a look at the docs for `tf.train.Saver()` here: https://www.tensorflow.org/api_docs/python/tf/train/Saver#__init__. You probably will be specifying the first argument `var_list` in `cnn_expanded` to accomplish this question.\n",
    "\n",
    "**Note:** you're welcome to decide how many training epochs to use, if that gets you the same results but faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Modify this:\n",
    "def new_train_model(model_dict, dataset_generators, epoch_n, print_every,\n",
    "                    save_model=False, load_model=False):\n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        if load_model:\n",
    "            ## -- ! code required \n",
    "            saver.restore(sess,'checkpoint_dir/MyModel')\n",
    "            print('Model loaded')\n",
    "        for epoch_i in range(epoch_n):\n",
    "            for iter_i, data_batch in enumerate(dataset_generators['train']):\n",
    "                train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
    "                sess.run(model_dict['train_op'], feed_dict=train_feed_dict)\n",
    "                \n",
    "                if iter_i % print_every == 0:\n",
    "                    collect_arr = []\n",
    "                    for test_batch in dataset_generators['test']:\n",
    "                        test_feed_dict = dict(zip(model_dict['inputs'], test_batch))\n",
    "                        to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
    "                        collect_arr.append(sess.run(to_compute, test_feed_dict))\n",
    "                    averages = np.mean(collect_arr, axis=0)\n",
    "                    fmt = (epoch_i, iter_i, ) + tuple(averages)\n",
    "                    print('iteration {:d} {:d}\\t loss: {:.3f}, '\n",
    "                          'accuracy: {:.3f}'.format(*fmt))\n",
    "                    \n",
    "        if save_model:\n",
    "            ## -- ! code required \n",
    "            saver.save(sess, 'checkpoint_dir/MyModel')\n",
    "            print('Model saved')\n",
    "            \n",
    "cnn_expanded_dict = apply_classification_loss(cnn_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 0\t loss: 26.153, accuracy: 0.119\n",
      "iteration 0 70\t loss: 2.223, accuracy: 0.198\n",
      "iteration 0 140\t loss: 2.198, accuracy: 0.214\n",
      "iteration 0 210\t loss: 2.081, accuracy: 0.269\n",
      "iteration 0 280\t loss: 1.930, accuracy: 0.320\n",
      "iteration 1 0\t loss: 1.922, accuracy: 0.324\n",
      "iteration 1 70\t loss: 1.778, accuracy: 0.374\n",
      "iteration 1 140\t loss: 1.615, accuracy: 0.450\n",
      "iteration 1 210\t loss: 1.597, accuracy: 0.453\n",
      "iteration 1 280\t loss: 1.288, accuracy: 0.593\n",
      "iteration 2 0\t loss: 1.208, accuracy: 0.623\n",
      "iteration 2 70\t loss: 1.069, accuracy: 0.674\n",
      "iteration 2 140\t loss: 0.974, accuracy: 0.704\n",
      "iteration 2 210\t loss: 0.880, accuracy: 0.735\n",
      "iteration 2 280\t loss: 0.871, accuracy: 0.742\n",
      "iteration 3 0\t loss: 0.856, accuracy: 0.744\n",
      "iteration 3 70\t loss: 0.815, accuracy: 0.755\n",
      "iteration 3 140\t loss: 0.804, accuracy: 0.763\n",
      "iteration 3 210\t loss: 0.774, accuracy: 0.767\n",
      "iteration 3 280\t loss: 0.754, accuracy: 0.776\n",
      "iteration 4 0\t loss: 0.770, accuracy: 0.769\n",
      "iteration 4 70\t loss: 0.727, accuracy: 0.783\n",
      "iteration 4 140\t loss: 0.753, accuracy: 0.780\n",
      "iteration 4 210\t loss: 0.707, accuracy: 0.790\n",
      "iteration 4 280\t loss: 0.676, accuracy: 0.801\n",
      "iteration 5 0\t loss: 0.710, accuracy: 0.790\n",
      "iteration 5 70\t loss: 0.658, accuracy: 0.807\n",
      "iteration 5 140\t loss: 0.675, accuracy: 0.804\n",
      "iteration 5 210\t loss: 0.631, accuracy: 0.816\n",
      "iteration 5 280\t loss: 0.637, accuracy: 0.815\n",
      "iteration 6 0\t loss: 0.627, accuracy: 0.815\n",
      "iteration 6 70\t loss: 0.635, accuracy: 0.813\n",
      "iteration 6 140\t loss: 0.648, accuracy: 0.819\n",
      "iteration 6 210\t loss: 0.587, accuracy: 0.831\n",
      "iteration 6 280\t loss: 0.598, accuracy: 0.830\n",
      "iteration 7 0\t loss: 0.591, accuracy: 0.829\n",
      "iteration 7 70\t loss: 0.599, accuracy: 0.823\n",
      "iteration 7 140\t loss: 0.595, accuracy: 0.830\n",
      "iteration 7 210\t loss: 0.598, accuracy: 0.829\n",
      "iteration 7 280\t loss: 0.585, accuracy: 0.833\n",
      "iteration 8 0\t loss: 0.607, accuracy: 0.827\n",
      "iteration 8 70\t loss: 0.595, accuracy: 0.823\n",
      "iteration 8 140\t loss: 0.577, accuracy: 0.839\n",
      "iteration 8 210\t loss: 0.568, accuracy: 0.834\n",
      "iteration 8 280\t loss: 0.584, accuracy: 0.838\n",
      "iteration 9 0\t loss: 0.590, accuracy: 0.837\n",
      "iteration 9 70\t loss: 0.567, accuracy: 0.839\n",
      "iteration 9 140\t loss: 0.580, accuracy: 0.836\n",
      "iteration 9 210\t loss: 0.565, accuracy: 0.836\n",
      "iteration 9 280\t loss: 0.572, accuracy: 0.844\n",
      "iteration 10 0\t loss: 0.624, accuracy: 0.834\n",
      "iteration 10 70\t loss: 0.565, accuracy: 0.842\n",
      "iteration 10 140\t loss: 0.580, accuracy: 0.842\n",
      "iteration 10 210\t loss: 0.538, accuracy: 0.849\n",
      "iteration 10 280\t loss: 0.580, accuracy: 0.847\n",
      "iteration 11 0\t loss: 0.615, accuracy: 0.841\n",
      "iteration 11 70\t loss: 0.576, accuracy: 0.841\n",
      "iteration 11 140\t loss: 0.610, accuracy: 0.837\n",
      "iteration 11 210\t loss: 0.565, accuracy: 0.846\n",
      "iteration 11 280\t loss: 0.609, accuracy: 0.844\n",
      "iteration 12 0\t loss: 0.597, accuracy: 0.847\n",
      "iteration 12 70\t loss: 0.616, accuracy: 0.842\n",
      "iteration 12 140\t loss: 0.609, accuracy: 0.846\n",
      "iteration 12 210\t loss: 0.609, accuracy: 0.841\n",
      "iteration 12 280\t loss: 0.593, accuracy: 0.849\n",
      "iteration 13 0\t loss: 0.622, accuracy: 0.844\n",
      "iteration 13 70\t loss: 0.603, accuracy: 0.847\n",
      "iteration 13 140\t loss: 0.681, accuracy: 0.836\n",
      "iteration 13 210\t loss: 0.626, accuracy: 0.835\n",
      "iteration 13 280\t loss: 0.633, accuracy: 0.843\n",
      "iteration 14 0\t loss: 0.623, accuracy: 0.845\n",
      "iteration 14 70\t loss: 0.660, accuracy: 0.832\n",
      "iteration 14 140\t loss: 0.671, accuracy: 0.841\n",
      "iteration 14 210\t loss: 0.625, accuracy: 0.843\n",
      "iteration 14 280\t loss: 0.635, accuracy: 0.850\n",
      "iteration 15 0\t loss: 0.656, accuracy: 0.847\n",
      "iteration 15 70\t loss: 0.697, accuracy: 0.832\n",
      "iteration 15 140\t loss: 0.678, accuracy: 0.847\n",
      "iteration 15 210\t loss: 0.664, accuracy: 0.840\n",
      "iteration 15 280\t loss: 0.678, accuracy: 0.847\n",
      "iteration 16 0\t loss: 0.721, accuracy: 0.841\n",
      "iteration 16 70\t loss: 0.652, accuracy: 0.844\n",
      "iteration 16 140\t loss: 0.741, accuracy: 0.837\n",
      "iteration 16 210\t loss: 0.674, accuracy: 0.845\n",
      "iteration 16 280\t loss: 0.661, accuracy: 0.854\n",
      "iteration 17 0\t loss: 0.706, accuracy: 0.853\n",
      "iteration 17 70\t loss: 0.678, accuracy: 0.847\n",
      "iteration 17 140\t loss: 0.829, accuracy: 0.833\n",
      "iteration 17 210\t loss: 0.750, accuracy: 0.841\n",
      "iteration 17 280\t loss: 0.683, accuracy: 0.849\n",
      "iteration 18 0\t loss: 0.732, accuracy: 0.854\n",
      "iteration 18 70\t loss: 0.725, accuracy: 0.846\n",
      "iteration 18 140\t loss: 0.812, accuracy: 0.840\n",
      "iteration 18 210\t loss: 0.797, accuracy: 0.841\n",
      "iteration 18 280\t loss: 0.728, accuracy: 0.852\n",
      "iteration 19 0\t loss: 0.709, accuracy: 0.857\n",
      "iteration 19 70\t loss: 0.796, accuracy: 0.841\n",
      "iteration 19 140\t loss: 0.870, accuracy: 0.833\n",
      "iteration 19 210\t loss: 0.780, accuracy: 0.841\n",
      "iteration 19 280\t loss: 0.770, accuracy: 0.851\n",
      "iteration 20 0\t loss: 0.753, accuracy: 0.853\n",
      "iteration 20 70\t loss: 0.880, accuracy: 0.848\n",
      "iteration 20 140\t loss: 0.880, accuracy: 0.826\n",
      "iteration 20 210\t loss: 0.816, accuracy: 0.848\n",
      "iteration 20 280\t loss: 0.811, accuracy: 0.850\n",
      "iteration 21 0\t loss: 0.851, accuracy: 0.844\n",
      "iteration 21 70\t loss: 0.852, accuracy: 0.850\n",
      "iteration 21 140\t loss: 0.981, accuracy: 0.826\n",
      "iteration 21 210\t loss: 0.863, accuracy: 0.833\n",
      "iteration 21 280\t loss: 0.831, accuracy: 0.844\n",
      "iteration 22 0\t loss: 0.912, accuracy: 0.844\n",
      "iteration 22 70\t loss: 0.906, accuracy: 0.836\n",
      "iteration 22 140\t loss: 0.957, accuracy: 0.828\n",
      "iteration 22 210\t loss: 0.831, accuracy: 0.847\n",
      "iteration 22 280\t loss: 0.818, accuracy: 0.851\n",
      "iteration 23 0\t loss: 0.847, accuracy: 0.853\n",
      "iteration 23 70\t loss: 0.919, accuracy: 0.847\n",
      "iteration 23 140\t loss: 0.953, accuracy: 0.843\n",
      "iteration 23 210\t loss: 0.882, accuracy: 0.844\n",
      "iteration 23 280\t loss: 0.892, accuracy: 0.844\n",
      "iteration 24 0\t loss: 0.916, accuracy: 0.855\n",
      "iteration 24 70\t loss: 0.903, accuracy: 0.846\n",
      "iteration 24 140\t loss: 0.905, accuracy: 0.846\n",
      "iteration 24 210\t loss: 0.924, accuracy: 0.850\n",
      "iteration 24 280\t loss: 0.953, accuracy: 0.842\n",
      "iteration 25 0\t loss: 0.958, accuracy: 0.856\n",
      "iteration 25 70\t loss: 0.974, accuracy: 0.852\n",
      "iteration 25 140\t loss: 0.949, accuracy: 0.846\n",
      "iteration 25 210\t loss: 0.941, accuracy: 0.848\n",
      "iteration 25 280\t loss: 1.014, accuracy: 0.850\n",
      "iteration 26 0\t loss: 0.906, accuracy: 0.857\n",
      "iteration 26 70\t loss: 0.943, accuracy: 0.847\n",
      "iteration 26 140\t loss: 1.008, accuracy: 0.844\n",
      "iteration 26 210\t loss: 1.018, accuracy: 0.851\n",
      "iteration 26 280\t loss: 1.074, accuracy: 0.850\n",
      "iteration 27 0\t loss: 0.996, accuracy: 0.857\n",
      "iteration 27 70\t loss: 0.977, accuracy: 0.845\n",
      "iteration 27 140\t loss: 1.064, accuracy: 0.835\n",
      "iteration 27 210\t loss: 1.105, accuracy: 0.844\n",
      "iteration 27 280\t loss: 1.045, accuracy: 0.852\n",
      "iteration 28 0\t loss: 1.071, accuracy: 0.853\n",
      "iteration 28 70\t loss: 0.995, accuracy: 0.843\n",
      "iteration 28 140\t loss: 1.104, accuracy: 0.847\n",
      "iteration 28 210\t loss: 1.068, accuracy: 0.843\n",
      "iteration 28 280\t loss: 1.130, accuracy: 0.840\n",
      "iteration 29 0\t loss: 1.109, accuracy: 0.852\n",
      "iteration 29 70\t loss: 1.035, accuracy: 0.843\n",
      "iteration 29 140\t loss: 1.149, accuracy: 0.849\n",
      "iteration 29 210\t loss: 1.218, accuracy: 0.844\n",
      "iteration 29 280\t loss: 1.217, accuracy: 0.844\n",
      "iteration 30 0\t loss: 1.219, accuracy: 0.846\n",
      "iteration 30 70\t loss: 1.165, accuracy: 0.834\n",
      "iteration 30 140\t loss: 1.179, accuracy: 0.846\n",
      "iteration 30 210\t loss: 1.224, accuracy: 0.852\n",
      "iteration 30 280\t loss: 1.134, accuracy: 0.842\n",
      "iteration 31 0\t loss: 1.143, accuracy: 0.838\n",
      "iteration 31 70\t loss: 1.138, accuracy: 0.851\n",
      "iteration 31 140\t loss: 1.155, accuracy: 0.846\n",
      "iteration 31 210\t loss: 1.166, accuracy: 0.851\n",
      "iteration 31 280\t loss: 1.229, accuracy: 0.840\n",
      "iteration 32 0\t loss: 1.200, accuracy: 0.844\n",
      "iteration 32 70\t loss: 1.199, accuracy: 0.838\n",
      "iteration 32 140\t loss: 1.201, accuracy: 0.842\n",
      "iteration 32 210\t loss: 1.173, accuracy: 0.848\n",
      "iteration 32 280\t loss: 1.302, accuracy: 0.839\n",
      "iteration 33 0\t loss: 1.300, accuracy: 0.823\n",
      "iteration 33 70\t loss: 1.252, accuracy: 0.833\n",
      "iteration 33 140\t loss: 1.217, accuracy: 0.847\n",
      "iteration 33 210\t loss: 1.212, accuracy: 0.847\n",
      "iteration 33 280\t loss: 1.363, accuracy: 0.839\n",
      "iteration 34 0\t loss: 1.218, accuracy: 0.842\n",
      "iteration 34 70\t loss: 1.191, accuracy: 0.842\n",
      "iteration 34 140\t loss: 1.272, accuracy: 0.844\n",
      "iteration 34 210\t loss: 1.292, accuracy: 0.848\n",
      "iteration 34 280\t loss: 1.404, accuracy: 0.839\n",
      "iteration 35 0\t loss: 1.275, accuracy: 0.844\n",
      "iteration 35 70\t loss: 1.276, accuracy: 0.829\n",
      "iteration 35 140\t loss: 1.329, accuracy: 0.846\n",
      "iteration 35 210\t loss: 1.196, accuracy: 0.852\n",
      "iteration 35 280\t loss: 1.382, accuracy: 0.841\n",
      "iteration 36 0\t loss: 1.306, accuracy: 0.844\n",
      "iteration 36 70\t loss: 1.300, accuracy: 0.820\n",
      "iteration 36 140\t loss: 1.336, accuracy: 0.849\n",
      "iteration 36 210\t loss: 1.330, accuracy: 0.850\n",
      "iteration 36 280\t loss: 1.489, accuracy: 0.841\n",
      "iteration 37 0\t loss: 1.387, accuracy: 0.845\n",
      "iteration 37 70\t loss: 1.418, accuracy: 0.821\n",
      "iteration 37 140\t loss: 1.429, accuracy: 0.844\n",
      "iteration 37 210\t loss: 1.435, accuracy: 0.852\n",
      "iteration 37 280\t loss: 1.501, accuracy: 0.840\n",
      "iteration 38 0\t loss: 1.444, accuracy: 0.843\n",
      "iteration 38 70\t loss: 1.374, accuracy: 0.845\n",
      "iteration 38 140\t loss: 1.376, accuracy: 0.849\n",
      "iteration 38 210\t loss: 1.519, accuracy: 0.842\n",
      "iteration 38 280\t loss: 1.539, accuracy: 0.837\n",
      "iteration 39 0\t loss: 1.359, accuracy: 0.849\n",
      "iteration 39 70\t loss: 1.250, accuracy: 0.848\n",
      "iteration 39 140\t loss: 1.425, accuracy: 0.842\n",
      "iteration 39 210\t loss: 1.480, accuracy: 0.846\n",
      "iteration 39 280\t loss: 1.503, accuracy: 0.840\n",
      "iteration 40 0\t loss: 1.402, accuracy: 0.839\n",
      "iteration 40 70\t loss: 1.268, accuracy: 0.849\n",
      "iteration 40 140\t loss: 1.479, accuracy: 0.847\n",
      "iteration 40 210\t loss: 1.567, accuracy: 0.857\n",
      "iteration 40 280\t loss: 1.624, accuracy: 0.840\n",
      "iteration 41 0\t loss: 1.534, accuracy: 0.844\n",
      "iteration 41 70\t loss: 1.378, accuracy: 0.854\n",
      "iteration 41 140\t loss: 1.494, accuracy: 0.852\n",
      "iteration 41 210\t loss: 1.532, accuracy: 0.854\n",
      "iteration 41 280\t loss: 1.624, accuracy: 0.849\n",
      "iteration 42 0\t loss: 1.611, accuracy: 0.848\n",
      "iteration 42 70\t loss: 1.507, accuracy: 0.851\n",
      "iteration 42 140\t loss: 1.586, accuracy: 0.852\n",
      "iteration 42 210\t loss: 1.613, accuracy: 0.852\n",
      "iteration 42 280\t loss: 1.759, accuracy: 0.849\n",
      "iteration 43 0\t loss: 1.761, accuracy: 0.843\n",
      "iteration 43 70\t loss: 1.509, accuracy: 0.850\n",
      "iteration 43 140\t loss: 1.655, accuracy: 0.849\n",
      "iteration 43 210\t loss: 1.668, accuracy: 0.843\n",
      "iteration 43 280\t loss: 1.746, accuracy: 0.849\n",
      "iteration 44 0\t loss: 1.652, accuracy: 0.851\n",
      "iteration 44 70\t loss: 1.485, accuracy: 0.845\n",
      "iteration 44 140\t loss: 1.645, accuracy: 0.845\n",
      "iteration 44 210\t loss: 1.636, accuracy: 0.854\n",
      "iteration 44 280\t loss: 1.713, accuracy: 0.855\n",
      "iteration 45 0\t loss: 1.743, accuracy: 0.847\n",
      "iteration 45 70\t loss: 1.545, accuracy: 0.848\n",
      "iteration 45 140\t loss: 1.639, accuracy: 0.852\n",
      "iteration 45 210\t loss: 1.577, accuracy: 0.857\n",
      "iteration 45 280\t loss: 1.795, accuracy: 0.851\n",
      "iteration 46 0\t loss: 1.766, accuracy: 0.845\n",
      "iteration 46 70\t loss: 1.676, accuracy: 0.845\n",
      "iteration 46 140\t loss: 1.692, accuracy: 0.855\n",
      "iteration 46 210\t loss: 1.672, accuracy: 0.855\n",
      "iteration 46 280\t loss: 1.893, accuracy: 0.852\n",
      "iteration 47 0\t loss: 1.789, accuracy: 0.851\n",
      "iteration 47 70\t loss: 1.617, accuracy: 0.849\n",
      "iteration 47 140\t loss: 1.757, accuracy: 0.855\n",
      "iteration 47 210\t loss: 1.735, accuracy: 0.854\n",
      "iteration 47 280\t loss: 1.919, accuracy: 0.846\n",
      "iteration 48 0\t loss: 1.881, accuracy: 0.843\n",
      "iteration 48 70\t loss: 1.738, accuracy: 0.846\n",
      "iteration 48 140\t loss: 1.740, accuracy: 0.852\n",
      "iteration 48 210\t loss: 1.844, accuracy: 0.846\n",
      "iteration 48 280\t loss: 1.834, accuracy: 0.858\n",
      "iteration 49 0\t loss: 1.956, accuracy: 0.849\n",
      "iteration 49 70\t loss: 1.682, accuracy: 0.847\n",
      "iteration 49 140\t loss: 1.786, accuracy: 0.850\n",
      "iteration 49 210\t loss: 1.803, accuracy: 0.854\n",
      "iteration 49 280\t loss: 1.881, accuracy: 0.851\n",
      "iteration 50 0\t loss: 1.879, accuracy: 0.844\n",
      "iteration 50 70\t loss: 1.829, accuracy: 0.844\n",
      "iteration 50 140\t loss: 1.686, accuracy: 0.858\n",
      "iteration 50 210\t loss: 1.864, accuracy: 0.855\n",
      "iteration 50 280\t loss: 1.970, accuracy: 0.854\n",
      "iteration 51 0\t loss: 2.066, accuracy: 0.842\n",
      "iteration 51 70\t loss: 1.952, accuracy: 0.842\n",
      "iteration 51 140\t loss: 1.638, accuracy: 0.846\n",
      "iteration 51 210\t loss: 1.802, accuracy: 0.860\n",
      "iteration 51 280\t loss: 1.930, accuracy: 0.853\n",
      "iteration 52 0\t loss: 1.923, accuracy: 0.849\n",
      "iteration 52 70\t loss: 1.909, accuracy: 0.843\n",
      "iteration 52 140\t loss: 1.772, accuracy: 0.854\n",
      "iteration 52 210\t loss: 1.821, accuracy: 0.856\n",
      "iteration 52 280\t loss: 2.000, accuracy: 0.846\n",
      "iteration 53 0\t loss: 1.956, accuracy: 0.847\n",
      "iteration 53 70\t loss: 1.845, accuracy: 0.841\n",
      "iteration 53 140\t loss: 1.733, accuracy: 0.855\n",
      "iteration 53 210\t loss: 1.798, accuracy: 0.858\n",
      "iteration 53 280\t loss: 2.094, accuracy: 0.851\n",
      "iteration 54 0\t loss: 1.962, accuracy: 0.848\n",
      "iteration 54 70\t loss: 1.854, accuracy: 0.849\n",
      "iteration 54 140\t loss: 1.713, accuracy: 0.856\n",
      "iteration 54 210\t loss: 1.915, accuracy: 0.853\n",
      "iteration 54 280\t loss: 2.070, accuracy: 0.855\n",
      "iteration 55 0\t loss: 2.055, accuracy: 0.847\n",
      "iteration 55 70\t loss: 1.700, accuracy: 0.850\n",
      "iteration 55 140\t loss: 1.843, accuracy: 0.850\n",
      "iteration 55 210\t loss: 1.748, accuracy: 0.849\n",
      "iteration 55 280\t loss: 2.066, accuracy: 0.853\n",
      "iteration 56 0\t loss: 1.945, accuracy: 0.855\n",
      "iteration 56 70\t loss: 1.743, accuracy: 0.850\n",
      "iteration 56 140\t loss: 1.753, accuracy: 0.853\n",
      "iteration 56 210\t loss: 1.812, accuracy: 0.859\n",
      "iteration 56 280\t loss: 2.142, accuracy: 0.854\n",
      "iteration 57 0\t loss: 2.003, accuracy: 0.856\n",
      "iteration 57 70\t loss: 1.907, accuracy: 0.851\n",
      "iteration 57 140\t loss: 1.915, accuracy: 0.851\n",
      "iteration 57 210\t loss: 1.891, accuracy: 0.849\n",
      "iteration 57 280\t loss: 2.123, accuracy: 0.848\n",
      "iteration 58 0\t loss: 2.031, accuracy: 0.848\n",
      "iteration 58 70\t loss: 1.939, accuracy: 0.848\n",
      "iteration 58 140\t loss: 1.983, accuracy: 0.850\n",
      "iteration 58 210\t loss: 1.917, accuracy: 0.857\n",
      "iteration 58 280\t loss: 2.203, accuracy: 0.849\n",
      "iteration 59 0\t loss: 2.135, accuracy: 0.850\n",
      "iteration 59 70\t loss: 2.125, accuracy: 0.842\n",
      "iteration 59 140\t loss: 1.830, accuracy: 0.851\n",
      "iteration 59 210\t loss: 1.924, accuracy: 0.855\n",
      "iteration 59 280\t loss: 2.109, accuracy: 0.854\n",
      "iteration 60 0\t loss: 2.268, accuracy: 0.846\n",
      "iteration 60 70\t loss: 1.869, accuracy: 0.856\n",
      "iteration 60 140\t loss: 1.905, accuracy: 0.854\n",
      "iteration 60 210\t loss: 1.921, accuracy: 0.853\n",
      "iteration 60 280\t loss: 1.965, accuracy: 0.854\n",
      "iteration 61 0\t loss: 2.097, accuracy: 0.849\n",
      "iteration 61 70\t loss: 1.963, accuracy: 0.843\n",
      "iteration 61 140\t loss: 1.925, accuracy: 0.855\n",
      "iteration 61 210\t loss: 1.899, accuracy: 0.851\n",
      "iteration 61 280\t loss: 2.105, accuracy: 0.851\n",
      "iteration 62 0\t loss: 2.308, accuracy: 0.845\n",
      "iteration 62 70\t loss: 1.958, accuracy: 0.843\n",
      "iteration 62 140\t loss: 2.002, accuracy: 0.852\n",
      "iteration 62 210\t loss: 2.066, accuracy: 0.848\n",
      "iteration 62 280\t loss: 2.142, accuracy: 0.854\n",
      "iteration 63 0\t loss: 2.330, accuracy: 0.845\n",
      "iteration 63 70\t loss: 2.182, accuracy: 0.851\n",
      "iteration 63 140\t loss: 2.015, accuracy: 0.850\n",
      "iteration 63 210\t loss: 1.987, accuracy: 0.852\n",
      "iteration 63 280\t loss: 2.080, accuracy: 0.855\n",
      "iteration 64 0\t loss: 2.423, accuracy: 0.843\n",
      "iteration 64 70\t loss: 2.170, accuracy: 0.853\n",
      "iteration 64 140\t loss: 1.947, accuracy: 0.852\n",
      "iteration 64 210\t loss: 2.229, accuracy: 0.836\n",
      "iteration 64 280\t loss: 2.254, accuracy: 0.852\n",
      "iteration 65 0\t loss: 2.447, accuracy: 0.849\n",
      "iteration 65 70\t loss: 2.171, accuracy: 0.853\n",
      "iteration 65 140\t loss: 1.936, accuracy: 0.852\n",
      "iteration 65 210\t loss: 2.150, accuracy: 0.848\n",
      "iteration 65 280\t loss: 2.140, accuracy: 0.852\n",
      "iteration 66 0\t loss: 2.298, accuracy: 0.853\n",
      "iteration 66 70\t loss: 2.150, accuracy: 0.850\n",
      "iteration 66 140\t loss: 2.174, accuracy: 0.853\n",
      "iteration 66 210\t loss: 2.204, accuracy: 0.853\n",
      "iteration 66 280\t loss: 2.320, accuracy: 0.856\n",
      "iteration 67 0\t loss: 2.427, accuracy: 0.853\n",
      "iteration 67 70\t loss: 2.434, accuracy: 0.846\n",
      "iteration 67 140\t loss: 2.304, accuracy: 0.850\n",
      "iteration 67 210\t loss: 2.176, accuracy: 0.853\n",
      "iteration 67 280\t loss: 2.237, accuracy: 0.843\n",
      "iteration 68 0\t loss: 2.355, accuracy: 0.852\n",
      "iteration 68 70\t loss: 2.360, accuracy: 0.847\n",
      "iteration 68 140\t loss: 2.437, accuracy: 0.847\n",
      "iteration 68 210\t loss: 2.215, accuracy: 0.852\n",
      "iteration 68 280\t loss: 2.418, accuracy: 0.845\n",
      "iteration 69 0\t loss: 2.462, accuracy: 0.848\n",
      "iteration 69 70\t loss: 2.401, accuracy: 0.850\n",
      "iteration 69 140\t loss: 2.332, accuracy: 0.841\n",
      "iteration 69 210\t loss: 2.167, accuracy: 0.848\n",
      "iteration 69 280\t loss: 2.239, accuracy: 0.851\n",
      "iteration 70 0\t loss: 2.436, accuracy: 0.852\n",
      "iteration 70 70\t loss: 2.442, accuracy: 0.851\n",
      "iteration 70 140\t loss: 2.232, accuracy: 0.842\n",
      "iteration 70 210\t loss: 2.301, accuracy: 0.847\n",
      "iteration 70 280\t loss: 2.143, accuracy: 0.854\n",
      "iteration 71 0\t loss: 2.493, accuracy: 0.849\n",
      "iteration 71 70\t loss: 2.384, accuracy: 0.853\n",
      "iteration 71 140\t loss: 2.421, accuracy: 0.848\n",
      "iteration 71 210\t loss: 2.391, accuracy: 0.849\n",
      "iteration 71 280\t loss: 2.392, accuracy: 0.850\n",
      "iteration 72 0\t loss: 2.595, accuracy: 0.851\n",
      "iteration 72 70\t loss: 2.240, accuracy: 0.857\n",
      "iteration 72 140\t loss: 2.403, accuracy: 0.844\n",
      "iteration 72 210\t loss: 2.380, accuracy: 0.848\n",
      "iteration 72 280\t loss: 2.328, accuracy: 0.853\n",
      "iteration 73 0\t loss: 2.515, accuracy: 0.852\n",
      "iteration 73 70\t loss: 2.262, accuracy: 0.859\n",
      "iteration 73 140\t loss: 2.387, accuracy: 0.836\n",
      "iteration 73 210\t loss: 2.360, accuracy: 0.848\n",
      "iteration 73 280\t loss: 2.333, accuracy: 0.845\n",
      "iteration 74 0\t loss: 2.491, accuracy: 0.856\n",
      "iteration 74 70\t loss: 2.377, accuracy: 0.860\n",
      "iteration 74 140\t loss: 2.469, accuracy: 0.838\n",
      "iteration 74 210\t loss: 2.472, accuracy: 0.852\n",
      "iteration 74 280\t loss: 2.416, accuracy: 0.847\n",
      "iteration 75 0\t loss: 2.511, accuracy: 0.852\n",
      "iteration 75 70\t loss: 2.400, accuracy: 0.855\n",
      "iteration 75 140\t loss: 2.446, accuracy: 0.841\n",
      "iteration 75 210\t loss: 2.541, accuracy: 0.853\n",
      "iteration 75 280\t loss: 2.381, accuracy: 0.851\n",
      "iteration 76 0\t loss: 2.543, accuracy: 0.858\n",
      "iteration 76 70\t loss: 2.407, accuracy: 0.855\n",
      "iteration 76 140\t loss: 2.576, accuracy: 0.842\n",
      "iteration 76 210\t loss: 2.584, accuracy: 0.855\n",
      "iteration 76 280\t loss: 2.491, accuracy: 0.843\n",
      "iteration 77 0\t loss: 2.672, accuracy: 0.857\n",
      "iteration 77 70\t loss: 2.457, accuracy: 0.856\n",
      "iteration 77 140\t loss: 2.615, accuracy: 0.846\n",
      "iteration 77 210\t loss: 2.485, accuracy: 0.848\n",
      "iteration 77 280\t loss: 2.281, accuracy: 0.851\n",
      "iteration 78 0\t loss: 2.445, accuracy: 0.846\n",
      "iteration 78 70\t loss: 2.696, accuracy: 0.857\n",
      "iteration 78 140\t loss: 2.559, accuracy: 0.851\n",
      "iteration 78 210\t loss: 2.528, accuracy: 0.856\n",
      "iteration 78 280\t loss: 2.385, accuracy: 0.844\n",
      "iteration 79 0\t loss: 2.527, accuracy: 0.852\n",
      "iteration 79 70\t loss: 2.610, accuracy: 0.853\n",
      "iteration 79 140\t loss: 2.661, accuracy: 0.852\n",
      "iteration 79 210\t loss: 2.611, accuracy: 0.846\n",
      "iteration 79 280\t loss: 2.435, accuracy: 0.853\n",
      "iteration 80 0\t loss: 2.559, accuracy: 0.853\n",
      "iteration 80 70\t loss: 2.468, accuracy: 0.855\n",
      "iteration 80 140\t loss: 2.665, accuracy: 0.848\n",
      "iteration 80 210\t loss: 2.655, accuracy: 0.853\n",
      "iteration 80 280\t loss: 2.409, accuracy: 0.846\n",
      "iteration 81 0\t loss: 2.572, accuracy: 0.855\n",
      "iteration 81 70\t loss: 2.706, accuracy: 0.854\n",
      "iteration 81 140\t loss: 2.744, accuracy: 0.848\n",
      "iteration 81 210\t loss: 2.588, accuracy: 0.854\n",
      "iteration 81 280\t loss: 2.392, accuracy: 0.852\n",
      "iteration 82 0\t loss: 2.491, accuracy: 0.852\n",
      "iteration 82 70\t loss: 2.577, accuracy: 0.856\n",
      "iteration 82 140\t loss: 2.507, accuracy: 0.850\n",
      "iteration 82 210\t loss: 2.615, accuracy: 0.857\n",
      "iteration 82 280\t loss: 2.634, accuracy: 0.845\n",
      "iteration 83 0\t loss: 2.613, accuracy: 0.858\n",
      "iteration 83 70\t loss: 2.731, accuracy: 0.856\n",
      "iteration 83 140\t loss: 2.635, accuracy: 0.853\n",
      "iteration 83 210\t loss: 2.769, accuracy: 0.856\n",
      "iteration 83 280\t loss: 2.800, accuracy: 0.846\n",
      "iteration 84 0\t loss: 2.754, accuracy: 0.849\n",
      "iteration 84 70\t loss: 2.901, accuracy: 0.854\n",
      "iteration 84 140\t loss: 2.909, accuracy: 0.846\n",
      "iteration 84 210\t loss: 2.853, accuracy: 0.857\n",
      "iteration 84 280\t loss: 2.800, accuracy: 0.856\n",
      "iteration 85 0\t loss: 2.824, accuracy: 0.856\n",
      "iteration 85 70\t loss: 2.715, accuracy: 0.855\n",
      "iteration 85 140\t loss: 2.637, accuracy: 0.854\n",
      "iteration 85 210\t loss: 2.755, accuracy: 0.854\n",
      "iteration 85 280\t loss: 2.647, accuracy: 0.858\n",
      "iteration 86 0\t loss: 2.715, accuracy: 0.857\n",
      "iteration 86 70\t loss: 2.773, accuracy: 0.852\n",
      "iteration 86 140\t loss: 2.748, accuracy: 0.846\n",
      "iteration 86 210\t loss: 2.809, accuracy: 0.855\n",
      "iteration 86 280\t loss: 2.701, accuracy: 0.848\n",
      "iteration 87 0\t loss: 2.861, accuracy: 0.859\n",
      "iteration 87 70\t loss: 2.860, accuracy: 0.858\n",
      "iteration 87 140\t loss: 2.816, accuracy: 0.851\n",
      "iteration 87 210\t loss: 2.967, accuracy: 0.853\n",
      "iteration 87 280\t loss: 2.641, accuracy: 0.848\n",
      "iteration 88 0\t loss: 2.528, accuracy: 0.856\n",
      "iteration 88 70\t loss: 2.739, accuracy: 0.859\n",
      "iteration 88 140\t loss: 2.835, accuracy: 0.851\n",
      "iteration 88 210\t loss: 2.848, accuracy: 0.855\n",
      "iteration 88 280\t loss: 2.643, accuracy: 0.852\n",
      "iteration 89 0\t loss: 2.652, accuracy: 0.853\n",
      "iteration 89 70\t loss: 3.007, accuracy: 0.854\n",
      "iteration 89 140\t loss: 2.899, accuracy: 0.851\n",
      "iteration 89 210\t loss: 2.919, accuracy: 0.849\n",
      "iteration 89 280\t loss: 2.791, accuracy: 0.854\n",
      "iteration 90 0\t loss: 2.780, accuracy: 0.851\n",
      "iteration 90 70\t loss: 2.901, accuracy: 0.852\n",
      "iteration 90 140\t loss: 2.918, accuracy: 0.851\n",
      "iteration 90 210\t loss: 3.032, accuracy: 0.858\n",
      "iteration 90 280\t loss: 2.792, accuracy: 0.852\n",
      "iteration 91 0\t loss: 2.719, accuracy: 0.857\n",
      "iteration 91 70\t loss: 2.826, accuracy: 0.861\n",
      "iteration 91 140\t loss: 2.696, accuracy: 0.851\n",
      "iteration 91 210\t loss: 2.941, accuracy: 0.855\n",
      "iteration 91 280\t loss: 2.896, accuracy: 0.856\n",
      "iteration 92 0\t loss: 2.855, accuracy: 0.854\n",
      "iteration 92 70\t loss: 2.700, accuracy: 0.851\n",
      "iteration 92 140\t loss: 2.816, accuracy: 0.857\n",
      "iteration 92 210\t loss: 2.968, accuracy: 0.855\n",
      "iteration 92 280\t loss: 3.090, accuracy: 0.853\n",
      "iteration 93 0\t loss: 2.956, accuracy: 0.851\n",
      "iteration 93 70\t loss: 2.839, accuracy: 0.857\n",
      "iteration 93 140\t loss: 3.022, accuracy: 0.849\n",
      "iteration 93 210\t loss: 3.166, accuracy: 0.854\n",
      "iteration 93 280\t loss: 2.872, accuracy: 0.855\n",
      "iteration 94 0\t loss: 2.960, accuracy: 0.853\n",
      "iteration 94 70\t loss: 2.997, accuracy: 0.853\n",
      "iteration 94 140\t loss: 2.710, accuracy: 0.852\n",
      "iteration 94 210\t loss: 3.021, accuracy: 0.857\n",
      "iteration 94 280\t loss: 2.815, accuracy: 0.857\n",
      "iteration 95 0\t loss: 2.808, accuracy: 0.859\n",
      "iteration 95 70\t loss: 2.899, accuracy: 0.855\n",
      "iteration 95 140\t loss: 3.017, accuracy: 0.854\n",
      "iteration 95 210\t loss: 2.884, accuracy: 0.860\n",
      "iteration 95 280\t loss: 2.894, accuracy: 0.855\n",
      "iteration 96 0\t loss: 2.958, accuracy: 0.858\n",
      "iteration 96 70\t loss: 2.789, accuracy: 0.855\n",
      "iteration 96 140\t loss: 3.219, accuracy: 0.854\n",
      "iteration 96 210\t loss: 3.332, accuracy: 0.854\n",
      "iteration 96 280\t loss: 3.180, accuracy: 0.846\n",
      "iteration 97 0\t loss: 3.190, accuracy: 0.852\n",
      "iteration 97 70\t loss: 3.158, accuracy: 0.858\n",
      "iteration 97 140\t loss: 3.218, accuracy: 0.852\n",
      "iteration 97 210\t loss: 3.144, accuracy: 0.850\n",
      "iteration 97 280\t loss: 2.841, accuracy: 0.856\n",
      "iteration 98 0\t loss: 2.957, accuracy: 0.853\n",
      "iteration 98 70\t loss: 2.946, accuracy: 0.854\n",
      "iteration 98 140\t loss: 3.064, accuracy: 0.854\n",
      "iteration 98 210\t loss: 3.077, accuracy: 0.858\n",
      "iteration 98 280\t loss: 2.823, accuracy: 0.848\n",
      "iteration 99 0\t loss: 2.756, accuracy: 0.860\n",
      "iteration 99 70\t loss: 2.843, accuracy: 0.861\n",
      "iteration 99 140\t loss: 2.909, accuracy: 0.857\n",
      "iteration 99 210\t loss: 3.195, accuracy: 0.857\n",
      "iteration 99 280\t loss: 3.129, accuracy: 0.852\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "### Hint: call the saver like this: tf.train.Saver(var_list)\n",
    "### where var_list is a list of TF variables you want to save\n",
    "new_train_model(cnn_expanded_dict, dataset_generators, epoch_n=100, print_every=70, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint_dir/MyModel\n",
      "Model loaded\n",
      "iteration 0 0\t loss: 3.107, accuracy: 0.860\n",
      "iteration 0 70\t loss: 3.127, accuracy: 0.858\n",
      "iteration 0 140\t loss: 3.119, accuracy: 0.857\n",
      "iteration 0 210\t loss: 3.238, accuracy: 0.853\n",
      "iteration 0 280\t loss: 3.312, accuracy: 0.841\n",
      "iteration 1 0\t loss: 3.273, accuracy: 0.850\n",
      "iteration 1 70\t loss: 3.054, accuracy: 0.856\n",
      "iteration 1 140\t loss: 3.073, accuracy: 0.856\n",
      "iteration 1 210\t loss: 3.278, accuracy: 0.856\n",
      "iteration 1 280\t loss: 2.958, accuracy: 0.851\n",
      "iteration 2 0\t loss: 3.082, accuracy: 0.854\n",
      "iteration 2 70\t loss: 3.232, accuracy: 0.857\n",
      "iteration 2 140\t loss: 3.320, accuracy: 0.855\n",
      "iteration 2 210\t loss: 3.348, accuracy: 0.859\n",
      "iteration 2 280\t loss: 3.175, accuracy: 0.851\n",
      "iteration 3 0\t loss: 3.222, accuracy: 0.854\n",
      "iteration 3 70\t loss: 3.142, accuracy: 0.854\n",
      "iteration 3 140\t loss: 3.193, accuracy: 0.848\n",
      "iteration 3 210\t loss: 3.359, accuracy: 0.857\n",
      "iteration 3 280\t loss: 3.347, accuracy: 0.849\n",
      "iteration 4 0\t loss: 3.314, accuracy: 0.839\n",
      "iteration 4 70\t loss: 3.301, accuracy: 0.855\n",
      "iteration 4 140\t loss: 3.492, accuracy: 0.852\n",
      "iteration 4 210\t loss: 3.348, accuracy: 0.858\n",
      "iteration 4 280\t loss: 3.169, accuracy: 0.848\n",
      "iteration 5 0\t loss: 3.213, accuracy: 0.850\n",
      "iteration 5 70\t loss: 3.358, accuracy: 0.857\n",
      "iteration 5 140\t loss: 3.257, accuracy: 0.853\n",
      "iteration 5 210\t loss: 3.520, accuracy: 0.854\n",
      "iteration 5 280\t loss: 3.234, accuracy: 0.853\n",
      "iteration 6 0\t loss: 3.412, accuracy: 0.852\n",
      "iteration 6 70\t loss: 3.352, accuracy: 0.857\n",
      "iteration 6 140\t loss: 3.163, accuracy: 0.856\n",
      "iteration 6 210\t loss: 3.319, accuracy: 0.855\n",
      "iteration 6 280\t loss: 3.185, accuracy: 0.859\n",
      "iteration 7 0\t loss: 3.360, accuracy: 0.842\n",
      "iteration 7 70\t loss: 3.405, accuracy: 0.855\n",
      "iteration 7 140\t loss: 3.353, accuracy: 0.855\n",
      "iteration 7 210\t loss: 3.457, accuracy: 0.859\n",
      "iteration 7 280\t loss: 3.296, accuracy: 0.852\n",
      "iteration 8 0\t loss: 3.431, accuracy: 0.851\n",
      "iteration 8 70\t loss: 3.544, accuracy: 0.855\n",
      "iteration 8 140\t loss: 3.302, accuracy: 0.851\n",
      "iteration 8 210\t loss: 3.784, accuracy: 0.857\n",
      "iteration 8 280\t loss: 3.423, accuracy: 0.851\n",
      "iteration 9 0\t loss: 3.562, accuracy: 0.850\n",
      "iteration 9 70\t loss: 3.318, accuracy: 0.854\n",
      "iteration 9 140\t loss: 3.371, accuracy: 0.857\n",
      "iteration 9 210\t loss: 3.451, accuracy: 0.852\n",
      "iteration 9 280\t loss: 3.410, accuracy: 0.852\n"
     ]
    }
   ],
   "source": [
    "### Hint: call the saver like this: tf.train.Saver(var_list)\n",
    "### where var_list is a list of TF variables you want to load from the checkpoint \n",
    "new_train_model(cnn_expanded_dict, dataset_generators, epoch_n=10, print_every=70, load_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fine-tuning a Pre-trained Network on CIFAR-10\n",
    "(20 points)\n",
    "\n",
    "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) is another popular benchmark for image classification.\n",
    "We provide you with modified verstion of the file cifar10.py from [https://github.com/Hvass-Labs/TensorFlow-Tutorials](https://github.com/Hvass-Labs/TensorFlow-Tutorials).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import read_cifar10 as cf10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a generator for the CIFAR-10 Dataset, yielding the next batch every time next is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@read_data.restartable\n",
    "def cifar10_dataset_generator(dataset_name, batch_size, restrict_size=1000):\n",
    "    assert dataset_name in ['train', 'test']\n",
    "    assert batch_size > 0 or batch_size == -1  # -1 for entire dataset\n",
    "    \n",
    "    X_all_unrestricted, y_all = (cf10.load_training_data() if dataset_name == 'train'\n",
    "                                 else cf10.load_test_data())\n",
    "    \n",
    "    actual_restrict_size = restrict_size if dataset_name == 'train' else int(1e10)\n",
    "    X_all = X_all_unrestricted[:actual_restrict_size]\n",
    "    data_len = X_all.shape[0]\n",
    "    batch_size = batch_size if batch_size > 0 else data_len\n",
    "    \n",
    "    X_all_padded = np.concatenate([X_all, X_all[:batch_size]], axis=0)\n",
    "    y_all_padded = np.concatenate([y_all, y_all[:batch_size]], axis=0)\n",
    "    \n",
    "    for slice_i in range(math.ceil(data_len / batch_size)):\n",
    "        idx = slice_i * batch_size\n",
    "        #X_batch = X_all_padded[idx:idx + batch_size]\n",
    "        X_batch = X_all_padded[idx:idx + batch_size]*255  \n",
    "        y_batch = np.ravel(y_all_padded[idx:idx + batch_size])\n",
    "        yield X_batch.astype(np.uint8), y_batch.astype(np.uint8)\n",
    "\n",
    "cifar10_dataset_generators = {\n",
    "    'train': cifar10_dataset_generator('train', 1000),\n",
    "    'test': cifar10_dataset_generator('test', -1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1 Fine-tuning\n",
    "Let's fine-tune SVHN net on **1000 examples** from CIFAR-10. \n",
    "Compare test accuracies of the following scenarios: \n",
    "  - Train from scratch on the 1000 CIFAR-10 examples\n",
    "  - Fine-tuning a pretrained SVHN net (trained on SVHN dataset) on 1000 exampes from CIFAR-10. Use `new_train_model()` defined above to load SVHN net weights, but train on the CIFAR-10 examples.\n",
    "  \n",
    "**Note:** you're welcome to decide how many training epochs to use, if that gets you the same results but faster.\n",
    "\n",
    "**Important:** please do not change the `restrict_size=1000` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 0\t loss: 35.235, accuracy: 0.094\n",
      "iteration 1 0\t loss: 34.882, accuracy: 0.105\n",
      "iteration 2 0\t loss: 31.594, accuracy: 0.090\n",
      "iteration 3 0\t loss: 26.190, accuracy: 0.130\n",
      "iteration 4 0\t loss: 19.750, accuracy: 0.113\n",
      "iteration 5 0\t loss: 12.925, accuracy: 0.108\n",
      "iteration 6 0\t loss: 8.208, accuracy: 0.112\n",
      "iteration 7 0\t loss: 5.369, accuracy: 0.122\n",
      "iteration 8 0\t loss: 4.191, accuracy: 0.113\n",
      "iteration 9 0\t loss: 3.790, accuracy: 0.107\n",
      "iteration 10 0\t loss: 3.399, accuracy: 0.106\n",
      "iteration 11 0\t loss: 3.103, accuracy: 0.110\n",
      "iteration 12 0\t loss: 2.857, accuracy: 0.118\n",
      "iteration 13 0\t loss: 2.638, accuracy: 0.130\n",
      "iteration 14 0\t loss: 2.489, accuracy: 0.133\n",
      "iteration 15 0\t loss: 2.408, accuracy: 0.119\n",
      "iteration 16 0\t loss: 2.360, accuracy: 0.120\n",
      "iteration 17 0\t loss: 2.328, accuracy: 0.126\n",
      "iteration 18 0\t loss: 2.310, accuracy: 0.131\n",
      "iteration 19 0\t loss: 2.290, accuracy: 0.132\n",
      "iteration 20 0\t loss: 2.269, accuracy: 0.143\n",
      "iteration 21 0\t loss: 2.256, accuracy: 0.154\n",
      "iteration 22 0\t loss: 2.244, accuracy: 0.161\n",
      "iteration 23 0\t loss: 2.231, accuracy: 0.171\n",
      "iteration 24 0\t loss: 2.216, accuracy: 0.181\n",
      "iteration 25 0\t loss: 2.200, accuracy: 0.188\n",
      "iteration 26 0\t loss: 2.183, accuracy: 0.192\n",
      "iteration 27 0\t loss: 2.168, accuracy: 0.196\n",
      "iteration 28 0\t loss: 2.155, accuracy: 0.199\n",
      "iteration 29 0\t loss: 2.143, accuracy: 0.207\n",
      "iteration 30 0\t loss: 2.129, accuracy: 0.217\n",
      "iteration 31 0\t loss: 2.108, accuracy: 0.226\n",
      "iteration 32 0\t loss: 2.079, accuracy: 0.243\n",
      "iteration 33 0\t loss: 2.052, accuracy: 0.260\n",
      "iteration 34 0\t loss: 2.032, accuracy: 0.267\n",
      "iteration 35 0\t loss: 2.012, accuracy: 0.273\n",
      "iteration 36 0\t loss: 1.994, accuracy: 0.275\n",
      "iteration 37 0\t loss: 1.985, accuracy: 0.278\n",
      "iteration 38 0\t loss: 1.967, accuracy: 0.287\n",
      "iteration 39 0\t loss: 1.948, accuracy: 0.292\n",
      "iteration 40 0\t loss: 1.934, accuracy: 0.299\n",
      "iteration 41 0\t loss: 1.919, accuracy: 0.308\n",
      "iteration 42 0\t loss: 1.912, accuracy: 0.314\n",
      "iteration 43 0\t loss: 1.901, accuracy: 0.320\n",
      "iteration 44 0\t loss: 1.896, accuracy: 0.323\n",
      "iteration 45 0\t loss: 1.888, accuracy: 0.328\n",
      "iteration 46 0\t loss: 1.886, accuracy: 0.325\n",
      "iteration 47 0\t loss: 1.889, accuracy: 0.326\n",
      "iteration 48 0\t loss: 1.875, accuracy: 0.336\n",
      "iteration 49 0\t loss: 1.871, accuracy: 0.340\n",
      "iteration 50 0\t loss: 1.875, accuracy: 0.344\n",
      "iteration 51 0\t loss: 1.870, accuracy: 0.346\n",
      "iteration 52 0\t loss: 1.869, accuracy: 0.349\n",
      "iteration 53 0\t loss: 1.866, accuracy: 0.351\n",
      "iteration 54 0\t loss: 1.866, accuracy: 0.354\n",
      "iteration 55 0\t loss: 1.880, accuracy: 0.354\n",
      "iteration 56 0\t loss: 1.883, accuracy: 0.356\n",
      "iteration 57 0\t loss: 1.916, accuracy: 0.349\n",
      "iteration 58 0\t loss: 1.874, accuracy: 0.358\n",
      "iteration 59 0\t loss: 1.881, accuracy: 0.359\n",
      "iteration 60 0\t loss: 1.920, accuracy: 0.354\n",
      "iteration 61 0\t loss: 1.892, accuracy: 0.360\n",
      "iteration 62 0\t loss: 1.877, accuracy: 0.362\n",
      "iteration 63 0\t loss: 1.917, accuracy: 0.362\n",
      "iteration 64 0\t loss: 1.911, accuracy: 0.364\n",
      "iteration 65 0\t loss: 1.910, accuracy: 0.363\n",
      "iteration 66 0\t loss: 1.928, accuracy: 0.365\n",
      "iteration 67 0\t loss: 1.912, accuracy: 0.369\n",
      "iteration 68 0\t loss: 1.941, accuracy: 0.367\n",
      "iteration 69 0\t loss: 1.961, accuracy: 0.369\n",
      "iteration 70 0\t loss: 1.950, accuracy: 0.371\n",
      "iteration 71 0\t loss: 1.963, accuracy: 0.368\n",
      "iteration 72 0\t loss: 1.980, accuracy: 0.371\n",
      "iteration 73 0\t loss: 2.009, accuracy: 0.371\n",
      "iteration 74 0\t loss: 2.010, accuracy: 0.367\n",
      "iteration 75 0\t loss: 2.022, accuracy: 0.373\n",
      "iteration 76 0\t loss: 2.052, accuracy: 0.373\n",
      "iteration 77 0\t loss: 2.073, accuracy: 0.369\n",
      "iteration 78 0\t loss: 2.083, accuracy: 0.372\n",
      "iteration 79 0\t loss: 2.108, accuracy: 0.374\n",
      "iteration 80 0\t loss: 2.125, accuracy: 0.372\n",
      "iteration 81 0\t loss: 2.149, accuracy: 0.371\n",
      "iteration 82 0\t loss: 2.177, accuracy: 0.375\n",
      "iteration 83 0\t loss: 2.197, accuracy: 0.373\n",
      "iteration 84 0\t loss: 2.220, accuracy: 0.371\n",
      "iteration 85 0\t loss: 2.254, accuracy: 0.373\n",
      "iteration 86 0\t loss: 2.283, accuracy: 0.373\n",
      "iteration 87 0\t loss: 2.294, accuracy: 0.372\n",
      "iteration 88 0\t loss: 2.324, accuracy: 0.372\n",
      "iteration 89 0\t loss: 2.358, accuracy: 0.370\n",
      "iteration 90 0\t loss: 2.377, accuracy: 0.373\n",
      "iteration 91 0\t loss: 2.405, accuracy: 0.371\n",
      "iteration 92 0\t loss: 2.440, accuracy: 0.370\n",
      "iteration 93 0\t loss: 2.466, accuracy: 0.372\n",
      "iteration 94 0\t loss: 2.500, accuracy: 0.372\n",
      "iteration 95 0\t loss: 2.533, accuracy: 0.371\n",
      "iteration 96 0\t loss: 2.562, accuracy: 0.371\n",
      "iteration 97 0\t loss: 2.587, accuracy: 0.372\n",
      "iteration 98 0\t loss: 2.621, accuracy: 0.370\n",
      "iteration 99 0\t loss: 2.659, accuracy: 0.370\n"
     ]
    }
   ],
   "source": [
    "cnn_expanded_dict = apply_classification_loss(cnn_expanded)\n",
    "\n",
    "## train a model from scratch\n",
    "new_train_model(cnn_expanded_dict, cifar10_dataset_generators, epoch_n=100, \n",
    "                print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint_dir/MyModel\n",
      "Model loaded\n",
      "iteration 0 0\t loss: 28.455, accuracy: 0.098\n",
      "iteration 1 0\t loss: 14.205, accuracy: 0.107\n",
      "iteration 2 0\t loss: 6.367, accuracy: 0.105\n",
      "iteration 3 0\t loss: 4.516, accuracy: 0.108\n",
      "iteration 4 0\t loss: 4.076, accuracy: 0.105\n",
      "iteration 5 0\t loss: 3.162, accuracy: 0.112\n",
      "iteration 6 0\t loss: 2.445, accuracy: 0.101\n",
      "iteration 7 0\t loss: 2.341, accuracy: 0.100\n",
      "iteration 8 0\t loss: 2.330, accuracy: 0.100\n",
      "iteration 9 0\t loss: 2.325, accuracy: 0.100\n",
      "iteration 10 0\t loss: 2.323, accuracy: 0.100\n",
      "iteration 11 0\t loss: 2.323, accuracy: 0.100\n",
      "iteration 12 0\t loss: 2.329, accuracy: 0.100\n",
      "iteration 13 0\t loss: 2.399, accuracy: 0.100\n",
      "iteration 14 0\t loss: 2.322, accuracy: 0.100\n",
      "iteration 15 0\t loss: 2.320, accuracy: 0.100\n",
      "iteration 16 0\t loss: 2.320, accuracy: 0.100\n",
      "iteration 17 0\t loss: 2.319, accuracy: 0.100\n",
      "iteration 18 0\t loss: 2.319, accuracy: 0.100\n",
      "iteration 19 0\t loss: 2.318, accuracy: 0.100\n",
      "iteration 20 0\t loss: 2.318, accuracy: 0.100\n",
      "iteration 21 0\t loss: 2.317, accuracy: 0.100\n",
      "iteration 22 0\t loss: 2.317, accuracy: 0.100\n",
      "iteration 23 0\t loss: 2.316, accuracy: 0.100\n",
      "iteration 24 0\t loss: 2.316, accuracy: 0.100\n",
      "iteration 25 0\t loss: 2.315, accuracy: 0.100\n",
      "iteration 26 0\t loss: 2.315, accuracy: 0.100\n",
      "iteration 27 0\t loss: 2.314, accuracy: 0.100\n",
      "iteration 28 0\t loss: 2.314, accuracy: 0.100\n",
      "iteration 29 0\t loss: 2.314, accuracy: 0.100\n",
      "iteration 30 0\t loss: 2.313, accuracy: 0.100\n",
      "iteration 31 0\t loss: 2.313, accuracy: 0.100\n",
      "iteration 32 0\t loss: 2.312, accuracy: 0.100\n",
      "iteration 33 0\t loss: 2.312, accuracy: 0.100\n",
      "iteration 34 0\t loss: 2.312, accuracy: 0.100\n",
      "iteration 35 0\t loss: 2.311, accuracy: 0.100\n",
      "iteration 36 0\t loss: 2.311, accuracy: 0.100\n",
      "iteration 37 0\t loss: 2.311, accuracy: 0.100\n",
      "iteration 38 0\t loss: 2.311, accuracy: 0.100\n",
      "iteration 39 0\t loss: 2.310, accuracy: 0.100\n",
      "iteration 40 0\t loss: 2.310, accuracy: 0.100\n",
      "iteration 41 0\t loss: 2.310, accuracy: 0.100\n",
      "iteration 42 0\t loss: 2.310, accuracy: 0.100\n",
      "iteration 43 0\t loss: 2.309, accuracy: 0.100\n",
      "iteration 44 0\t loss: 2.309, accuracy: 0.100\n",
      "iteration 45 0\t loss: 2.309, accuracy: 0.100\n",
      "iteration 46 0\t loss: 2.309, accuracy: 0.100\n",
      "iteration 47 0\t loss: 2.309, accuracy: 0.100\n",
      "iteration 48 0\t loss: 2.308, accuracy: 0.100\n",
      "iteration 49 0\t loss: 2.308, accuracy: 0.100\n",
      "iteration 50 0\t loss: 2.308, accuracy: 0.100\n",
      "iteration 51 0\t loss: 2.308, accuracy: 0.100\n",
      "iteration 52 0\t loss: 2.308, accuracy: 0.100\n",
      "iteration 53 0\t loss: 2.308, accuracy: 0.100\n",
      "iteration 54 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 55 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 56 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 57 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 58 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 59 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 60 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 61 0\t loss: 2.307, accuracy: 0.100\n",
      "iteration 62 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 63 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 64 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 65 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 66 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 67 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 68 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 69 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 70 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 71 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 72 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 73 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 74 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 75 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 76 0\t loss: 2.306, accuracy: 0.100\n",
      "iteration 77 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 78 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 79 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 80 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 81 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 82 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 83 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 84 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 85 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 86 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 87 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 88 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 89 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 90 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 91 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 92 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 93 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 94 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 95 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 96 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 97 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 98 0\t loss: 2.305, accuracy: 0.100\n",
      "iteration 99 0\t loss: 2.305, accuracy: 0.100\n"
     ]
    }
   ],
   "source": [
    "## fine-tuning SVHN Net using Cifar-10 weights saved in Q2\n",
    "new_train_model(cnn_expanded_dict, cifar10_dataset_generators, epoch_n=100, \n",
    "                print_every=10, load_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: TensorBoard Visualization\n",
    "(30 points)\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) is a very helpful tool for visualization of neural networks. \n",
    "\n",
    "Present at least one visualization for each of the following:\n",
    "  - Filters\n",
    "  - Loss\n",
    "  - Accuracy\n",
    "  - Feature map  \n",
    "\n",
    "Modify code you have wrote above to also have summary writers. To  run tensorboard, the command is `tensorboard --logdir=path/to/your/log/directory`.\n",
    "\n",
    "Please notice that there may be some difficulty to run the tensorboard on SCC and you may want to run it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 0\t loss: 141.749, accuracy: 0.159\n",
      "iteration 1 0\t loss: 2.239, accuracy: 0.196\n",
      "iteration 2 0\t loss: 2.210, accuracy: 0.196\n",
      "iteration 3 0\t loss: 2.208, accuracy: 0.196\n",
      "iteration 4 0\t loss: 2.225, accuracy: 0.196\n",
      "iteration 5 0\t loss: 2.194, accuracy: 0.194\n",
      "iteration 6 0\t loss: 2.089, accuracy: 0.263\n",
      "iteration 7 0\t loss: 1.005, accuracy: 0.692\n",
      "iteration 8 0\t loss: 0.870, accuracy: 0.739\n",
      "iteration 9 0\t loss: 0.804, accuracy: 0.761\n",
      "iteration 10 0\t loss: 0.695, accuracy: 0.802\n",
      "iteration 11 0\t loss: 0.712, accuracy: 0.809\n",
      "iteration 12 0\t loss: 0.783, accuracy: 0.796\n",
      "iteration 13 0\t loss: 0.795, accuracy: 0.801\n",
      "iteration 14 0\t loss: 0.779, accuracy: 0.816\n",
      "iteration 15 0\t loss: 0.809, accuracy: 0.816\n",
      "iteration 16 0\t loss: 0.829, accuracy: 0.814\n"
     ]
    }
   ],
   "source": [
    "# Filter, loss, accuracy, and feature map visualizations\n",
    "\n",
    "def visualize():\n",
    "    log_dir = 'Tensorboard'\n",
    "    dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "    }\n",
    "    model_dict = apply_classification_loss(SVHN_net_v0)\n",
    "    #train_model(model_dict, dataset_generators, epoch_n=50, print_every=20)\n",
    "    \n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        #filters of each conv layer\n",
    "        filters1 = tf.get_default_graph().get_tensor_by_name('conv1/kernel:0')\n",
    "        filters1_t = tf.transpose(filters1, [3, 0, 1, 2])\n",
    "        tf.summary.image('conv1/filters1', filters1_t, max_outputs=1)\n",
    "        \n",
    "        #filters2 = tf.get_default_graph().get_tensor_by_name('conv2/kernel:0')\n",
    "        #filters2_t = tf.transpose(filters2, [3, 0, 1, 2])\n",
    "        #tf.summary.image('conv2/filters2', filters2_t, max_outputs=1)\n",
    "        #loss and accuracy\n",
    "        tf.summary.scalar('loss', model_dict['loss'])\n",
    "        tf.summary.scalar('accuracy', model_dict['accuracy'])\n",
    "        #feature map\n",
    "        feature1 = tf.gather(tf.get_default_graph().get_tensor_by_name('conv1/Relu:0'),[0])\n",
    "        features_t = tf.transpose(feature1, [3, 1, 2, 0])\n",
    "        tf.summary.image('conv1/feature1', features_t, max_outputs = 1)\n",
    "        \n",
    "        feature2 = tf.gather(tf.get_default_graph().get_tensor_by_name('conv2/Relu:0'),[0])\n",
    "        features_t = tf.transpose(feature2, [3, 1, 2, 0])\n",
    "        tf.summary.image('conv1/feature2', features_t, max_outputs=1)\n",
    "        \n",
    "        img = tf.get_default_graph().get_tensor_by_name('Placeholder:0')\n",
    "        img = tf.gather(img, [0])\n",
    "        tf.summary.image('input', img, max_outputs=1)\n",
    "        \n",
    "        merged = tf.summary.merge_all()\n",
    "        \n",
    "        test_writer = tf.summary.FileWriter(log_dir+'/test', sess.graph)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        \n",
    "        for epoch_i in range(20):\n",
    "            for iter_i, data_batch in enumerate(dataset_generators['train']):\n",
    "                train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
    "                sess.run(model_dict['train_op'], feed_dict=train_feed_dict)\n",
    "                \n",
    "                if iter_i % 287 == 0:\n",
    "                    collect_arr = []\n",
    "                    for test_batch in dataset_generators['test']:\n",
    "                        test_feed_dict = dict(zip(model_dict['inputs'], test_batch))\n",
    "                        to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
    "                        collect_arr.append(sess.run(to_compute, test_feed_dict))\n",
    "                                         \n",
    "                        # Vistualize testing\n",
    "                        summary_test = sess.run(merged, feed_dict=test_feed_dict)\n",
    "                        test_writer.add_summary(summary_test, epoch_i)\n",
    "                        \n",
    "                    averages = np.mean(collect_arr, axis=0)\n",
    "                    fmt = (epoch_i, iter_i, ) + tuple(averages)\n",
    "                    print('iteration {:d} {:d}\\t loss: {:.3f}, '\n",
    "                          'accuracy: {:.3f}'.format(*fmt))\n",
    "    \n",
    "\n",
    "            \n",
    "visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Bonus\n",
    "(20 points)\n",
    "\n",
    "### Q5.1 SVHN Net ++\n",
    "Improve the accuracy of SVHN Net beyond that of the provided demo: SVHN Net ++. Report your result and explain why it is improved. (The best result will get the most bonus points!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 143.839, accuracy: 0.196\n",
      "epoch 0 iter 280, loss: 0.794, accuracy: 0.762\n",
      "epoch 1 iter 0, loss: 0.748, accuracy: 0.777\n",
      "epoch 1 iter 280, loss: 0.584, accuracy: 0.829\n",
      "epoch 2 iter 0, loss: 0.565, accuracy: 0.834\n",
      "epoch 2 iter 280, loss: 0.533, accuracy: 0.843\n",
      "epoch 3 iter 0, loss: 0.495, accuracy: 0.858\n",
      "epoch 3 iter 280, loss: 0.529, accuracy: 0.843\n",
      "epoch 4 iter 0, loss: 0.462, accuracy: 0.871\n",
      "epoch 4 iter 280, loss: 0.463, accuracy: 0.871\n",
      "epoch 5 iter 0, loss: 0.489, accuracy: 0.872\n",
      "epoch 5 iter 280, loss: 0.495, accuracy: 0.866\n",
      "epoch 6 iter 0, loss: 0.526, accuracy: 0.872\n",
      "epoch 6 iter 280, loss: 0.539, accuracy: 0.863\n",
      "epoch 7 iter 0, loss: 0.557, accuracy: 0.867\n",
      "epoch 7 iter 280, loss: 0.545, accuracy: 0.874\n",
      "epoch 8 iter 0, loss: 0.684, accuracy: 0.849\n",
      "epoch 8 iter 280, loss: 0.627, accuracy: 0.868\n",
      "epoch 9 iter 0, loss: 0.594, accuracy: 0.875\n",
      "epoch 9 iter 280, loss: 0.631, accuracy: 0.871\n",
      "epoch 10 iter 0, loss: 0.639, accuracy: 0.866\n",
      "epoch 10 iter 280, loss: 0.597, accuracy: 0.882\n",
      "epoch 11 iter 0, loss: 0.733, accuracy: 0.867\n",
      "epoch 11 iter 280, loss: 0.655, accuracy: 0.884\n",
      "epoch 12 iter 0, loss: 0.752, accuracy: 0.869\n",
      "epoch 12 iter 280, loss: 0.685, accuracy: 0.882\n",
      "epoch 13 iter 0, loss: 0.697, accuracy: 0.883\n",
      "epoch 13 iter 280, loss: 0.759, accuracy: 0.878\n",
      "epoch 14 iter 0, loss: 0.744, accuracy: 0.880\n",
      "epoch 14 iter 280, loss: 0.791, accuracy: 0.883\n",
      "epoch 15 iter 0, loss: 0.834, accuracy: 0.878\n",
      "epoch 15 iter 280, loss: 0.775, accuracy: 0.882\n",
      "epoch 16 iter 0, loss: 0.827, accuracy: 0.877\n",
      "epoch 16 iter 280, loss: 0.895, accuracy: 0.880\n",
      "epoch 17 iter 0, loss: 0.969, accuracy: 0.873\n",
      "epoch 17 iter 280, loss: 0.921, accuracy: 0.882\n",
      "epoch 18 iter 0, loss: 0.924, accuracy: 0.882\n",
      "epoch 18 iter 280, loss: 0.865, accuracy: 0.883\n",
      "epoch 19 iter 0, loss: 0.886, accuracy: 0.881\n",
      "epoch 19 iter 280, loss: 0.866, accuracy: 0.879\n",
      "epoch 20 iter 0, loss: 0.981, accuracy: 0.878\n",
      "epoch 20 iter 280, loss: 0.930, accuracy: 0.881\n",
      "epoch 21 iter 0, loss: 0.968, accuracy: 0.881\n",
      "epoch 21 iter 280, loss: 1.039, accuracy: 0.875\n",
      "epoch 22 iter 0, loss: 1.067, accuracy: 0.873\n",
      "epoch 22 iter 280, loss: 0.934, accuracy: 0.885\n",
      "epoch 23 iter 0, loss: 0.977, accuracy: 0.882\n",
      "epoch 23 iter 280, loss: 0.989, accuracy: 0.882\n",
      "epoch 24 iter 0, loss: 1.072, accuracy: 0.873\n",
      "epoch 24 iter 280, loss: 1.108, accuracy: 0.882\n",
      "epoch 25 iter 0, loss: 1.019, accuracy: 0.886\n",
      "epoch 25 iter 280, loss: 1.117, accuracy: 0.875\n",
      "epoch 26 iter 0, loss: 1.042, accuracy: 0.872\n",
      "epoch 26 iter 280, loss: 1.101, accuracy: 0.882\n",
      "epoch 27 iter 0, loss: 1.154, accuracy: 0.879\n",
      "epoch 27 iter 280, loss: 1.112, accuracy: 0.877\n",
      "epoch 28 iter 0, loss: 1.014, accuracy: 0.882\n",
      "epoch 28 iter 280, loss: 1.078, accuracy: 0.878\n",
      "epoch 29 iter 0, loss: 1.173, accuracy: 0.876\n",
      "epoch 29 iter 280, loss: 1.001, accuracy: 0.886\n",
      "epoch 30 iter 0, loss: 1.036, accuracy: 0.881\n",
      "epoch 30 iter 280, loss: 1.296, accuracy: 0.882\n",
      "epoch 31 iter 0, loss: 1.182, accuracy: 0.883\n",
      "epoch 31 iter 280, loss: 1.279, accuracy: 0.884\n",
      "epoch 32 iter 0, loss: 1.220, accuracy: 0.883\n",
      "epoch 32 iter 280, loss: 1.214, accuracy: 0.884\n",
      "epoch 33 iter 0, loss: 1.218, accuracy: 0.884\n",
      "epoch 33 iter 280, loss: 1.444, accuracy: 0.880\n",
      "epoch 34 iter 0, loss: 1.398, accuracy: 0.880\n",
      "epoch 34 iter 280, loss: 1.493, accuracy: 0.877\n",
      "epoch 35 iter 0, loss: 1.425, accuracy: 0.883\n",
      "epoch 35 iter 280, loss: 1.284, accuracy: 0.885\n",
      "epoch 36 iter 0, loss: 1.245, accuracy: 0.885\n",
      "epoch 36 iter 280, loss: 1.329, accuracy: 0.890\n",
      "epoch 37 iter 0, loss: 1.434, accuracy: 0.883\n",
      "epoch 37 iter 280, loss: 1.376, accuracy: 0.886\n",
      "epoch 38 iter 0, loss: 1.490, accuracy: 0.881\n",
      "epoch 38 iter 280, loss: 1.312, accuracy: 0.886\n",
      "epoch 39 iter 0, loss: 1.350, accuracy: 0.886\n",
      "epoch 39 iter 280, loss: 1.316, accuracy: 0.886\n",
      "epoch 40 iter 0, loss: 1.309, accuracy: 0.883\n",
      "epoch 40 iter 280, loss: 1.360, accuracy: 0.889\n",
      "epoch 41 iter 0, loss: 1.358, accuracy: 0.886\n",
      "epoch 41 iter 280, loss: 1.272, accuracy: 0.892\n",
      "epoch 42 iter 0, loss: 1.259, accuracy: 0.891\n",
      "epoch 42 iter 280, loss: 1.358, accuracy: 0.888\n",
      "epoch 43 iter 0, loss: 1.242, accuracy: 0.884\n",
      "epoch 43 iter 280, loss: 1.326, accuracy: 0.888\n",
      "epoch 44 iter 0, loss: 1.330, accuracy: 0.881\n",
      "epoch 44 iter 280, loss: 1.284, accuracy: 0.887\n",
      "epoch 45 iter 0, loss: 1.289, accuracy: 0.891\n",
      "epoch 45 iter 280, loss: 1.397, accuracy: 0.891\n",
      "epoch 46 iter 0, loss: 1.421, accuracy: 0.889\n",
      "epoch 46 iter 280, loss: 1.558, accuracy: 0.884\n",
      "epoch 47 iter 0, loss: 1.496, accuracy: 0.879\n",
      "epoch 47 iter 280, loss: 1.595, accuracy: 0.888\n",
      "epoch 48 iter 0, loss: 1.595, accuracy: 0.888\n",
      "epoch 48 iter 280, loss: 1.590, accuracy: 0.886\n",
      "epoch 49 iter 0, loss: 1.625, accuracy: 0.889\n",
      "epoch 49 iter 280, loss: 1.407, accuracy: 0.889\n",
      "epoch 50 iter 0, loss: 1.547, accuracy: 0.887\n",
      "epoch 50 iter 280, loss: 1.491, accuracy: 0.884\n",
      "epoch 51 iter 0, loss: 1.535, accuracy: 0.884\n",
      "epoch 51 iter 280, loss: 1.477, accuracy: 0.885\n",
      "epoch 52 iter 0, loss: 1.450, accuracy: 0.885\n",
      "epoch 52 iter 280, loss: 1.577, accuracy: 0.883\n",
      "epoch 53 iter 0, loss: 1.612, accuracy: 0.886\n",
      "epoch 53 iter 280, loss: 1.480, accuracy: 0.888\n",
      "epoch 54 iter 0, loss: 1.536, accuracy: 0.888\n",
      "epoch 54 iter 280, loss: 1.611, accuracy: 0.887\n",
      "epoch 55 iter 0, loss: 1.570, accuracy: 0.887\n",
      "epoch 55 iter 280, loss: 1.711, accuracy: 0.887\n",
      "epoch 56 iter 0, loss: 1.822, accuracy: 0.882\n",
      "epoch 56 iter 280, loss: 1.711, accuracy: 0.885\n",
      "epoch 57 iter 0, loss: 1.759, accuracy: 0.885\n",
      "epoch 57 iter 280, loss: 1.562, accuracy: 0.888\n",
      "epoch 58 iter 0, loss: 1.529, accuracy: 0.886\n",
      "epoch 58 iter 280, loss: 1.714, accuracy: 0.889\n",
      "epoch 59 iter 0, loss: 1.641, accuracy: 0.891\n",
      "epoch 59 iter 280, loss: 1.476, accuracy: 0.887\n",
      "epoch 60 iter 0, loss: 1.477, accuracy: 0.890\n",
      "epoch 60 iter 280, loss: 1.625, accuracy: 0.885\n",
      "epoch 61 iter 0, loss: 1.562, accuracy: 0.888\n",
      "epoch 61 iter 280, loss: 1.672, accuracy: 0.894\n",
      "epoch 62 iter 0, loss: 1.628, accuracy: 0.895\n",
      "epoch 62 iter 280, loss: 1.550, accuracy: 0.887\n",
      "epoch 63 iter 0, loss: 1.638, accuracy: 0.889\n",
      "epoch 63 iter 280, loss: 1.914, accuracy: 0.888\n",
      "epoch 64 iter 0, loss: 1.856, accuracy: 0.891\n",
      "epoch 64 iter 280, loss: 1.912, accuracy: 0.885\n",
      "epoch 65 iter 0, loss: 1.811, accuracy: 0.888\n",
      "epoch 65 iter 280, loss: 1.642, accuracy: 0.889\n",
      "epoch 66 iter 0, loss: 1.578, accuracy: 0.892\n",
      "epoch 66 iter 280, loss: 1.671, accuracy: 0.892\n",
      "epoch 67 iter 0, loss: 1.651, accuracy: 0.889\n",
      "epoch 67 iter 280, loss: 1.812, accuracy: 0.888\n",
      "epoch 68 iter 0, loss: 1.853, accuracy: 0.891\n",
      "epoch 68 iter 280, loss: 1.930, accuracy: 0.887\n",
      "epoch 69 iter 0, loss: 1.943, accuracy: 0.889\n",
      "epoch 69 iter 280, loss: 1.997, accuracy: 0.889\n",
      "epoch 70 iter 0, loss: 1.796, accuracy: 0.895\n",
      "epoch 70 iter 280, loss: 1.682, accuracy: 0.886\n",
      "epoch 71 iter 0, loss: 1.654, accuracy: 0.887\n",
      "epoch 71 iter 280, loss: 1.828, accuracy: 0.887\n",
      "epoch 72 iter 0, loss: 1.818, accuracy: 0.890\n",
      "epoch 72 iter 280, loss: 1.694, accuracy: 0.890\n",
      "epoch 73 iter 0, loss: 1.685, accuracy: 0.888\n",
      "epoch 73 iter 280, loss: 1.687, accuracy: 0.889\n",
      "epoch 74 iter 0, loss: 1.765, accuracy: 0.890\n",
      "epoch 74 iter 280, loss: 1.723, accuracy: 0.893\n",
      "epoch 75 iter 0, loss: 1.879, accuracy: 0.894\n",
      "epoch 75 iter 280, loss: 1.692, accuracy: 0.890\n",
      "epoch 76 iter 0, loss: 1.837, accuracy: 0.888\n",
      "epoch 76 iter 280, loss: 1.881, accuracy: 0.891\n",
      "epoch 77 iter 0, loss: 1.885, accuracy: 0.892\n",
      "epoch 77 iter 280, loss: 1.703, accuracy: 0.890\n",
      "epoch 78 iter 0, loss: 1.776, accuracy: 0.893\n",
      "epoch 78 iter 280, loss: 2.151, accuracy: 0.884\n",
      "epoch 79 iter 0, loss: 2.069, accuracy: 0.886\n",
      "epoch 79 iter 280, loss: 2.092, accuracy: 0.893\n",
      "epoch 80 iter 0, loss: 2.113, accuracy: 0.895\n",
      "epoch 80 iter 280, loss: 1.808, accuracy: 0.885\n",
      "epoch 81 iter 0, loss: 1.874, accuracy: 0.884\n",
      "epoch 81 iter 280, loss: 1.960, accuracy: 0.893\n",
      "epoch 82 iter 0, loss: 2.020, accuracy: 0.890\n",
      "epoch 82 iter 280, loss: 2.027, accuracy: 0.893\n",
      "epoch 83 iter 0, loss: 2.008, accuracy: 0.894\n",
      "epoch 83 iter 280, loss: 1.901, accuracy: 0.893\n",
      "epoch 84 iter 0, loss: 1.930, accuracy: 0.891\n",
      "epoch 84 iter 280, loss: 2.379, accuracy: 0.882\n",
      "epoch 85 iter 0, loss: 2.333, accuracy: 0.877\n",
      "epoch 85 iter 280, loss: 2.195, accuracy: 0.892\n",
      "epoch 86 iter 0, loss: 2.141, accuracy: 0.889\n",
      "epoch 86 iter 280, loss: 2.186, accuracy: 0.887\n",
      "epoch 87 iter 0, loss: 2.142, accuracy: 0.886\n",
      "epoch 87 iter 280, loss: 2.111, accuracy: 0.891\n",
      "epoch 88 iter 0, loss: 2.182, accuracy: 0.892\n",
      "epoch 88 iter 280, loss: 2.082, accuracy: 0.892\n",
      "epoch 89 iter 0, loss: 2.049, accuracy: 0.894\n",
      "epoch 89 iter 280, loss: 2.068, accuracy: 0.893\n",
      "epoch 90 iter 0, loss: 2.177, accuracy: 0.891\n",
      "epoch 90 iter 280, loss: 2.189, accuracy: 0.888\n",
      "epoch 91 iter 0, loss: 2.151, accuracy: 0.889\n",
      "epoch 91 iter 280, loss: 1.836, accuracy: 0.887\n",
      "epoch 92 iter 0, loss: 1.983, accuracy: 0.890\n",
      "epoch 92 iter 280, loss: 2.062, accuracy: 0.886\n",
      "epoch 93 iter 0, loss: 2.077, accuracy: 0.890\n",
      "epoch 93 iter 280, loss: 1.988, accuracy: 0.893\n",
      "epoch 94 iter 0, loss: 2.104, accuracy: 0.893\n",
      "epoch 94 iter 280, loss: 2.240, accuracy: 0.881\n",
      "epoch 95 iter 0, loss: 2.158, accuracy: 0.886\n",
      "epoch 95 iter 280, loss: 2.192, accuracy: 0.888\n",
      "epoch 96 iter 0, loss: 2.290, accuracy: 0.885\n",
      "epoch 96 iter 280, loss: 2.048, accuracy: 0.892\n",
      "epoch 97 iter 0, loss: 2.079, accuracy: 0.895\n",
      "epoch 97 iter 280, loss: 2.200, accuracy: 0.894\n",
      "epoch 98 iter 0, loss: 2.335, accuracy: 0.894\n",
      "epoch 98 iter 280, loss: 2.157, accuracy: 0.892\n",
      "epoch 99 iter 0, loss: 2.154, accuracy: 0.894\n",
      "epoch 99 iter 280, loss: 2.348, accuracy: 0.890\n"
     ]
    }
   ],
   "source": [
    "def SVHN_plusplus(x_):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            filters=64,  # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=128, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "            inputs=pool2,\n",
    "            filters=256,  # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)  \n",
    "    \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "            inputs=pool3,\n",
    "            filters=256,  # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.leaky_relu)  \n",
    "    \n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv3, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)  # convolution stride\n",
    "    pool_flat = tf.contrib.layers.flatten(pool4, scope='pool2flat')\n",
    "    \n",
    "    dense1 = tf.layers.dense(inputs=pool_flat, units=2000, activation=tf.nn.relu)\n",
    "    dense2 = tf.layers.dense(inputs=dense1, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense2, units=10)\n",
    "    return logits\n",
    "\n",
    "\n",
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}\n",
    "\n",
    "SVHN_plusplus_dict = apply_classification_loss(SVHN_plusplus)\n",
    "train_model(SVHN_plusplus_dict, dataset_generators, epoch_n=100, print_every=280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuraccy of my SVHN_plusplus is 0.890. I tried to make the network deeper by adding 1 more conv layer, 1 more maxpooling layer and 1 more fully connected layer. I chose to use the $3*3$ conv kernel and increasing the number of filters in the deeper conv layers. I adjust the network according to the development of CNN networks: LeNet, Alexnet, VGG16, RestNet. Increase the accuracy by using deeper network and increasing the non-linearity at the same time avoid  the gradient problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
